[
["index.html", "SARP: Sosyal Bilimler R Platformu 1 Kapak 1.1 Tanıtım", " SARP: Sosyal Bilimler R Platformu Burak AYDIN, James ALGINA, Walter LEITE 2017 1 Kapak Bu platformun hakları korunmuştur CC0 by Burak AYDIN. 1.1 Tanıtım Bu materyal İngilizce olarak hazırlanıp Türkçeye çevirilmiştir. Bu platform sosyal bilimler alanında çalışan ve nicel veri analizlerinin teoriden ziyade uygulama aşamasına ilgi gösteren araştırmacılar için oluşturulmuştur. Bütün istatistiksel prosedürler R (R Core Team 2016b) ile yürütülmüş, gerçek veri kullanımına özen gösterilmiştir. Bu materyale platform denilmesinin üç sebebi vardır, (a) katkıya açıktır,(b) dinamik bir içeriğe sahiptir, (c) bilgisayar anakartı gibi kullanılabilir, R ile oluşturulmuş herhangi bir üst düzey çıktı platforma eklenebilir. Bu materyal Bookdown (Xie 2016) ile inşaa edilmiştir, Bookdown ise R Markdown (Allaire et al. 2016) üzerine inşa edilmiştir. Materyalin hazırlanma aşamasında R Studio (RStudio Team 2016) kullanılmıştır. 1.1.1 Neden Bookdown? Bookdown ile görsel zenginliği mevcut materyaller oluşturulabilir. Shiny uygulamaları, basit olmayan grafikler gibi R’ın araştırmacılara sunduğu ve sunacağı teknolojiler bu materyale kolayca eklenebilir. Bookdown ile aynı materyal PDF, HTML veya EBOOK olarak farklı şekilde kolayca okunabilir. Bookdown ile yazılan bir kitap Git Hub içerisinde depolanabilir ve en önemlisi katkı sağlamak isteyen araştırmacıların kolaylık sağlar. Kısacası Bookdown yeni nesil kitap yazma araçlarından biridir. 1.1.2 İçerik Platformun bu versiyonunda yer alan konular; Windows için R kurulumu R’a giRiş Veri Setleri Betimsel analizler ve hipotez testi t-test Varyans analizine giriş Korelasyon Çoklu regresyona giriş Kitabın içeriği bir ders kitabından ziyade yardımcı materyal olarak hazırlanmıştır. İçerik az ve öz ele alınmıştır. Eğer açıklamaların yetersiz olduğunu düşünüyorsanız ve katkı sağlamak istiyorsanız isminize Teşekkürler 2.2 kısmında yer verilecektir. References "],
["onyuz.html", " 2 Önyüz 2.1 Yazarlar 2.2 Teşekkür 2.3 Data 2.4 Finansal Destek", " 2 Önyüz Bu kitabın yazarları elinde olan notları bir araya getirmek istemişlerdir. Akademik özenle oluşturduğumuz bu içerik her zaman açık kaynak olarak kalacaktır. Katkılarınız, istekleriniz titizlikle dikkate alınacak ve içeriğe dahil edilecektir. Bu içeriğin hangi motivasyonlarla hazırlandığını merak eden okuyucular kitabın sonuna eklediğimiz1 proje önerisini okuayabilirler. 2.1 Yazarlar Akademik çalışmalarımız araştırma tasarıları (research design) ve nicel veri analizine yoğunlaşmıştır. Monte Carlo simulasyonları mutlaka çalışma takvimimizde yer alır. Diğer bir orta noktamız çok düzeyli modellere üzerine yaptığımız çalışmalardır. 2.1.1 Burak Aydın, Ph.D. Eğitimde araştırma ve değerlendirme metotları doktora ve istatistik doktora yandal derecesi mevcuttur. 2010 yılından bu yana R kullanıcısıdır. Yapısal eşitlik modelleri, çok düzeyli modeller ve eğilim puanları üzerine akademik çalışmaları vardır. Detaylı bilgi için Kişisel or Kurumsal 2.1.2 James Algina, Ph.D. Klasik ve Modern Test Teorisi kitabının yazarıdır. Amerikan Eğitim Araştırmaları Birliği ve Amerikan Psikoloji Birliği (APA) üyesidir. 100’den fazla saygın akademik çalışması mevcuttur.Detaylı bilgi için UF Anita Zucker Center 2.1.3 Walter L. Leite, Ph.D. Florida Üniversitesi Eğitim Fakültesinde Doçenttir. Gerçek deneysel ve yarı deneysel çalışmalardan edinilen verilerin analizinde saygın çalışmaları mevcuttur. Detaylı bilgi için UF College of Education 2.2 Teşekkür Burada katkı sağlayanların isimlerine yer verilecektir. 2.3 Data Veri kullanıma açıktır, Dünya Bankası ve İŞKUR tarafından toplanmıştır. Türkiye’de yaşayan, İŞKUR’dan mesleki eğitim talebinde bulunmuş bireyleri temsil eder. 5902 kişi içerir. Materyal içerisinde kullanılan veriye dataWBT (data WorldBank Türkiye) ismi verilmiştir ulaşmak için Bölüm 6.1.4 içerisinde yer alan basamaklar takip edilebilir. dataWBT içerisinde yer alan değişkenler; Id: katılımcı kimliği Program: Mesleki eğitim aldı mı? 1=evet, 2=Hayır Cinsiyet: Erkek, Kadın Kurs: 51 farklı kurs, muhasebeden garsonluğa. Şehir: Katılımcıların yaşadığı şehir Eğitim: en yüksek diploma Babanın eğitim durumu Annenin eğitim durumu Soru 1-6: Toplumsal cinsiyet algısı (4lü likert). Yüksek puan cinsiyet ayrımına işaret eder. Yüksek öğretim durumu: 0=Lise veya altı diplomalı , 1= Yüksek öğretim diplomalı 11: Yaş : 2010 yılında katılımcı yaşları 12: Hane geliri: TL olarak hane geliri 13: Hanede yaşayan kişi sayısı 14: Kişi başı yıllık gelir (hane geliri/hanede yaşayan kişi sayısı) 15: Toplumsal cinsiyet algısı genel puanı: 2,3,4,5 ve 6. soruların ortalaması. 16: Gelir kaynakları (12 farklı kaynak) Toplumsal cinsiyet algısı puanları ve kullanılışı hakkında detaylı bilgi için Gök ve Aydın (basımda) incelenebilir. Dünya Bankası Tarafından Katılımcılara Sorulan Sorular Evlendikten sonra hem kadın hem erkek hane gelirine katkıda bulunmalıdır (çift-gelirlilik). Üniversite eğitimi kızlardan ziyade erkekler için önemlidir. MAddi durum zorlamadığı sürece evlı bir kadın evinin dışında çalışmamalıdır. Eşinin çalışması bir erkek için onur kırıcıdır. Bir kadın düşüncelerini evde söyleyebilir fakat dışarda asla Bir kadın eşinin sözünden çıkmamalıdır. 2.4 Finansal Destek Bu materyalin hazırlanması Recep Tayyip Erdoğan Üniversitesi BAP birimi tarafından desteklenmiştir. BAP-53005-601 Öncesinde, bu proje TUBİTAK tarafından Şubat 2016 tarihinde ret edilmiştir.ID 1059B191501734. sadece Türkçe versiyonunda yer alır↩ "],
["rn-populerligi.html", " 3 R’ın popülerliği", " 3 R’ın popülerliği R programının kullanım sıklığı sürekli artmaktadır. Tippmann (2015) Scopus veri tabanında taranan ve 2014 yılında basılmış her 100 makaleden 1 tanesinde R programına veya R paketlerine atıfta bulunulduğunu yazmıştır. 2014 yılında 2925 R paketi mevcuttur. 2016 yılı sonunda bu sayı 10000’e ulaşmıştır. Data analizi ve istatistiksel modellemenin yanında, işlevsel grafikler çizme, dokümanlar oluşturma, sunum hazırlama ve simülasyon üretme gibi çeşitli amaçlar için kullanılabilen R, başta istatistikçiler olmak üzere, mühendisler, ekonometristler ve sosyal bilimlerde modern ve komplike modellerle çalışan araştırmacıların dikkatini çekmiştir.R programının yaygınlığı hakkındaki diğer göstergelere örnekler; R veri analizikonusunda evrensel bir dil olmuştur ve yeni metotlar çoğu zaman R ile sunulur (Muenchen 2011). Elektrik ve elektronik mühendisleri enstitüsü (IEEE) üyeleri tarafından en çok kullanılan 5 programlama dilinden biridir. see R programlama dilini lisans ve yüksek lisans düzeyinde ders olarak sunan üniversiteler ve uzaktan eğitim kurumları mevcuttur. Özel şirketler tarafından kullanılan bir programlama dilidir. References "],
["windows-icin-r-kurulumu.html", " 4 Windows için R kurulumu", " 4 Windows için R kurulumu R kurulumu oldukça kolaydır. R-project websitesinde yer alan basamaklar takip edilebilir veya sessiz olarak kaydedilmiş video izlenebilir (Video1 4.1). Figure 4.1: Windows için R yükle R programını betik dosyası oluşturmadan doğrudan kullanmak mümkündğr fakat bir betik düzenleyici kullanmak kolaylık sağlar. En basit betik düzenleyicisi R programının içeresinde yer alır. R açık iken File ve sonrasında new script seçilerek betik düzenleyici açılır. Bu basamaklar Video2 4.2) ile gösterilmiştir. Figure 4.2: R betik Fakat R içerisinde yer alan betik düzenleyici çok basittir. Kullanışlılğı oldukça yüksek olan ve bu materyalin hazırlanmasında da kullanılmış olan betik dzenleyici R studio’dur. Kurulum basamakları Video3 4.3 ile gösterilmiştir. Figure 4.3: R Studio Yükle "],
["basics.html", " 5 Giriş 5.1 Fonksiyonlar 5.2 R Data Tipleri 5.3 R Paketleri 5.4 Çalışma alanı (workspace)", " 5 Giriş R veri analizi, grafik veya interaktif web uygulaması gibi basit olmayan çıktılar oluşturabilir. Bu bölümün amacı basit olmayan çıktılar oluşturmadan önce gereken temel prensipleri göstermektir. 5.1 Fonksiyonlar R gibi programlanabilir gelişmiş hesap makineleri kullanıcıların fonksiyon yazmasına ve saklamasına izin verir. R kullanıcılarının fonksiyonların nasıl çalıştığını kavraması önemlidir. 5.1.1 R: Basit Hesap makinesi R hesap yapabilir. Aşağıdaki işlemleri ve ilgili R kodlarını inceleyiniz. \\[\\begin{equation} 1+1=2 \\tag{5.1} \\end{equation}\\] 1+1 ## [1] 2 \\[\\begin{equation} 1-1=0 \\tag{5.2} \\end{equation}\\] 1-1 ## [1] 0 \\[\\begin{equation} 1 + (2 / 3) - (2 * 6.5) = -11.33 \\tag{5.3} \\end{equation}\\] 1 + (2 / 3) - (2 * 6.5) ## [1] -11.33333 \\[\\begin{equation} sin(30) + 4^3 + log(4) + e^3 + \\sqrt{7} = 87.13 \\tag{5.4} \\end{equation}\\] sin(30) + 4^3 + log(4) + exp(3) + sqrt(7) ## [1] 87.12955 Eşitlik (5.1) ’den (5.4) ’e kadar olan işlemler R tarafından tamamlanır fakat hafızada tutulmaz. Eğer yaptığınız bir işelmin sonucunu tekrar kullanmak istiyorsanız ona isim vermelisiniz. İsim verdiğiniz R çıktıları oturum süresince (session) tekrar erişime açıktır. Çıktılara oturum kapandıktan sonra da ulaşmak istiyorsanız kaydetmelisiniz. Kaydetme işlemleri ilerleyen bölümlerde ele alınmıştır. İsim verme işlemi fraklı şekillerde yapılabilir; “=”, “&lt;-” or “&lt;&lt;-”. Bu materyal “=” operatörünü kullanır. Eşitlik (5.1) ’den (5.4) ’e kadar olan işlemleri oturum süresince saklamak için; a=1 - 1 b=1 + 1 c=1 + (2 / 3) - (2 * 6.5) d=sin(30) + 4^3 + log(4) + exp(3) + sqrt(7) İsim verdiğiniz çıktılar ile işlem yapabilirsiniz. a+b+c+d ## [1] 77.79622 İsim verdiğiniz bir çıktıyı değiştirebilirsiniz (overwrite) e=3+2 e ## [1] 5 e=e+10 e ## [1] 15 Farklı bir isim vermek için (Not: R büyük harf küçük harf ayrımı yapar) Equation1_output=a Equation1_output + b + c + d # a+b+c+d ile eşit ## [1] 77.79622 5.1.2 R: Programlanabilir Hesap makinesi En basit hali ile fonksiyon 3 parçadan oluşur, girdi, işlem, çıktı. Bu bölümde verilen fonksiyonların test puanlarının analiz basamağında kullanıldığını varsayalım. 5.1.2.1 Tek girdi - Tek Çıktı Aşağıda verilen fonksiyonun adı sabit5 olsun. sabit5 fonksiyonu her öğrencinin puanına 5 puan ekleyecektir. Bir diğer deyişle, son derece basit bir fonksiyon olan sabit5 verilen bir puana 5 ekleyerek çıktı oluşturur. sabit5=function(girdi){ cikti=girdi+5 return(cikti) } sabit5(girdi=50) ## [1] 55 sabit5(60) ## [1] 65 sabit5(80) ## [1] 85 sabit5 fonksiyonu girdiyi alır , 5 ekler (input+5), ve bir çıktı oluşturur (cikti=girdi+5), ve çıktıyı rapor eder (return(cikti)). Bütün bu işlemler { } içinde verilmelidir. Diğer basit bir fonksiyon sistematik1 olarak isimlendirilmiştir ve verilen her bir puana %1 ekler. systematic1=function(input){ output=input+(input/100) return(output) } systematic1(input=50) ## [1] 50.5 systematic1(100) ## [1] 101 systematic1(120) ## [1] 121.2 5.1.2.2 Çoklu Girdi-Tek Çıktı Daha önce verilen fonksiyonlar tek girdi alıp tek çıktı oluşturmuştur. Bu örnekte iki farklı girdi ve tek bir çıktı vardır. Fonksiyona eksipuan adı verilmiştir. Ham puan ve yanlış sayısı verilen fonksiyon, her yanlış için 0.2 puan düşürür. Örneğin 90 puan ve 6 yanlış girildiğinde çıktı olarak (90-0.2*6) 88.8 verilir. eksipuan=function(puan, yanlis){ cikti=puan - (0.2 * yanlis) return(cikti) } eksipuan(puan=90,yanlis=6) ## [1] 88.8 eksipuan(90,17) ## [1] 86.6 Bir R fonksiyonunda girdiler argüman (arguments) olarak isimlendirilir. eksipuan fonksiyonu 2 argümana sahiptir (puan ve yanlış) ve tek bir çıktı verir. Çoklu argüman ve çoklu çıktı içeren fonksiyonlar yazılabilir. 5.1.2.3 Çoklu Girdi ve Çoklu Çıktı geridönüt fonksiyonu doğru yanıt sayısını ve her sorunun kaç puan olduğu argümanlarını alır, çıktı olarak toplam puanı ve 100 almak için eksik kalan soru sayısını hesaplar. geridonut=function(dogruyanit, katsayi){ total=dogruyanit*katsayi kalan=(100-total)/katsayi cikti=c(paste(&quot;Puan:&quot;, total,&quot; eksik:&quot;,kalan)) return(cikti) } geridonut(dogruyanit=20,katsayi=2) ## [1] &quot;Puan: 40 eksik: 30&quot; geridonut(27,2) ## [1] &quot;Puan: 54 eksik: 23&quot; 5.1.2.4 Basit Hata R fonksiyonlarının çalışması için argumanların doğru kullanılması gerekir. Eğer geridönüt fonksiyonuna katsayı parametresini girmezseniz bir hata ile karşılaşırsınız. geridonut=function(dogruyanit, katsayi){ total=dogruyanit*katsayi kalan=(100-total)/katsayi cikti=c(paste(&quot;Puan:&quot;, total,&quot; eksik:&quot;,kalan)) return(cikti) } geridonut(dogruyanit=20) ## Error in geridonut(dogruyanit = 20): argument &quot;katsayi&quot; is missing, with no default 5.1.2.5 Basit uyarı R fonksiyonları uyarı içerebilir. Daha önce yazdığımız eksipuan fonksiyonunu düşünelim eksipuan=function(puan, yanlis){ cikti=puan - (0.2 * yanlis) return(cikti) } eksipuan(puan=50,yanlis=10) ## [1] 48 Bu fonksiyona bir uyarı ekleyebiliriz. Örneğin hesaplanacak puan sıfırın altında ise bir uyarı verebbiliriz. eksipuan2=function(puan, yanlis){ cikti=puan - (0.2 * yanlis) if (cikti&lt;0) warning(&quot;Yeni puan 0&#39;dan düşük&quot;) return(cikti) } eksipuan2(puan=10,yanlis=60) ## Warning in eksipuan2(puan = 10, yanlis = 60): Yeni puan 0&#39;dan düsük ## [1] -2 5.1.2.6 Basit Sekte Bir R fonksiyonu, yazarın belirlediği durumlarda sekteye uğrayabilir. Örneğin eksipuan3 fonksiyonunu 20’den düşük puanlar için düzeltme yapmayacak şekilde yazabiliriz. eksipuan3=function(puan, yanlis){ if ((puan)&lt;(20)) stop(&quot;20den düşük puanlar için bu fonksiyon işlemez&quot;) cikti=puan - (0.2 * yanlis) return(cikti) } eksipuan3(10,9) ## Error in eksipuan3(10, 9): 20den düsük puanlar için bu fonksiyon islemez 5.1.3 Yardım! Her R kullanıcısı yeni fonksiyonlar yazmak zorunda değildir, fakat fonksiyonların nasıl çalıştığını bilmek önemlidir. Eğer R bir hata veriyorsa bu genellikle kullanıcı veya datadan kaynaklıdır. Her ne kadar çok karşılaşılmasa da hatanın fonksiyonun kendisinden kaynaklandığı durumlar da olabilir. R fonksiyonlar sayesinde çalışır. Dünyanın her yerinden araştırmacılar R fonksiyonları yazmakta, bu fonksiyonları bir R paketi olarak erişime açmaktadırlar. Hali hazırda 10 binden fazla R paketi vardır. R programını indirdiğinizde yaklaşık 30 R paketi bilgisayarınıza otomatik olarak indirilir. Bu 30 R paketinde binlerce fonksiyon bulunur. R programınızı yüklediğinizde otomatik olarak yüklenen 30 paketten bir tanesi base dir. Bu paketin içinde 1200’den fazla fonksiyon bulunur. Örneğin mean fonksiyonu aritmetik ortalama hesaplar.Genellikle paketler detaylı açıklamalar ile birlikte sunulur. Kullanıcıların bu açıklamalara ulaşabilmesi için çeşitli yollar mevcuttur; help, ?, ?? veya example help(&quot;base&quot;) # help(mean) # aritmetik ortalama fonksiyonu ve argümanları ?mean # aritmetik ortalama fonksiyonu ve argümanları ??mean # aritmetik ortalama fonksiyonu ve argümanları example(mean) # aritmetik ortalama fonksiyonu ve argümanları 5.2 R Data Tipleri Bu bölümde vektörler, matrisler, değişken çeşitleri, kayıp veriler ve data çerçeveleri (data frames) kısaca tanıtılmıştır. 5.2.1 Vektörler R c fonksionu ile vektör oluşturabilir. 10 öğrenci için not girelim. notlar=c(40,50,53,65,72,77,79,81,86,90) notlar ## [1] 40 50 53 65 72 77 79 81 86 90 R vektörler üzerinden işlem yapabilir. notlar=c(40,50,53,65,72,77,79,81,86,90) #her nota 10 ekle notlar+10 ## [1] 50 60 63 75 82 87 89 91 96 100 #her nota yüzde 10 ekle notlar+(notlar*0.10) ## [1] 44.0 55.0 58.3 71.5 79.2 84.7 86.9 89.1 94.6 99.0 #kendi ile çarp notlar*notlar ## [1] 1600 2500 2809 4225 5184 5929 6241 6561 7396 8100 # yeni notlar notlar2=c(30,40,46,58,64,66,69,72,74,81) # notlar ve notlar2 nin ortalamasını al (notlar+notlar2)/2 ## [1] 35.0 45.0 49.5 61.5 68.0 71.5 74.0 76.5 80.0 85.5 # ilk notların yüzde 40ı ile ikinci notların yüzde 60ını topla notlar*0.4 + notlar2*0.6 ## [1] 34.0 44.0 48.8 60.8 67.2 70.4 73.0 75.6 78.8 84.6 Vektör oluşturmak için işeyarar birçok fonksiyon vardır. Örneğin rep fonksiyonu (bknz: example(rep)) aynı değerleri tekrarlamak için kullanışlıdır. rnorm fonksiyonu normal dağılıma sahip veriler simüle etmek için işe yarar. Eğer ?rnorm kullanılırsa bu fonksiyonun 3 argümanı olduğu görülür rnorm(n, mean = 0, sd = 1). Bu fonksiyon vektör uzunluğu (değişken sayısı) n verilmediği sürece çalışmaz. Eğer sadece n verilirse, popülasyon ortalaması 0 ve standart sapması 1 olan dağılımdan rasgele seçilen değerler ile bir vektör oluşturulur. Bu parametreler değiştirilebilir. Örneğin rnorm(12,mean=10,sd=2) popülasyon parametreleri 10 ve 2 olan normal bir dağılımdan 12 adet gözlem çeker. Benzer bir fonksiyon runif(n, min = 0, max = 1) tekdüzey bir dağılımdan gözlem çeker. a=1:12 # a 1 den 12ye tam sayılar rep(0,12) # 0 12 kez tekrarlanır ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 rep(1:5,each=3) # 1 den 5&#39;e tam sayılar 3er kez tekrarlanır ## [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 rep(1:5,times=3) # 3 kere 1&#39;den 5&#39;e tekrarla ## [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 seq(from=1,to=12) # 1&#39;den 12&#39;ye tam sayılar ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 seq(1,25,by=2) # 1&#39;den 25&#39;e ikişer atla ## [1] 1 3 5 7 9 11 13 15 17 19 21 23 25 seq(1,6,by=0.5) # 1&#39;den 6&#39;ya 0.5 atla ## [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 rnorm(12) # ~N(0,1) 12 gözlem ## [1] 0.51256818 0.47163340 -0.03548146 1.75731224 -0.71937825 ## [6] -0.55629544 -0.06325666 0.24623285 0.30773823 0.93725790 ## [11] 1.00082762 1.56596657 rnorm(12,mean=10,sd=2) #~ N(10,2) 12 gözlem ## [1] 9.308290 9.163879 7.742514 13.615628 11.442990 10.425684 12.352461 ## [8] 8.751339 11.352095 11.268938 11.445167 9.087891 runif(12, min = 10, max = 37) ## [1] 28.38705 29.82471 30.64895 32.69487 12.40952 13.24206 25.66105 ## [8] 36.67329 24.83213 19.86003 24.09246 21.87811 5.2.2 Matrisler R matrisler oluşturup işlem yapabilir. A=matrix(1:16,ncol=4,nrow=4) #4x4 matris oluştur A ## [,1] [,2] [,3] [,4] ## [1,] 1 5 9 13 ## [2,] 2 6 10 14 ## [3,] 3 7 11 15 ## [4,] 4 8 12 16 B=matrix(runif(16,min=20,max=40),ncol=4) #4x4 matris oluştur # işlem örnekleri A+B # topla ## [,1] [,2] [,3] [,4] ## [1,] 27.68644 37.41041 41.76502 44.44653 ## [2,] 22.09183 30.34109 31.95584 50.50530 ## [3,] 26.32991 45.57403 42.58540 47.44820 ## [4,] 27.52571 28.32999 48.22204 40.17403 A*B # çarp ## [,1] [,2] [,3] [,4] ## [1,] 26.68644 162.0520 294.8852 408.8049 ## [2,] 40.18367 146.0466 219.5584 511.0742 ## [3,] 69.98974 270.0182 347.4394 486.7230 ## [4,] 94.10285 162.6399 434.6644 386.7844 A%*%B # matris çarp ## [,1] [,2] [,3] [,4] ## [1,] 642.9491 765.5720 897.6993 820.2692 ## [2,] 736.5830 881.2275 1020.2276 944.8432 ## [3,] 830.2169 996.8831 1142.7559 1069.4173 ## [4,] 923.8508 1112.5386 1265.2841 1193.9914 t(B) # çevir ## [,1] [,2] [,3] [,4] ## [1,] 26.68644 20.09183 23.32991 23.52571 ## [2,] 32.41041 24.34109 38.57403 20.32999 ## [3,] 32.76502 21.95584 31.58540 36.22204 ## [4,] 31.44653 36.50530 32.44820 24.17403 5.2.3 Değişkenler Çözümlenecek verisetinin özelliklerini bilmek çok önemlidir. R içerisinde çözümlenecek değişkenler genellikle sınıflama, sıralı, sürekli , kayıp veya tarih tipindedir. 5.2.3.1 Sınıflama R’da bir sınıflama verisi alfanumerik şekilde girilebilir fakat yorumlanması sayısal değil sınıflama şeklindedir. Örneğin; adres=c(&quot;AAX&quot;,&quot;BBZ&quot;,&quot;CBT&quot;,&quot;DBA&quot;,&quot;DDC&quot;,&quot;XZT&quot;) cinsiyet=c(&quot;M&quot;,&quot;F&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;) id=sample(letters,6) program=rep(c(&quot;var&quot;,&quot;yok&quot;),each=3) sehir=as.character(1:6) 5.2.3.2 Sıralı Sıralı bir değişken sınıflama değişkenine göre daha çok bilgi içerir. Sıra ifade eder fakat değerler arasındaki farklılık anlmalı değildir. Örneğin koşucular birinci, ikinci ve üçüncü olarak sıralanabilir fakat bu sıralama verisi birinci ile ikinci arasında kaç dakika farklılık olduğunu belirtmez. Birinci koşucu ikinciden 5 saniye hızlı iken, ikinci koşucu üçüncü koşucudan yarım saat daha hızlı olabilir. R içerisinde ordered fonksiyonu ve level argümanı ile sıra belirtilebilir. Eğer level argüanı boş bırakılırsa R değerleri küçükten büyüğe sıralar. soru1=ordered(c(&quot;zayif&quot;,&quot;orta&quot;,&quot;iyi&quot;,&quot;iyi&quot;,&quot;zayif&quot;,&quot;zayif&quot;), levels=c(&quot;zayif&quot;,&quot;orta&quot;,&quot;iyi&quot;)) ses=ordered(c(1,3,2,2,1,3),levels=c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;)) 5.2.3.3 Sürekli Eşit aralıklı veya eşit oranlı değişkenler sıralı ve sınıflama değişkenlerine göre daha fazla bilgi içerir. Değerler arasındaki farklılık anlamlıdır. notlar=c(52,75,39,62,24,86) notlar=rnorm(n=6,mean=160,sd=5) 5.2.3.4 Tarih as.Date fonksiyonu ile tarih verisi girilebilir. dt=as.Date(c(&quot;1994-06-01&quot;,&quot;1988-10-20&quot;,&quot;1990-12-01&quot;, &quot;1978-03-23&quot;,&quot;1974-08-22&quot;,&quot;1994-11-04&quot;)) dt ## [1] &quot;1994-06-01&quot; &quot;1988-10-20&quot; &quot;1990-12-01&quot; &quot;1978-03-23&quot; &quot;1974-08-22&quot; ## [6] &quot;1994-11-04&quot; tatil=as.Date(c(&quot;01/01/2016&quot;,&quot;04/23/2016&quot;,&quot;05/19/2016&quot;,&quot;08/30/2016&quot;,&quot;09/29/2016&quot;), format=&quot;%m/%d/%y&quot;) tatil ## [1] &quot;2020-01-01&quot; &quot;2020-04-23&quot; &quot;2020-05-19&quot; &quot;2020-08-30&quot; &quot;2020-09-29&quot; Sys.Date( ) ## [1] &quot;2017-03-20&quot; Sys.Date( )-dt ## Time differences in days ## [1] 8328 10378 9606 14242 15551 8172 5.2.3.5 Doğru-Yanlış (logical) Bu değişken TRUE veya FALSE değerlerini alır. Eğer sayısal veri olmaya zorlanırsa 1 ve 0 değerlerini alır. Aşağıda verilen kod girilen notların ortalamadan düşük olup olmadığını gösterir. notlar=c(52,75,39,62,24,86) # notlar notlar&gt;mean(notlar) ## [1] FALSE TRUE FALSE TRUE FALSE TRUE as.numeric(notlar&gt;mean(notlar)) # 1 ve 0. ## [1] 0 1 0 1 0 1 5.2.4 Faktörler R içerisinde yer alan factor veri tipi sıralı ve sınıflama verileri için kullanılan bir çatıdır. kurs=factor(c(&quot;muhasebe&quot;,&quot;garson&quot;,&quot;temizlik&quot;,&quot;garson&quot;,&quot;muhasebe&quot;,&quot;garson&quot;)) ga1=factor(c(1,1,3,4,2,3),levels = 1:4, labels=c(&quot;tamamenkatilmiyorum&quot;,&quot;katilmiyorum&quot;,&quot;katiliyorum&quot;,&quot;tamamenkatiliyorum&quot;)) ga2=factor(c(1,3,4,4,2,3),ordered = T) ga3=gl(n=3,k=2,labels=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),ordered=F) Faktörler önemlidir. Faktörlerin alt sınıfları (levels) dikkatli bir şekilde incelenmelidir. Çözümleme aşamasında kullanılmayan alt sınıflar silinmelidir. Örneğin veri seti bölünmeden önce Renk faktörü girilmiş olsun, “mavi”, “yeşil”, “sarı” alt sınıflar olsun. Daha sonra veri seti bölündüğünde alt sınıf “sarı” kullanılmamış olsun. R Renk değişkenini hala 3 alt sınıflı olarak düşünecektir ve ona göre işlem yapacaktır. Bu hatalara sebep olur. Droplevel fonksiyonu kullanılarak faktör değişkeni düzeltilmelidir. renk=factor(c(1,1,1,2,2,3),levels = 1:3,labels=c(&quot;mavi&quot;,&quot;yesil&quot;,&quot;sari&quot;)) renk ## [1] mavi mavi mavi yesil yesil sari ## Levels: mavi yesil sari renk2=renk[1:5] # renk2 değişkeni son degeri almadı renk2 #fakat hala 3 level mevcut ## [1] mavi mavi mavi yesil yesil ## Levels: mavi yesil sari droplevels(renk2) #kullanılmayan level silindi ## [1] mavi mavi mavi yesil yesil ## Levels: mavi yesil 5.2.5 Kayıp Veriler Veri seti kayıp veriler içerebilir. R kayıp verileri NA (not available) ile belirtir. gelir=c(&quot;maas&quot;,&quot;maas&quot;,&quot;destek&quot;,NA,NA,&quot;maas&quot;) hanekisi=c(3,2,3,NA,NA,4) NOT: Kayıp veri belirleyiciler çetrefilli olabilir. NA, , &quot; &quot; (boşluk) veya önceden belirlenmiş bir sayı,örneğin -99 kayıp verileri temsil edebilir. ornek = factor(c(&#39;maas&#39;,&#39;destek&#39;, NA, &#39;NA&#39;,&quot; &quot;,-99,&quot;-99&quot;)) # faktör içerisinde kayıp veriler &lt;NA&gt; olarak verilir. # &lt; &gt; içinde yer almayan NA faktör sınıfını gosterir. # &quot; &quot; bu da faktör alt sınıfını gösterir #-99 and &quot;-99&quot; aynı faktör sınıfını gösterir # is.na fonksiyonu kayıp verileri gösterir. # ornek için bakıldığında sadece 3. eleman kayıp veri olarak görünür is.na(ornek) ## [1] FALSE FALSE TRUE FALSE FALSE FALSE FALSE #çözüm &#39;NA&#39;, &quot; &quot;, -99 ve &quot;-99&quot; ları NA&#39;ye çevirelim ornek[ornek==&#39;NA&#39; | ornek==&quot; &quot;| ornek== -99 | ornek== &quot;-99&quot;]=NA #kontrol is.na(ornek) ## [1] FALSE FALSE TRUE TRUE TRUE TRUE TRUE #droplevel kullanalım ornek=droplevels(ornek) 5.2.6 Veri Çerçeveleri (Data Frames) Bir veri çerçevesi değişkenlerden oluşur. Sosyal bilimcilerin genellikle değişkenler arası ilişkileri araştırdığını düşünürsek, veri çerçeveleri kullanıcılarının temel R ögesidir. Daha önce oluşturduğumuz değişkenleri bir veri çerçevesine alabiliriz; # hatırlatma # id=sample(letters,6) # program=rep(c(&quot;var&quot;,&quot;yok&quot;),each=3) # cinsiyet=c(&quot;M&quot;,&quot;F&quot;,&quot;F&quot;,&quot;M&quot;,&quot;F&quot;,&quot;M&quot;) # soru1=ordered(c(&quot;zayif&quot;,&quot;orta&quot;,&quot;iyi&quot;,&quot;iyi&quot;,&quot;zayif&quot;,&quot;zayif&quot;), # levels=c(&quot;zayif&quot;,&quot;orta&quot;,&quot;iyi&quot;)) # ses=ordered(c(1,3,2,2,1,3),levels=c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;)) # notlar=c(52,75,39,62,24,86) # gelir=c(&quot;maas&quot;,&quot;maas&quot;,&quot;destek&quot;,NA,NA,&quot;maas&quot;) # dt=as.Date(c(&quot;1994-06-01&quot;,&quot;1988-10-20&quot;,&quot;1990-12-01&quot;, # &quot;1978-03-23&quot;,&quot;1974-08-22&quot;,&quot;1994-11-04&quot;)) # kurs=factor(c(&quot;muhasebe&quot;,&quot;garson&quot;,&quot;temizlik&quot;,&quot;garson&quot;,&quot;muhasebe&quot;,&quot;garson&quot;)) basit_data=data.frame(id,program,cinsiyet,soru1,ses, notlar,gelir,dt,kurs) basit_data ## id program cinsiyet soru1 ses notlar gelir dt kurs ## 1 f var M zayif 1 52 maas 1994-06-01 muhasebe ## 2 a var F orta 3 75 maas 1988-10-20 garson ## 3 m var F iyi 2 39 destek 1990-12-01 temizlik ## 4 v yok M iyi 2 62 &lt;NA&gt; 1978-03-23 garson ## 5 z yok F zayif 1 24 &lt;NA&gt; 1974-08-22 muhasebe ## 6 q yok M zayif 3 86 maas 1994-11-04 garson Veri setleri el yordamı ile girildiğinde veya hazır olarak R a aktarıldığında (örneğin excel dosyasından) veri setinin yapısını incelemek önemlidir. str (structure) fonksiyonu kullanılabilir. str(basit_data) ## &#39;data.frame&#39;: 6 obs. of 9 variables: ## $ id : Factor w/ 6 levels &quot;a&quot;,&quot;f&quot;,&quot;m&quot;,&quot;q&quot;,..: 2 1 3 5 6 4 ## $ program : Factor w/ 2 levels &quot;var&quot;,&quot;yok&quot;: 1 1 1 2 2 2 ## $ cinsiyet: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 1 1 2 1 2 ## $ soru1 : Ord.factor w/ 3 levels &quot;zayif&quot;&lt;&quot;orta&quot;&lt;..: 1 2 3 3 1 1 ## $ ses : Ord.factor w/ 3 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;: 1 3 2 2 1 3 ## $ notlar : num 52 75 39 62 24 86 ## $ gelir : Factor w/ 2 levels &quot;destek&quot;,&quot;maas&quot;: 2 2 1 NA NA 2 ## $ dt : Date, format: &quot;1994-06-01&quot; &quot;1988-10-20&quot; ... ## $ kurs : Factor w/ 3 levels &quot;garson&quot;,&quot;muhasebe&quot;,..: 2 1 3 1 2 1 5.3 R Paketleri R bilgisayarınıza kurulurken 30’dan fazla paket yükler. Bu paketler sistem kütüphanesinde saklanır. R paketleri otomatik olarak yüklenen bu 30 paketle sınırlı değildir, örneğin doğrusal karma etkiler modellerini (linear mixed models) çözümlemek için lme(Bates et al. 2015) paketi kullanılabilir. Bu paket 60000’den fazla bilgisayara yüklenmiş ve 1500’den fazla akademik yayında kullanılmıştır. R paketleri genellikle CRAN (comprehensive R archive network) içerisinde bulunur. Paketler yazarlar tarafından güncellendiği sürece CRAN’da bulunur. R paketlerini CRAN’dan çekerek kendi bilgisayarınızda saklayabilirsiniz. Yüklediğiniz paketler kullanıcı kütüphanesinde tutulur. Paketleri bir R oturumunda kullanabilmek için onları aktif hale getirmeniz gerekir. R ve R Studio’yu kurma aşamasında R-RStudio-R paketleri arasında bilgisayar tarafından sağlanan otomatik bir bağ olduğunu farketmiş olabilirsiniz. R studio R’dan sonra yüklendiğinde bilgisayarınızı tarayacak, R programının yerini bulacak ve ona bağlanacaktır. Hem R hem de R Studio R paketlerinizin yerini bulabilir (eğer siz yerlerini değiştirmediyseniz). Eğer R paketlerinizin nerede olduğunu öğrenmek isterseniz .libPaths() fonksiyonunu kullanabilirsiniz. CRAN’da yer alan R kütüphaneleri bilgisayarınıza kolayca yüklenebilir. R studio’da yer alan Packages ve install sekmesinden veya install.packages(“paketismi”) fonksiyonu ile paketleri indirebilirsiniz. Paketlerin oturum esnasında aktif hale getirilmesi gerekir. Bu işlem R studio Paketler sekmesinde yer alan paket isimlerinin yanındaki kutucuğa tıklayarak veya library(“paketismi”) fonksiyonu ile tamamlanabilir. Bu basamaklar Video 4 ile gösterilmiştir.5.1. Figure 5.1: R Paketi Yükle 5.4 Çalışma alanı (workspace) Bir R oturumu açtığınızda ve R işlemleri yaptığınızda bu işlemler çalışma alanında yürütülür. Her adımınız R Studio sağ üst köşede yer alan History sekmesinde görülür. Çalışma alanınızı oturum sonunda kaydedebilirsiniz. Oturum esnasında oluşturduğunuz R çıktıları çalışma alanında tutulur. ls() fonksiyonu ile bu çıktıları görebilirsiniz. R çıktıları çalışma alanına getirilebilir veya çalışma alanı dışına uzun süreliğine kaydedilebilir. Dosyaların yerlerini bulmak ile uğraşmak istemiyorsanız bütün işlemlerinizi aynı klasörde tamamlamayı tercih edebilirsiniz. getwd() fonksiyonu size hangi klasör içinde (working directory) olduğunuzu gösterir. Uzun süreliğine kaydetmek istediğiniz bir R çıktısı bu klasöre kolayca kaydedilebilir. Aktif olan klasörünüzü setwd() fonksiyonu ile değiştirebilirsiniz. Tabiki bilgisayarınızda her hangi bir klasörde, hatta internette sakladığınız bir nesneyi R çalışma alanınıza getirebilir veya çalışma alanınızda oluşturduğunuz bir dosyayı bilgisayarınızda her hangi bir klasöre kaydedebilirsiniz. Fakat bu durumlarda adresi (location) hatasız bir şekilde R’a bildirmeniz gerekir. Girdi ve Çıktı konuları bir sonraki bölümde ele alınmıştır. References "],
["veri-setleri.html", " 6 Veri Setleri 6.1 Veri Çekme 6.2 Basit Veri İşlemleri 6.3 veri Kaydetme", " 6 Veri Setleri Verileri teker teker kaydetme 5.2.6 bölümünde verilmiştir. Fakat veri setleri genellikle çözümleme yapacak araştırmacıya hazır şekilde gelir. Bu bölüm (a) veri çekme , (b) basit veri işleme etme yöntemleri ve (c) veri kaydetme konularını içerir. 6.1 Veri Çekme Bir veri seti farklı formatlarda bulunabilir. R kullanıcılarının çok karşılaştığı veri formatları arasında .csv, .sav, .Rdata, .txt sayılabilir. Çözümleme işleminden önce verilerin düzgün bir şekilde çalışma alanına getirilmesi önemlidir.Eğer çalışacağınız veri seti ve R betiği aynı klasör içerisinde ise, bir diğer deyişle veri setiniz çalışma klasörünün (working directory) içerisinde ise adres belirtmeden veriyi çalısma alanınıza çağırabilirsiniz. 6.1.1 CSV CSV (comma separated values) virgülle ayrılmış değerler içeren dosyalardır. Microsoft Excel kullanıcıları excel formatında yer alan verileri kolayca csv olarak kaydedbilirler. Diğer excel formatları ile kıyaslandığında (xls,xlsx,xlsb, vd.) işlemesi daha kolay veri formatıdır. read.csv fonksiyonu ile veri çalısma alanına çağırılabilir. En basit hali ile; data1=read.csv(&quot;dataismi.csv&quot;) # eğer çalısma klasöründe dataisim.csv dosyası # mevut ise çalışır #Windows için data1=read.csv(&quot;C:\\\\Users\\Desktop\\\\folderX\\\\dataismi.csv&quot;) # adres (path) data1=read.csv(&quot;C:/Users/Desktop/folderX/dataismi.csv&quot;) # adres (path) #NOTE: \\ karakteri hata verir / veya \\\\ kullanılmalıdır. ?read.csv komutu ile fonksiyonun argümanlarını görebilirsiniz. Önemli olan argümanlara örnek; veya değişken isimleri mevcut ise header=TRUE aksi halde header=FALSE . Kayıp veri belirticiler için na.strings . Örneğin na.strings = “-99” bütün -99 değerlerinin kayıp veriyi belirttiğini R’a iletir. Benzer şekilde na.strings = c(“-99” , “-9” ) hem -99 hem de -9 değerlerinin kayıp veri olduğunu belirtir. Eğer karakter verilerini faktör olarak kullanmak istiyorsanız stringsAsFactors=TRUE aksi halde stringsAsFactors=FALSE. Veriyi çağırma esnasında değişkenlere yeni isim vermek istiyorsanız col.names argümanı kullanılabilir. Örneğin 3 değiskeniniz varsa col.names=c(“A1”,“B2”,“C3”) argümanı ile sütunlara isim verebilirsiniz. Eğer csv dosyanızda ondalık sayılar nokta yerine virgül ile ayrılmış ise (Avrupa ve Türkiye) bu read.csv fonksiyonu için problem oluşturur. Çözüm olarak read.csv2 fonksiyonunu kullanabilir, veya read.csv içerisinde sep=“;” ve dec=“,” argümanlarını kullanabilirsiniz. CSV dosyasından veri çağırma basamakları Video 5 ile gösterilmiştir. Figure 6.1: CSV Oku 6.1.2 SPSS SAV sosyal bilimciler tarafından kullanılan bir veri formatıdır. foreign (R Core Team 2016a) paketinde yer alan read.spss fonksiyonu sav dosyalarını okumak için kullanılabilir. require(foreign) ?read.spss data=read.spss(&quot;dataismi.sav&quot;,to.data.frame=TRUE) # eğer dataisim.sav çalışma klasöründe ise çalılşır 6.1.3 Rdata Rdata formatı genelde daha az bilgisayar hafızası işgal eder. Rdata olarak kaydedilecek her R çıktısı ismi ile birlikte kaydedilir. load(&quot;dataisim.Rdata&quot;) #eğer dataisim.Rdata çalışma klasöründe ise çalılşır 6.1.4 Sanal Depolardan Veri Çekmek R ile sanal dünyadan veri çekilebilir. Süreci basite indirgersek, (a) öncelikle verinin nerede yer aldığı doğru şekilde belirlenmelidir, (b) verinin formatı doğru şekilde belirlenmelidir, (c) veri indirilip R’ çağrılır veya doğrudan R’a çağrılır. Aşağıda verilen komutlar 2.3 bölümünde tanıtılan dataWBT’nin çalışma alanınıza getirilmesini sağlar. #sanal depodan CSV oku urldosyasi=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataismi=read.csv(urldosyasi) str(dataismi) #sanal depodan Rdata oku urldosyasi2=&#39;https://github.com/burakaydin/materyaller/blob/gh-pages/ARPASS/dataWBT.Rdata?raw=true&#39; load(url(urldosyasi2)) str(dataWBT) Bu veri setleri Github Depo veya , excel dosyası olarak buradan indirilebilir. 6.1.5 R Stuido Aracılığı ile Veri Çağırma Veri dosyanız bilgisayarınızda farklı bir klasörde (çalışma klasörü dışında) ise veya tıkla-bırak yöntemini (point-click) tercih ederseniz R Studio’nun sağ üst köşesinde Environment sekmesi altında yer alan import dataset ile veri çağırabilirsiniz. Bu basamaklar Video 6 ile gösterilmiştir. Figure 6.2: R Studio ile CSV Oku 6.2 Basit Veri İşlemleri Genellikle çözümleme basamağına geçilmeden önce verinin işlenmesi gerekir. Bu bölüm (a) değişkenleri yeniden kodlama, (b) alt küme seçme, (c) yeni değişken oluşturma, (d) veri çerçevesini değiştirme, (e) değişken türünü değiştirme ve (f) veri silme işlemlerini kısaca özetler. 6.2.1 Değişkenleri yeniden kodlama Bir satırı, bir sütünü veya bir satır/sütün keşiminde yer alan tek bir elemanı değiştirmek mümkündür. Değişkenlerin yeni isimler vermek mümkündür. plyr (Wickham 2011) paketi değişkenleri yeniden kodlamada yardımcı olabilir. # sanal depodan CSV oku urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya) #URL adresini sil rm(urldosya) # 151. satır 16. sütunu değiştir ve 30 yap veriseti1[151,16]=30 # aynı işlem satır ismi ve sütün ismi verilerek yapılabilir. # id numarası 67034022 olan satırın yaş değerini 32 yap. veriseti1[veriseti1$id==67034022,&quot;age&quot;]=32 # tekrar kodlama # Veri setinde yer alan treatment değişkeni 0 ve 1 olarak girilmiştir. # 1leri &quot;trt&quot; ve 2leri &quot;cnt&quot; yapmak için veriseti1[veriseti1$treatment==1,&quot;treatment&quot;]=&quot;trt&quot; veriseti1[veriseti1$treatment==2,&quot;treatment&quot;]=&quot;cnt&quot; # ifelse fonksiyonu benzer şekilde çalışır # &quot;wage01&quot; değişkeninde &quot;wage01&quot; &quot;Yes&quot; ise 0.5, değil ise -0.5 olarak kodlayalım veriseti1$wage01=ifelse(veriseti1$wage01==&quot;Yes&quot;,0.5,-0.5) # plyr paketi kullanarak require(plyr) # pension01yeni değişkeni pension01 değişkeni üzeriden tanımlanmıştır # eski değerler olan Yes ve No yerine 1 ve 0 kodlayalım veriseti1$pension01yeni &lt;- mapvalues(veriseti1$pension01, from=c(&quot;Yes&quot;,&quot;No&quot;),to=c(&quot;1&quot;,&quot;0&quot;)) #bir değişkene yeni isim verelim #4. ve 5. değişkenlere yeni isim verelim colnames(veriseti1)[4]=&quot;kurs&quot; colnames(veriseti1)[5]=&quot;bolge&quot; #isim verme işlemini tek sıra kod ile yapalım colnames(veriseti1)[c(17,21)]=c(&quot;Tgelir&quot;,&quot;maas1&quot;) #plyr paketini kullanalım gen_att değişkenine toplumsalCinsiyet ismi verelim veriseti1 &lt;- rename(veriseti1,c(&#39;gen_att&#39;=&#39;toplumsalCinsiyet&#39;)) #kontrol etmek için head(veriseti) veya summary(veriseti) kullanılabilir # veriseti1&#39;i çalışma alanından sil rm(veriseti1) 6.2.2 Alt Küme Seçme (Subsetting) R ile alt küme oluşturmak oldukça kolaydır. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya) # URL adresi sil rm(urldosya) # sadece İstanbul&#39;u seç istDAT=veriseti1[veriseti1$city==&quot;ISTANBUL&quot;,] # sadece İstanbul&#39;dan ilk sekiz katılımcıyı seç istDAT18=veriseti1[veriseti1$city==&quot;ISTANBUL&quot;,1:8] # sadece İstanbul&#39;dan gen_att puanı 2den yüksek olanları seç istDATGAT2=veriseti1[veriseti1$city==&quot;ISTANBUL&quot; | veriseti1$gen_att &gt;2 ,] # subset fonksiyonu # sadece İstanbul&#39;dan gen_att puanı 2den yüksek olan ilk sekiz katılımcıyı seç istDATGAT2B=subset(veriseti1, city==&quot;ISTANBUL&quot; | veriseti1$gen_att &gt;2, select=1:8) #item 1 değeri 1,2 ve 3 olan katılımcıları seç item1_123 &lt;- veriseti1[veriseti1$item1 %in% c(1,2,3), ] #çalışma alanını temizle rm(list=ls()) 6.2.3 Yeni Değişken Oluştur Daha önce 5 bölümünde değişken oluşturma yöntemlerine değinilmiştir. Bu bölüm hatırlatma olarak görülebilir. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya) #URL dosyası yükle rm(urldosya) # item2&#39;den 6&#39;ya kadar olan sütünları topla veriseti1$itemTOPLAM=with(veriseti1,item2+item3+item4+item5+item6) # item2&#39;den 6&#39;ya kadar olan sütünların ortalamasını al (na.rm =T önemli) veriseti1$itemAVE=with(veriseti1, rowMeans(cbind(item2,item3,item4,item5,item6),na.rm=T)) #veya rowMeans fonksiyonu veriseti1$itemAVE=rowMeans(veriseti1[,10:14],na.rm = T) # Şehirler için ortalama hesapla veriseti1$CityAVEscore =with(veriseti1, ave(itemAVE,city,FUN=function(x) mean(x, na.rm=T))) #veya veriseti1=merge(veriseti1, aggregate(itemAVE ~ city, data = veriseti1, FUN=mean, na.rm=TRUE), by = &quot;city&quot;, suffixes = c(&quot;&quot;, &quot;citymean&quot;),all=T) #veya her bir soru için şehir ortalaması hesapla veriseti1=merge(veriseti1, aggregate(cbind(item2,item3,item4,item5,item6) ~ city, data = veriseti1, FUN=mean, na.rm=TRUE), by = &quot;city&quot;, suffixes = c(&quot;&quot;, &quot;Citymean&quot;),all=T) # değişkenlerin kategorize edilmesi. Eğer item1AVE 2&#39;den küçük ise 0 aksi halde 1 veriseti1$itemAVE01=ifelse(veriseti1$itemAVE&lt;2,0,1) # 0 ile 1.8 arasına 1 ver # 1.8 ve 2.5 arasına 2 ver # 2.5 ile 5 arasına 3 ver veriseti1$itemAVE123=with(veriseti1,cut(itemAVE, breaks=c(0,1.8,2.5,5), labels = FALSE)) # cut fonksiyonu içerisinde yer alan right=T argümanına göz gezdirin # örneğin right=T ise değeri tam olarak 1.8 olan değişkenler 1 olur # right=F ise değeri tam olarak 1.8 olan değişkenler 2 olur 6.2.4 Veri Çerçevesini Değiştirme (Reshaping data) Veri çerçevesini değitirmek, uzun formattan geniş formata geçmek veya tam tersi gerekli olabilir. tidyr (Wickham 2016) yardımcı olabilir. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya) #adresi sil rm(urldosya) # genişten uzuna item 1den 6 ya kadar olan sütünları item adı altında birleştir library(tidyr) data_long = gather(veriseti1, item, score, item1:item6, factor_key=TRUE) #id&#39;ye göre diz data_long=data_long[order(data_long$id),] # uzundan genişe. data_wide = spread(data_long, item, score) ## belirlediğiniz nesneler dışında çalışma alanını temizle rm(list=setdiff(ls(),c(&quot;veriseti1&quot;))) 6.2.5 Değişken Türünü Değiştirme Sayısal girilen verileri faktöre çevirme gibi işlemler çözümleme basamağından önce gerekli olabilir. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya,stringsAsFactors = F) #URL sil rm(urldosya) #treatment değişkenini incele str(veriseti1$treatment) #sayısal veriyi faktöre çevir veriseti1$treatmentFactor=factor(veriseti1$treatment,labels=c(&quot;treatment&quot;,&quot;control&quot;)) #karakter olarak girildiğinde faktörleri sayıya çevirme veriseti1$iv1=factor(rep(c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;),length=nrow(veriseti1))) veriseti1$iv1numeric=as.numeric(levels(veriseti1$iv1))[veriseti1$iv1] #veya veriseti1$iv1numeric=as.numeric(as.character(veriseti1$iv1)) #NAleri -99&#39;a çevir veriseti1[is.na(veriseti1)]= (-99) #çalışma alanını temizle rm(list=ls()) 6.2.6 Veri Silme Bir tek hücreyi, bir satırı veya bir sütunu silmek gerekebilir. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya,stringsAsFactors = F) #URL sil rm(urldosya) #3. satır 5. sütunda yer alan hücreyi sil veriseti1[3,5]=NA #3. satırı sil veriseti1[3,]= NA #veya veriseti1=veriseti1[-3,] #course taken isimli sütunu sil veriseti1$course_taken=NULL #gösterim amaçlı veri oluştur temp=veriseti1[,1:10] # kayıp verili satırı silme (listwise) temp=na.omit(temp) #çalışma alanını temizle rm(list=ls()) 6.3 veri Kaydetme Adres belirtmediğiniz sürece kaydetme işlemi mevcut çalışma klasörünüz (working directory) içeriside tamamlanır. # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; veriseti1=read.csv(urldosya,stringsAsFactors = F) #URL sil rm(urldosya) #nesne oluştur. subset1=veriseti1[1:20,1:5] object2=mean(veriseti1$item1,na.rm = T) #çalışma klasörünüzü kontrol edin getwd() # Rdata olarak sakla save(subset1,file=&quot;subset1Rfile.Rdata&quot;) # adres vererek sakla save(object2,file=&quot;C:/Users/Desktop/object2Rfile.Rdata&quot;) # csv olarak sakla write.csv(subset1,file=&quot;subset1CSVfile.csv&quot;,row.names = F) #sps dosyası olarak sakla library(foreign) write.foreign(subset1, &quot;subset1SPSfile.txt&quot;,&quot;subset1SPSfile.sps&quot;, package=&quot;SPSS&quot;) #çalışma alanını temizle rm(list=ls()) References "],
["betimleyici-istatistikler-ve-hipotez-testi.html", " 7 Betimleyici İstatistikler ve Hipotez Testi 7.1 Betimleyici İstatistikler 7.2 Basit Grafikler 7.3 Hipotez Testi Tanıtım", " 7 Betimleyici İstatistikler ve Hipotez Testi Betimleyici istatistikler örneklemi tanımlamayı amaçlar. Bu bölüm içeriside daha önce tanıtılan dataWBT (2.3) kullanılarak (a) betimleyici istatistikler hesaplanmış (b) basit grafikler çizilmiş ve (c) hipotez testi açıklanmıştır. Bu bölümde yer alan R kodlarını kullanmak isteyen araştırmacıların bir önceki bölümü inceledikleri varsayılmıştır. Bu bölümde yer alan basamakların atlanmadan takip edildiği varsayımı da yapılmıltır. dataWBT çalışma alanınıza çağırmak için; # CSV yükle urldosya=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataWBT=read.csv(urldosya) #remove URL rm(urldosya) 7.1 Betimleyici İstatistikler Bu alt bölümde ortalama, ortanca, varyans, standart sapma, çarpıklık ve basıklık hesaplanmıştır. Örneklerde toplumsal cinsiyet algısı (gen_att) değişkeni kullanılmıştır. 7.1.1 Ortalama Eşitlik (7.1) ’de verildiği gibi, ortalama, bir değişkeni oluşturan değerlerin toplamının toplam değer sayısına bölünmesi ile hesaplanır. \\[\\begin{equation} \\bar{Y} = \\frac{1}{n} \\sum\\limits_{i=1}^n {Y_i} \\tag{7.1} \\end{equation}\\] # gen_att değişkeninin ortalamasını hesapla mean(dataWBT$gen_att,na.rm = T) ## [1] 1.940576 # birden fazla değişkenin ortalamasını hesapla # ?colMeans colMeans(dataWBT[,c(&quot;gen_att&quot;,&quot;item1&quot;)],na.rm = T) ## gen_att item1 ## 1.940576 3.451014 7.1.2 Ortanca Büyükten küçüğe veya küçükten büyüğe dizilmiş bir değişkenin orta noktasına ortanca denir. Eğer değişkenin eleman sayısı (n) tek sayı ise \\(({(n+1)/2}).\\) sırada yer alan, eğer çift sayı ise \\((n/2).\\) ve \\(((n+1)/2).\\) değerin ortalaması ortancayı verir. # Ortanca hesapla median(dataWBT$gen_att,na.rm = T) ## [1] 2 7.1.3 Varyans Varyans değişkenin ne kadar yayıldığını anlamada çok kullanılan bir ölçüdür. Eşitlik (7.2) ile hesaplanır. \\[\\begin{equation} s_Y^2 = \\frac{1}{{n - 1}}\\sum\\limits_{i = 1}^n {\\left( {Y_i - \\bar Y} \\right)^2 } \\tag{7.2} \\end{equation}\\] #varyans hesapla var(dataWBT$gen_att,na.rm = T) ## [1] 0.3638408 7.1.4 Standart Sapma Varyansın kareköküdür ve Eşitlik (7.3) ile hesaplanır. \\[\\begin{equation} s_Y = \\sqrt {\\frac{1}{{n - 1}}\\sum\\limits_{i = 1}^n {\\left( {Y_i - \\bar Y} \\right)^2 } } \\tag{7.3} \\end{equation}\\] #SS hesapla sd(dataWBT$gen_att,na.rm = T) ## [1] 0.6031922 7.1.5 Çarpıklık (Skewness) Çarpıklık değeri dağılımın şekli hakkında bilgi verir. Tamamen simetrik olan bir dağılımın çarpıklık değeri 0’dır. Dağılımın sol kuyruğu sağ kuyruğuna nazaran uzun olduğunda çarpıklık değerinin sıfırdan küçük çıkması tipiktir. Bu tür dağılımlar sola çarpık veya negatif çarpık olarak isimlendirilir. Bu tür dağılımlarda medyan ortalamadan yüksektir Dağılımın sağ kuyruğu sol kuyruğuna nazaran uzun olduğunda çarpıklık değerinin sıfırdan büyük hesaplanması tipiktir. Bu tür dağılımlar sağa çarpık veya pozitif çarpık olarak isimlendirilir. Bu tür dağılımlarda medyan ortalamadan küçüktür. Örneklem için çarpıklık formülü2 \\[\\begin{equation} \\sqrt{n}\\frac{\\sum_{i}^{n}\\left ( X_{i}-\\bar{X} \\right )^{3}} {\\left (\\sum_{i}^{n} \\left ( X_{i}-\\bar{X} \\right )^{2} \\right )^{3/2}} \\tag{7.4} \\end{equation}\\] Örneklem için çarpıklık değeri moments (Komsta and Novomestky 2015) paketinde yer alan skewness fonksiyonu ile hesaplanabilir. #çarpıklık hesapla library(moments) skewness(dataWBT$gen_att,na.rm = T) ## [1] 0.377095 NOT: Çarpıklık ve basıklık değerleri için standart hata ve sonrasında z-puanı hesaplanabilir. Hesaplanan bu z-puanı seçilen bir kritik değer ile (ör. 1.96) kıyaslanarak çarpıklık veya basıklığın istatistiksel olarak anlamlı olup olmadığı sınanabilir. Benzer şekilde normallik testleri de (ör. Shapiro-Wilk) yapılabilir. Fakat bu testler örneklem büyüklüğüne hassasstır. Bir diğer deyişle örneklem büyüdükçe çok küçük farklılıklar istatistiksel olarak anlamlı bulunabilir. Çarpıklık,basıklık veya normallik testlerinin varsayım ihlallerini tespit etmek üzere kullanılışı nispeten eskimiş yöntemlerdir. Bu testleri kullanmak yerine normallik grafik üzerinden incelenip, dirençli tahminleyicilerin (robust estimators) veya Monte Carlo simulasyon tekniklerinin çıktıları incelenebilir. 7.1.5.1 Çarpıklık örnekleri Normal bir dağılım ve çarpıklık istatistiği; Figure 7.1: Normal dagilim gösteren bir sürekli degisken Sola çarpık sürekli değişken; Figure 7.2: Sola çarpik sürekli degisken Sağa çarpık sürekli değişken; Figure 7.3: Saga çarpik sürekli degisken 7.1.6 Basıklık (Kurtosis) Basıklık değeri dağılımın şekli hakkında bilgi verir. Normal bir dağılımın Pearson basıklık değeri 3’tür. Eşitlik (7.5) basıklık değerinin hesaplanışını gösterir. \\[\\begin{equation} n\\frac{\\sum_{i}^{n}(X_i-\\bar{X})^4}{(\\sum_{i}^{n}(X_i-\\bar{X})^2)^2} \\tag{7.5} \\end{equation}\\] Eşitlik (7.5) sıfırdan küçük değerler vermez. 0 ile 3 arasında yer alan değerler genellikle düz dağılımlarda hesaplanır, örneğin tekdüzey dağılımlar. Uzun kuyruklu dağılımlarda 3’ten büyük değerler görülebilir. Alanyazında yorumu kolaylaştırmak için Eşitlik (7.5) ’ten 3 çıkarıldığı durumlar mevcuttur. Örneklem için Pearson basıklık değeri moments (Komsta and Novomestky 2015) paketinde yer alan kurtosis fonksiyonu ile hesaplanabilir. #basıklık hesapla library(moments) kurtosis(dataWBT$gen_att,na.rm = T) ## [1] 2.903905 7.1.6.1 Basıklık Örnekleri Normal bir dağılım ve basıklık ölçüsü Figure 7.4: Normal dagilim gösteren bir sürekli degisken Tekdüzey bir dağılım ve basıklık değeri Figure 7.5: Tekdüzey dagilim gösteren sürekli degisken Beta dağılımı gösteren bir sürekli değişken Figure 7.6: Beta dagilimi gösteren bir sürekli degisken 7.1.7 Betimleyici İstatisklerin Raporlanması psych (Revelle 2016), doBy (Højsgaard and Halekoh 2016) ve apaStyle (de Vreeze 2016) paketleri betimsel analizleri rapor etmede yardımcı olabilir. # psych paketi describe fonksiyonu sırasıyla; # n: gözlem sayısı (kayıp veriler hariç) # ortalama, ss, ortanca, budanmış ortalama (trim=0.05 5% budanmış) # ortanca mutlak dağılımı (median absolute deviation), # minimum, maksimum, ranj # çarpıklık ve basıklık-3 (type=2 popülasyon basıklık ve çarpıklık) # standart hata library(psych) desc1=describe(dataWBT[,c(&quot;gen_att&quot;,&quot;age&quot;)],trim = 0.05,type=3) desc1 ## vars n mean sd median trimmed mad min max range skew ## gen_att 1 5302 1.94 0.60 2 1.92 0.59 1 4 3 0.38 ## age 2 5308 27.08 7.21 25 26.62 5.93 15 60 45 0.96 ## kurtosis se ## gen_att -0.10 0.01 ## age 0.63 0.10 # kaydet write.csv(desc1,file=&quot;pscyhbetimsel.csv&quot;) #doBy # program değişkenine göre betimleyici istatistikler library(doBy) library(moments) desc2=as.matrix(summaryBy(gen_att+age~treatment, data = dataWBT, FUN = function(x) { c(n = sum(!is.na(x)), nmis=sum(is.na(x)), m = mean(x,na.rm=T), s = sd(x,na.rm=T), skw=moments::skewness(x,na.rm=T), krt=moments::kurtosis(x,na.rm=T)) } )) #yuvarlama round(desc2,2) ## treatment gen_att.n gen_att.nmis gen_att.m gen_att.s gen_att.skw ## 1 1 2736 265 1.93 0.6 0.38 ## 2 2 2566 335 1.95 0.6 0.38 ## gen_att.krt age.n age.nmis age.m age.s age.skw age.krt ## 1 2.90 2739 262 26.89 7.17 0.99 3.69 ## 2 2.91 2569 332 27.28 7.24 0.93 3.57 write.csv(round(desc2,2),file=&quot;doBydesc.csv&quot;) #apaStyle # APA formatında tablo library(apaStyle) apa.descriptives(data = dataWBT[,c(&quot;gen_att&quot;,&quot;age&quot;)], variables = c(&quot;Gender Attitude&quot;,&quot;Age&quot;), report = c(&quot;M&quot;, &quot;SD&quot;), title = &quot;APAtableGenderAge&quot;, filename = &quot;APAtableGenderAge.docx&quot;, note = NULL, position = &quot;lower&quot;, merge = FALSE, landscape = FALSE, save = TRUE) ## ## Word document succesfully generated in: C:/Users/Burak/Desktop/github/SARP #apaStyle paketi hata veriyorsa; #https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/ #Sys.setenv(JAVA_HOME=&#39;C:\\\\Program Files\\\\Java\\\\jre1.8.0_111&#39;) Figure 7.7: APA Tablo.docx 7.1.7.1 Betimsel İstatistik Rapor Örneği Toplumsal cinsiyet algısı puanları 5302 katılımcı için 1 ve 4 arasında değişmiştir, ortanca 2, ortalama 1.94 ve standart sapma 0.6 olarak hesaplanmıştır. Puanların dağılımı örneklem bazında 0.38 çarpıklık ve -0.1 basıklık değerine sahiptir. 7.2 Basit Grafikler R programı ile basit olmayan grafikler çizilebilir. Popüler olan grafik oluşturma yöntemlerinden dört tanesi, base(R Core Team 2016b), lattice(Sarkar 2016), ggplot2(Wickham and Chang 2016) ve plotrixtir(Lemon et al. 2016). Bu materyal ggplot2 kullanmıştır. Bir ggplot fonksiyonunda argüman sayısı oldukça fazladır, bu sayede kullanıcılar grafiğin her noktasında değişiklik yapabilirler. 7.2.1 Histogram Dikdörtgenlerden oluşan histogram grafikleri değişken içerisinde yer alan değerlerin frekanslarına göre oluşturulur. 7.2.1.1 Tek değişken için histogram Dağılım hakkında bilgi sahibi olmak için kullanışlıdır. library(ggplot2) ggplot(dataWBT, aes(x = gen_att)) + geom_histogram(binwidth = 0.2)+ theme_bw()+labs(x = &quot;Toplumsal Cinsiyet Algısı &quot;)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 7.8: Toplumsal Cinsiyet Algisi Puan Dagilimi 7.2.1.2 Tek değişken tek faktör histogram Gruplara dayalı farklılıkları görmek için kullanışlı dataWBT$HEF=droplevels(factor(dataWBT$higher_ed, levels = c(0,1), labels = c(&quot;Lise ve altı&quot;, &quot;Üniversite&quot;))) ggplot(dataWBT, aes(x = gen_att, fill=HEF,drop=T)) + geom_histogram(breaks=seq(1, 4, by =0.2),alpha=.5,col=&quot;black&quot;)+ theme_bw()+labs(x = &quot;Toplumsal Cinsiyet Algısı&quot;,fill=&#39;Yüksek Öğretim Durumu&#39;)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) dataWBT2=na.omit(dataWBT[,c(&quot;gen_att&quot;,&quot;HEF&quot;)]) ggplot(dataWBT2, aes(x = gen_att)) + geom_histogram(breaks=seq(1, 4, by =0.2),alpha=.5,col=&quot;black&quot;)+ theme_bw()+labs(x = &quot;Toplumsal Cinsiyet Algısı&quot;)+ facet_wrap(~ HEF)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 7.9: Egitime Göre Toplumsal Cinsiyet Algisi library(ggplot2) ggplot(dataWBT, aes(x = gen_att)) + geom_histogram(binwidth = 0.2)+ theme_bw()+ facet_wrap(~city, ncol = 8) 7.2.1.3 Tek değişken iki faktör histogram Useful for two way interactions dataWBT2=na.omit(dataWBT[,c(&quot;gen_att&quot;,&quot;HEF&quot;,&quot;gender&quot;)]) ggplot(dataWBT2, aes(x = gen_att,fill=gender)) +labs(fill=&#39;Gender&#39;)+ geom_histogram(binwidth = 0.2,alpha=.5)+ theme_bw()+ facet_grid(~HEF) 7.2.1.4 Tek değişken üç faktör histogram Etkileşim (interaction) açıklamada kullanışlı dataWBT$Condition=droplevels(factor(dataWBT$treatment, levels = c(1,2), labels = c(&quot;treatment&quot;, &quot;control&quot;))) dataWBT2=na.omit(dataWBT[,c(&quot;gen_att&quot;,&quot;HEF&quot;,&quot;gender&quot;,&quot;Condition&quot;)]) ggplot(dataWBT2, aes(x = gen_att,fill=gender)) +labs(fill=&#39;Gender&#39;)+ geom_histogram(binwidth = 0.2,alpha=.5)+ theme_bw()+ facet_grid(~HEF+Condition) 7.3 Hipotez Testi Tanıtım Cambridge sözlüğü evren (popülasyon) tanımı olarak “aynı ülke, aynı alan veya aynı yerde yaşayan insan veya canlı grubu” cümlesini kullanır. Sosyal bilimlerde evren genellikle “belli bir gruba ait bütün insanlar” olarak belirlenir. Örneğin sekiz yaşındaki tüm öğrenciler, belli bir ülkede bulunan sekiz yaşındaki tüm öğrenciler, 8 yaşında disleksi teşhisi konulan öğrenciler. Sosyal bilimciler araştırma soruları doğrultusunda ilgili evreni tanımlar. Evrende yer alan bireylerin (unit) gözlenlenebilen karakteristik özellikleri değişkenleri oluşturur. Diğer bir ifade ile değişkene ait popülasyon tanımlanabilir. Bölüm 5.2.3 ’de değişken türleri açıklanmıştır. Evren değişkene ait bütün değerleri kapsar, bu değerlere ait bir ranj ve görülme olasılığı (probability of occurence) vardır. Yoğunluk (probability, sürekli değişken için) ve çoğunluk (mass, sürekli olmayan değişken için) fonksiyonları görülme olasılıklarını formüle etmek için kullanışlıdır. Dağılım hakkında yapılacak geçerli bir varsayım ile örneklemden evrene genellemeler yapılabilir. Seçkisiz seçilen bir örneklem ile ulaşılan değişken evrende sahip olduğu bütün değerleri içermeyebilir. Fakat, özellikle gözlem sayısı küçük değil ise, seçkisiz seçme işleminde sistematik bir yanlılık görülmeyeceği düşünüldüğünde, örneklemin evrene benzer özellikler göstermesi beklenir.Bu bilgi kullanılarak evrene ait bir parametre örneklemden yola çıkarak tahmin edilebilir. Bu işlem genellikle bir model sayesinde olur. Modelin veriye gösterdiği uyum araştırmacı tarafından değerlendirilir. Hipotez testleri kullanılan bir model sonrasında araştırma soruları ile ilgili karara varma sürecidir. 7.3.1 Örnekleme Dağılım (Sampling Distribution) Seçkisiz bir örneklem için hesaplanmış bir istatistik aslında bir değişkendir ve belli bir dağılıma sahiptir. Örnekleme dağılım konusununu açıklamak için en çok kullanılan istatistik aritmetik ortalamadır. Merkezi limit teoremine göre basit seçkisiz örneklem kullanıldığında3 değişkenin evrende gösterdiği dağılımdan bağımsız olarak, o değişkene ait örneklem ortalamalarının dağılımı yaklaşık olarak normaldir. Örneklem büyüdükçe ; \\[\\begin{equation} \\bar X_n \\sim N(\\mu, \\frac{\\sigma^2}{n}). \\tag{7.6} \\end{equation}\\] Eğer evren bazında dağılım normal ise (7.6) küçük örneklemler için de doğrudur. Ortalamanın örnekleme dağılımına ait standart sapma ortalamanın standart hatası olarak isimlendirilir ve istatistiksel çıkarımlarda kullanılır. Eşitlik (7.6) içinde yer alan \\(\\mu\\) ve \\(\\sigma^2\\) bilinmezdir. Fakat bu eşitlik örnekleme ait ortalamanın evrene ait ortalamayı ne derecede kestirebileceğini anlamada önemlidir. Örneğin bir araştırmacının basit seçkisiz yöntemle 10 kişilik bir örneklem seçtiğini düşünelim. Araştırmacının bilemeceği parametrelerin ise \\(\\mu=100\\) ve \\(\\sigma=15\\) olduğunu düşünelim. Bu durumda örnekleme dağılım için standart sapma \\((15⁄\\sqrt{10})=4.74\\) olarak bulunur. %95 olasılıkla araştımacının 10 kişilik örneklem ile ulaşacağı aritmetik ortalama 90.7 ve 109.3 arasında olacaktır. Bu oldukça geniş bir aralıktır. Fakat araştırmacı 10 kişi yerine 100 kişiyi aynı örneklem ile seçseydi ulaşacağı örneklem ortalaması %95 olasılıkla 97.1 ve 102.9 olacaktır. Bu noktada önem taşıyan konu, örneklemden gelen bilgilerle evrene ait parametrelerin hangi tahminleme yöntemleri (estimator) ile yansız, tutarlı ve keskin (unbiased, consistent and efficient) olarak kestirebileceğidir. Örneğin \\(\\mu\\), Eşitlik (7.1) ile, \\(\\sigma^2\\) ise Eşitlik (7.2) ile yansız olarak kestirilebilir. 7.3.1.1 Yansız tahminleme ve örnneklem seçimi Eklenecek 7.3.2 Güven Aralıkları (The Confidence Intervals (CI)) Dağılım hakkında yapılacak bir varsayım, örneklemden gelen bilgi ve uygun bir tahminleyici (estimator to produce a point estimate) kullanılarak güven aralıkları oluşturulabilir. Bir güven aralığı evren parametresinin muhtemelen hangi aralıkta olduğunu gösterir. Fakat bu evren parametresinin bu aralıkta kesinlikle yer aldığı anlamına gelmez. Örnekleme ait aritmetik ortalamadan yola çıkarak evren parametresi için güven aralığı hesaplamak oldukça basittir.Değişkene ait dağılımın normal olduğu varsayıldığında, ortalamanın örnekleme dağılımı da normaldir ve örnekleme ait ortalama yansız bir tahmindir. Normal dağılım bilindik özellikleri vardır, yoğunluk fonksiyonu değerlerin %95’inin ortalamadan 1.96 standart sapma aşağıda ve yukarıda olduğunu gösterir. Normal dağılımın bu özelliği grafik 7.10 ile gösterilmiştir. Mavi ile işaretlenen bölgeden bir gözlem yapma olasılığı %5tir. Benzer şekilde, mavi veya sarı ile işaretlenen bölgeden gözlem yapma olasılığı da %10’dur. Gri bölge (\\(\\pm 1\\)) yoğunluğun yaklaşık olarak %68’ini kapsar.Bu bilgi kullanışlıdır. Örneklem için hesaplanan ortalama ve varyans \\(\\mu\\) için güven aralığı hesaplamada kullanılabilir. Figure 7.10: The z distribution 7.3.2.1 Güven Aralığı Örneği Toplumsal Cinsiyet Algısına ait ortalama ve güven aralığı hesaplamaları # gözlem sayısı, n GA_n=sum(!is.na(dataWBT$gen_att)) #ortalama GA_m=mean(dataWBT$gen_att,na.rm = T) #ss GA_s=sd(dataWBT$gen_att,na.rm = T) #95% güven aralığı alt=GA_m - 1.96 * (GA_s/sqrt(GA_n)) alt ## [1] 1.924339 ust=GA_m + 1.96 * (GA_s/sqrt(GA_n)) ust ## [1] 1.956812 #veya GA_m +c(-1,1)*1.96 * (GA_s/sqrt(GA_n)) ## [1] 1.924339 1.956812 #1.96 için qnorm(0.975) 7.3.2.2 Ortalama için güven aralığı raporlama 5302 katılımcı için Toplumsal Cinsiyet Algısı puanlarına ait ortalama 1.94 (%95 GA [1.92-1.96]), standart sapma 0.60 bulunmuştur. 7.3.3 Boş Hipotez Hipotez testinin amacı evren hakkında öne sürülen iki hipotezden hangisinin örneklem tarafından desteklendiğine karar vermektir. Bir hipotez testi beş basamaktan oluşur; Boş hipotezin4 belirlenmesi (örneğin \\(\\mu=0\\)) Alternatif hipotezin belirlenmesi. (örneğin \\(\\mu \\neq 0\\)) Test istatistiğinin seçilmesi Test istatistiği ve belirlenen kritik değeri karşılaştırarak karar verilmesi. Eğer hesaplanan test istatistiği kritik değerden daha yüksekse boş hipotezin ret edilmesi (kritik değer alternatif hipoteze göre değişir). Sonucun açıklanması. Araştırma sorusuna yanıt vermek üzere kararın ifade edilmesi. Boş hipotez (\\(H_0\\)) ve alternatif hipotez (\\(H_1\\)) araştırma sorusunu cevaplamak üzere belirlenir. İstatistiksel kanıtlar boş hipotezini kabul veya terketmek için kullanılır. Boş hipotezi kabul etmek veya terketmek bir karardır, teorik istatistik açısından bu karara yönelik oluşabilecek durumlar şunlardır; Gerçekte Durum Karar Sonuç \\(H_0\\) Kabul \\(H_0\\) Doğru Karar \\(H_0\\) Red \\(H_0\\) Yanlış Karar (Tip I hata,\\(\\alpha\\)) \\(H_1\\) Red \\(H_0\\) Doğru Karar \\(H_1\\) Kabul \\(H_0\\) Yanlış Karar (Tip II hata, \\(\\beta\\)) Tip-I hata: Gerçekte doğru olduğu halde boş hipotezin terkedilmesi durumudur. Alfa , \\(\\alpha\\), boş hipotezin gerçekte doğru olduğu halde red edilme olasılığıdır. Hipotez testi sürecinde önemli olan noktalardan biri \\(\\alpha\\)’nın yeterince küçük olması gerektiğidir. Sosyal bilimlerde sıklıkla \\(\\alpha=.05\\) kullanılır. Tip-II hata: Gerçekte yanlış olan bir boş hipotezin terkedilememisidir. Beta, \\(\\beta\\), gerçekte yanlış olan bir boş hipotezi kabul etme olasılığıdır. 7.3.4 z-puanı ve z-testi z-puanı için genel formül; \\[z_X=\\frac{X-\\bar{X}}{s_X}\\] Hesaplanan bu z değişkeni 0 ortalamaya ve 1 standart sapmaya sahiptir. Eğer X normal dağılım gösteriyorsa z de normal dağılım gösterir. # z puanı hesapla GA_m=mean(dataWBT$gen_att,na.rm = T) GA_s=sd(dataWBT$gen_att,na.rm = T) z_GA=(dataWBT$gen_att-GA_m)/GA_s #veya z_GA=scale(dataWBT$gen_att, center=T, scale=T) # scale fonksiyonu ile birden fazla değisken için z hesaplanabilir. # center=T her X puanından ortalamayı çıkarır # scale=T farkı standart sapmaya böler # scale(dataWBT$gen_att, center=3, scale=2)her değerden 3 çıkarıp 2&#39;ye böler. Ortalama için z-istatistiği hesaplamak kolaydır; \\[ z=\\frac{\\bar{X}-\\mu_{hipotez}}{Standart Hata} = \\frac{\\bar{X}-\\mu_{hipotez}}{\\sigma_X/\\sqrt{n}}\\] Hesaplanan bu z istatistiği bir z dağılımı kullanılarak yorumlanabilir (Figür 7.10); Eğer alternatif hipotez, gözlemlenen ortalamanın, hipotez değerinden küçük olacağını belirtiyorsa, hesaplanan z istatistiği \\(z_{alpha}\\) veya \\(-z_{(1-alpha)}\\) ile kıyaslanır. Eğer hesaplanan z , \\(z_{alpha}\\)’ya eşit veya küçük ise boş hipotez terkedilir. Eğer alternatif hipotez, gözlemlenen ortalamanın, hipotez değerinden farklı olacağını belirtiyorsa, hesaplanan z istatistiğinin mutlak değeri \\(z_{1-(alpha/2)}\\) ile kıyaslanır. Eğer mutlak z , \\(z_{1-(alpha/2)}\\)’ya eşit veya büyük ise boş hipotez terkedilir. Eğer alternatif hipotez, gözlemlenen ortalamanın, hipotez değerinden büyük olacağını belirtiyorsa, hesaplanan z istatistiği \\(z_{1-alpha}\\) ile kıyaslanır. Eğer hesaplanan z , \\(z_{1-(alpha)}\\)’ya eşit veya büyük ise boş hipotez terkedilir. Burada dikkat edilmesi gereken nokta a ve c senaryolarında (yönlü alternatif) kullanılan kritik değerin b senaryosunda (yönsüz alternatif) kullanılan kritik değerden farklı oluşudur. Araştırmacılar alternatif hipotezlerinin yönlü veya yönsüz oluşunu savunabilmelidir. 7.3.4.1 z testi örnek-1 (yönsüz) Boş hipotez \\(H_0: \\mu_{Cinsiyet Algisi} = 2\\) ve alternatif hipotez \\(H_1: \\mu_{Cinsiyet Algisi} \\neq 2\\) ve \\(\\alpha=0.05\\); # n GA_n=sum(!is.na(dataWBT$gen_att)) #ortalama GA_m=mean(dataWBT$gen_att,na.rm = T) #ss GA_s=sd(dataWBT$gen_att,na.rm = T) # boş hipotez mu_hyp=2 # z istatistiği (GA_m-mu_hyp)/(GA_s/sqrt(GA_n)) ## [1] -7.17343 #alpha=0.05 ve yönsüz alternatif için kritik değer qnorm(1-(0.05/2)) ## [1] 1.959964 5302 katılımcıya ait Toplumsal Cinsiyet Algısı puanları için ortalama 1.94 ve standart sampma 0.6 olarak hesaplanmıştır. Tek örneklem için hesaplanan z testi, gözlemlenen ortalamanın, hipotez ile öne sürülen 2’den 7.17 standart hata daha düşük olduğunu göstermiştir. Kritik değer olarak 1.96 (\\(z_{1-(0.05/2)}\\)) seçildiğinde ve gözlemlenen ortalama ve hipotez ile öne sürülen ortalama arasındaki farkın istatistiksel olarak anlamlı olduğu kararı verilmiştir. 7.3.4.2 z testi örnek-2 (yönlü) Bu örnekte Toplumsal Cinsiyet Algısı değişkeninin evren bazında ortalaması 1.9 ve standart sapması 0.75 olarak varsayılmıştır. Eğer evren bazında standart sapma biliniyorsa istatistik hesaplarken kullanılmalıdır. \\(H_0: \\mu_{Cinsiyet Algisi} = 1.9\\) ve \\(H_1: \\mu_{Cinsiyet Algisi} &gt; 1.9\\) ve \\(\\alpha=0.01\\); # boş hipotez mu_hyp=1.9 # z istatistik (GA_m-mu_hyp)/(0.75/sqrt(GA_n)) ## [1] 3.939368 #yönlü alternatif ve alfa=.01 qnorm(1-(0.01)) ## [1] 2.326348 Kritik değer olarak 2.33 kullanıldığında (\\(z_{0.99}\\)) gözlemlenen ortalamanın hipotez ile öne sürülen ortalamadan büyük olduğu ve bu farkın istatistiksel olarak anlamlı olduğu kararına varılmıştır \\(z=3.94\\). 7.3.5 Tek örneklem t-testi Evrene ait dağılım normal olsa dahi küçük örneklemler için z dağılımı yerine t dağılımı kullanmak daha geçerlidir. bu t dağılımının serbestlik derecesi n-1’dir. 7.3.5.1 t test örnek-1 (yönsüz) Örnek için Düzce ilinde yaşadığını belirten katılımcılara ait Toplumsal Cinsiyet Algısı puanları kullanılmıştır. \\(H_0: \\mu_{Cinsiyet Algisi} = 1.94\\) ve alternatif \\(H_1: \\mu_{Cinsiyet Algisi} \\neq 1.94\\) ve \\(\\alpha=0.05\\); dataWBT_DUZCE=dataWBT[dataWBT$city==&quot;DUZCE&quot;,] #betimleyici describe(dataWBT_DUZCE[,&quot;gen_att&quot;],type=3) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 47 2.18 0.55 2 2.14 0.59 1 3.8 2.8 0.56 0.28 0.08 #t test t.test(dataWBT_DUZCE$gen_att, alternative=&quot;two.sided&quot;, mu=1.94, conf.level = 0.95) ## ## One Sample t-test ## ## data: dataWBT_DUZCE$gen_att ## t = 2.9391, df = 46, p-value = 0.005133 ## alternative hypothesis: true mean is not equal to 1.94 ## 95 percent confidence interval: ## 2.014224 2.336840 ## sample estimates: ## mean of x ## 2.175532 #kritik değer qt(.975,df=46) ## [1] 2.012896 Düzce ilinde yaşayan katılımcıların Cinsiyet Algısı puanları 1 ve 3.8 arasında değişmiştir, ortanca 2, ortalama 2.18, standart sapma 0.55, örnekleme ait dağılımın çarpıklığı 0.56 ve basıklığı 0.28 olarak hesaplanmıştır. Düzce şehrinde yaşayan katılımcılara ait Toplumsal Cinsiyet Algısı ortalaması, hipotez ile öne sürülen 1.94 değerinden farklıdır ve bu farklılık istatistiksel olarak anlamlıdır, t(46)=2.94 ve \\(t_{.975,46}=2.01\\) 7.3.5.2 t test örnek-2 \\(H_0: \\mu_{Cinsiyet Algisi} = 1.94\\) ve alternatif \\(H_1: \\mu_{Cinsiyet Algisi} \\leq 1.94\\) ve \\(\\alpha=0.05\\); #t test t.test(dataWBT_DUZCE$gen_att, alternative=&quot;less&quot;, mu=1.94, conf.level = 0.95) ## ## One Sample t-test ## ## data: dataWBT_DUZCE$gen_att ## t = 2.9391, df = 46, p-value = 0.9974 ## alternative hypothesis: true mean is less than 1.94 ## 95 percent confidence interval: ## -Inf 2.310055 ## sample estimates: ## mean of x ## 2.175532 #kritik değer qt(.05,df=46) ## [1] -1.67866 Test istatistiği t(46)=2.94 ve kritik değer \\(t_{.05,46}=-1.68\\) kullanılarak örneklemin, evrene ait ortalamanın 1.94’ten küçük olduğu hipotezini destekleyecek kanıtı içermediği kararı verilmiştir. 7.3.6 p-değeri Tek örneklem ile t testi için kullanılan t.test fonksiyonu bir p değeri rapor etmiştir. Bu p değeri hesabı, boş hipotezin ve dağılım için yapılan varsayımın doğru olduğu kabulü üzerine yapılır. Bu p-değerinin amacı araştıracıyı hesaplanan istatistiğin sıradan olup olmadığı yönünde bilgilendirmektir. Uzun yıllardır araştırmacılar hesapladıkları bu p-değerini daha önceden belirledikleri bir alfa kriteri ile kıyaslayıp, buldukları sonuçların istatistiksel olarak anlamlı olup olmadığına karar vermişlerdir. 7.3.7 p değeri örnek-1 Bir z-dağılımın geçerli olduğu ve z değerinin 1.80 hesaplandığı durum için grafik; Figure 7.11: z dagilimi ve z=1.8 Mavi alan yoğunluğun %3.6’sını gösterir, p=0.0359 1-pnorm(1.8) ## [1] 0.03593032 Bu p değeri yönlü bir alternatif hipotez için hesaplanmıştır. Yönsüz alternatif için geçerli değildir. Yönsüz alternatif için ; Figure 7.12: z dagilimi ve |z|)=1.8 Mavi alan yoğunluğun %7.2’sini gösterir, p=0.0719; 2*(1-pnorm(1.8)) ## [1] 0.07186064 7.3.8 İstatiksel Güç İstatistiksel güç, gerçekte yanlış olan bir boş hipotezi terketme olasılığıdır ve \\((1-\\beta) &#39;ya\\) eşittir. Bu olasılık istatistiksel sınamalar yapıldıktan önce (a-priori) veya sonra (post-hoc) hesaplanabilir, fakat sınama sonrasında yapılan güç analizi genellikle işlevsizdir. Sınama yapılmadan önce, daha doğrusu veriler toplanmadan önce yapılacak bir güç hesabı ile çalışma tasarısı gözden geçirebilir, yeniden düzenlenebilir ve örneklem sayısı belirlenebilir. Amerika’da bir çok proje başvurusu istatistiksel güç analizlerini mecbur tutar. İstatisksel gücü açıklamak için R ile çizilen grafik ve kod5; x &lt;- seq(-4, 8, 0.02) zdat &lt;- data.frame(x = x, y1 = dnorm(x, 0, 1), y2 = dnorm(x, 2.5, 1)) ggplot(zdat, aes(x = x)) + geom_line(aes(y = y1), size=2) + geom_line(aes(y = y2), color=&#39;red&#39;,size=2) + geom_vline(xintercept = c(0,2.5), color=&quot;black&quot;, linetype = &quot;longdash&quot;)+ geom_vline(xintercept = qnorm(1 - 0.05))+ scale_x_continuous(breaks = c(-4,0,1.65,2.5,4))+ annotate(&quot;text&quot;, label=&quot;beta&quot; , x=1.1, y=0.05, parse=T, fontface =2, size=6)+ annotate(&quot;text&quot;, label=&quot;alpha&quot;, x=2 , y=0.02, parse=T, fontface =2, size=6)+ annotate(&quot;text&quot;, label=&quot;1-~beta&quot;, x=3.3, y=0.1, parse=T, fontface =2,size=6)+ geom_area(aes(y=y1, x = ifelse(x &gt; qnorm(.95), x, NA)), fill = &#39;blue&#39; , alpha=0.25) + geom_area(aes(y=y2, x = ifelse(x &gt; qnorm(.95), x, NA)), fill = &#39;green&#39; , alpha=0.25) + geom_area(aes(y=y2, x = ifelse(x &lt; qnorm(.95), x, NA)), fill = &#39;yellow&#39;, alpha=0.25) + xlab(&quot;z&quot;) + ylab(&quot;dnorm(z)&quot;) + theme_bw() Figure 7.13: z dagilimi ile istatistiksel güç \\(H_0:\\mu=0\\) boş hipotezini doğru kabul eden bir z dağılımı siyah çizgiler ile gösterilmiştir, bu dağılımın ortalaması sıfırdır ve kesik çizgiler ile gösterilmiştir. Kırmızı çizgiler ile gösterilen dağılım (a) boş hipotezin yanlış olduğu ve (b) evrene ait ortalama ve standard sapma ile hesaplanan z-istatistiğinin \\(((\\mu-\\mu_{hypothesis} )⁄(\\sigma⁄\\sqrt{n})=2.5)\\) olduğu varsayımı ile çizilmiştir. Bu görsel yönlü bir alternatif hipotez ve alfa=0.05, dolayısıyla kritik değer \\(z_{0.95}=1.65\\) için geçerlidir. Mavi alan \\(\\alpha\\)’yı, sarı alan \\(\\beta\\)’yı ve yeşil alan istatistiksel gücü yansıtır. Bu görselde istatistiksel güç .804’tür. 1-pnorm(qnorm(0.95),mean=2.5) ## [1] 0.8037649 Figüre6 7.13 , istatistiksel güç hesaplamak için iki farklı dağılımın, bir alfa değerinin ve bir test istatistiğinin olması gerektiğini gösterir. Bu bilinenler ile istatistiksel güç hesaplanabilir. Burda önemli olan detay bir test istatistiğinin kendi bileşenleri olduğudur, genellikle bu bileşenler bir bölünen ve bir bölendir. z testi için bölünen , hipotez ile öne sürülen değer ile gözlemlenen değer arasındaki fark, bölen ise ortalamanın standart hatasıdır (\\(\\sigma/\\sqrt(n)\\)). Eğer istatistiksel güç sabit tutulursa (örneğin .8) eşitlik seçilen bir bilinmeyene göre çözülebilir. Genellikle de seçilen bilinmeyen örneklem sayısıdır, n. İstatistiksel güç ilerleyen bölümlerde tekrar değinilmiştir. Test istatistikleri, parametre kestirimleri, standart hatalar, dağılımsal varsayımlar tasarlanan araştırmaya göre değişecektir. Tek örneklem için t testi düşünüldüğünde power.t.test fonksiyonu işeyarardır. #power.t.test power.t.test(delta=.1, sd=.6,sig.level=0.05, power=0.9, type=&quot;one.sample&quot;, alternative=&quot;one.sided&quot;) ## ## One-sample t test power calculation ## ## n = 309.6563 ## delta = 0.1 ## sd = 0.6 ## sig.level = 0.05 ## power = 0.9 ## alternative = one.sided Bu örnek, belirlenmiş bir ortalama fark 0.1, standart sapma 0.6, alfa 0.05, yönlü alternatif ve istenilen güç 0.9 için örneklemin 310 olması gerektiğini gösterir. Bir diğer ifade ile, araştırmacı 310 kişiden gelen bir veride, ortalama fark 0.1 , standart sapme 0.6 tespıt eder ve alfa 0.05 ile yönlü bir test kullanırsa boş hipotezi (\\(H_0:\\mu=0\\)) terketme olasılığı 0.90’dır. 7.3.9 z ve t dağılımları geçerli değil ise Bilinenlerden (örneklem) bilinmeyenlere (evren) genelleme varsayımların yapılmasını gerektirir. Bir test istatistiğine ait örnekleme dağılımın, belli bir örneklem sayısında, belirli bir varsayımın ihlal edilmesi ile büyük ölçüde değişmemesi durumu direnç (robustness) olarak isimlendirilir (Verzani (2014)). Burda dikkat edilmesi gereken, bir test istatitiğinin bir varsayım ihlaline dirençli iken başka bir varsayım ihlaline dirençsiz olabileceğidir. Ayrıca, bir varsayım ihlaline dirençli olan bir test istatistiği, ikinci bir varsayım ihlalinin de yaşanması durumunda direncini yitirebilir. Bir test istatistiği dirençli olduğu için kullanılması şart değildir çünkü aynı şartlar altında daha iyi çalışan bir başka test istatistiği olabilir. z istatistiği, örneklem 30’dan büyük ise normallik varsayımının ihlallerine karşı dirençlidir(Field, Miles, and Field (2012), page 198). Örnekleme dağılımın z dağılımına yakınlığını etkileyen bir faktör diğer faktörde örneklemin nasıl bir dağılım gösterdiğidir. Ayrıca, evrene ait dağılımın normal olduğu varsayımı ile küçük örneklemler için t dağılımı geçerlidir. Tek örneklem ile aritmetik ortalama için yapılacak dirençli istatistikler detaylı olarak Wilcox (2012) tarafından verilmiştir. Verilen R kodu bootstrap-t metodu içim %95 güven aralığı hesaplar (Wilcox (2012), page 117). #ikinci tür bootstrap t metodu # Düzce katılımcılarını seç dataWBT_DUZCE=na.omit(dataWBT[dataWBT$city==&quot;DUZCE&quot;,c(&quot;id&quot;,&quot;gen_att&quot;)]) # normallik varsayımı ve t test kullanarak # evren ortalamasının 1.94 olup olmadığını sına t.test(dataWBT_DUZCE$gen_att,mu=1.94,conf.level = 0.95) ## ## One Sample t-test ## ## data: dataWBT_DUZCE$gen_att ## t = 2.9391, df = 46, p-value = 0.005133 ## alternative hypothesis: true mean is not equal to 1.94 ## 95 percent confidence interval: ## 2.014224 2.336840 ## sample estimates: ## mean of x ## 2.175532 # bootstrap ile 95% GA (normallik varsayımı yok) set.seed(04012017) B=5000 # bootstrap sayısı alpha=0.05 # alfa #x değişken # xBAR gözlemlenen ortalama tstar=function(x,xBAR) sqrt(length(x))*abs(mean(x)-xBAR)/sd(x) output=c() for (i in 1:B){ output[i]=tstar(sample(dataWBT_DUZCE$gen_att, replace=T, size=length(dataWBT_DUZCE$gen_att)), xBAR=mean(dataWBT_DUZCE$gen_att)) } output=sort(output) Tc=output[as.integer(B*(1-alpha))] #bootstrap GA mean(dataWBT_DUZCE$gen_att)+c(-1,1)*(Tc*sd(dataWBT_DUZCE$gen_att)/sqrt(length(dataWBT_DUZCE$gen_att))) ## [1] 2.011540 2.339524 7.3.9.1 Raporlama Düzce ilinden 47 katılımcının verdiği yanıtlar ile hesaplanan Toplumsal Cinsiyet Algısı puanları 1 ve 3.8 arasında değişmiş, ortancası 2, ortalaması 2.18, standart sapması 0.55 bulunmuştur. Puanların dağılımına ait çarpıklık değeri 0.56, basıklık değeri 0.28 olarak hesaplanmıştır. Kritik değer olarak 2.01 (\\(t_{.975,46}\\)) kullanıldığında, tek örneklem t testi anlamlı bir farklılığa işaret etmiştir,t(46)=2.94, bu şehirdeki katılımcıların puanları hipotez ile öne sürülen 1.94 değerinden farklıdır. Normallik varsayımı yapıldığında %95 güven aralığı [2.01,2.34] olarak bulunmuştur. Normallik varsayımı yapılmadığıda 5000 tekrarlı bootstrap metodu ile hesaplanan güven aralığı [2.01,2.34] olarak bulunmuştur. References "],
["iki-ortalamann-karslastrlmas-t-testi.html", " 8 İki Ortalamanın Karşılaştırılması, t-testi 8.1 Bağımsız gruplar t-test (The Independent Groups t-test) 8.2 Bağlı gruplar t-testi (Within-subjects t-test) 8.3 Yaygın Tasarılar", " 8 İki Ortalamanın Karşılaştırılması, t-testi Bölüm 7.3.1 örnekleme dağılım (sampling distribution) konusunun ana hatlarını tek bir aritmetik ortalama üzerinden ele almıştır. Eğer iki farklı aritmetik ortalama kıyaslanmak isteniyorsa t testi kullanılabilir, bu prosedür aritmetik ortalamaların örnekleme dağılımı üzerine inşaa edilmiştir. \\(\\bar{Y_1}-\\bar{Y_2}\\) \\((\\mu_{\\bar{Y_1}-\\bar{Y_2}})\\) sonucunun örnekleme dağılım ortalaması daima \\(\\mu_1 - \\mu_2\\) ’dir. Fakat örnekleme dağılım standart sapması \\((\\sigma_{\\bar{Y_1}-\\bar{Y_2}})\\) araştırmanın tasarısına göre değişir. Örnek Bir cerrahın yaraların iyileşmesi konusunda araştırma yaptığını düşünelim. Cerrahın kapanan bir yaradan sonra gerilme direncini araştırdığını, yara bandı ve dikiş atma tedavisinin arasında bir fark olup olmadığını araştırdığını varsayalım. Bu çalışmada tek bir faktör vardır, yara kapatma yöntemi ve bu faktöre ait iki alt sınıf vardır, yara bandı ve dikiş. Bu araştırmayı iki farklı şekilde tasarlamak mümkündür. Bağlı gözlemler (within-subjects) 10 tavşanın her birinin sırtına (omurganın sağına ve soluna) 2 kesik oluşturulur. 2 kesikten bir tanesi yeni geliştirilen bir yara bandı ile diğeri dikiş ile kapatılır, hangi kapatma yönteminin hangi yarayı kapatacağı rassal (random) seçilmelidir. Bu tasarı bağlı-gözlemler olarak isimlendirilmiştir çünkü faktöre ait iki alt sınıf aynı tavşan üzerinde gözlemlenmiştir. Bağlı olmayan gözlemler (between-subjects) 20 tavşan rassal olarak 2 gruba ayrılır, birinci grupta yer alan tavşanların yaraları bant ile, ikinci grupta yer alan tavşanların yaraları ise dikiş ile kapatılır. Yaralar omurganın sağ veya sol tarafında rassal olarak açılmalıdır. Bu tasarı bağlı olmayan gözlemler olarak isimlendirilmiştir çünkü faktöre ait alt sınıflar farklı tavşanlar üzerinde gözlemlenmiştir ve bu tavşanların herhangi bir şekilde eşlenmiş değillerdir. Örneğin aynı anneden gelen iki tavşan rassal olarak gruplara atansa idi gözlemler bağlı olurdu. Her iki yara kapatma yönteminden sonra yapılacak gerilme direnci ölçümlerinin evren bazında bir ortalaması ve standart sapması olduğu aşikardır. Konuyu açıklama amaçlı, yara bandı yönteminden sonra yapılan gerilme direnci ölçümlerine ait ortalamanın ve standart sapmanın bağlı gözlem veya bağlı olmayan gözlem tasarılarında aynı olduğunu düşünelim. Parametres Bant Dikiş Ortalama \\(\\mu_B\\) \\(\\mu_D\\) Standart Sapma \\(\\sigma_B\\) \\(\\sigma_D\\) Örneklem \\(n_B\\) \\(n_D\\) Buradan itibaren \\(\\mu_B\\) yerine \\(\\mu_1\\), \\(\\mu_D\\) yerine \\(\\mu_2\\), \\(\\sigma_B\\) yerine \\(\\sigma_1\\),\\(\\sigma_D\\) yerine \\(\\sigma_2\\) kullanılmıştır. Örnekleme dağılım parametresi Bağlı olmayan gözlem Bağlı gözlem Ortalama (\\(\\mu_{\\bar{Y_1}-\\bar{Y_2}}\\)) \\(\\mu_1-\\mu_2\\) \\(\\mu_1-\\mu_2\\) Standart sapma (\\(\\sigma_{\\bar{Y_1}-\\bar{Y_2}}\\)) \\(\\sqrt{\\frac{\\sigma_1^2+\\sigma_2^2}{n}}\\) \\(\\sqrt{\\frac{\\sigma_1^2+\\sigma_2^2-2\\sigma_1 \\sigma_2 \\rho_{12}}{n}}\\) \\(\\rho_{12}\\) bağlı gözlemlerde, bant ve dikiş sonrası yapılan ölçümlerin arasındakı korelasyondur. Standart sapmadaki değişiklik \\(\\rho_{12}\\)’den kaynaklanır. Eğer bu korelasyon 0 ise iki tasarının da örneklem dağılımına ait standart sapma aynıdır. Bir araştırma tasarısında hedeflerden biri standart hatayı mümkün olduğunca küçük tutmaktır. Standart hatanın küçük olması elde edilen test istatistiğinin tahmin edilen parametreye yakın olduğu anlamına gelir. Veri çözümleme sürecinde hata varyansı (error variance) hesaplamak için bir formül seçilir. Yanlış formülün kullanılması büyük bir hatadır. Uygulamada, standart hatanın hesaplanışı tasarının bağlı mı bağsız mı olduğuna göre değişir. Tasarının yanlış sınıflandırılması, çözümleme sürecinde büyük bir hatadır. 8.1 Bağımsız gruplar t-test (The Independent Groups t-test) Uşak ilinde yaşayan katılımcıların Toplumsal Cinsiyet Algısı (TCA) puanları yüksek öğretim durumuna göre karşılaştırılmıltır. Her grup için yoğunluk grafikleri; # csv yükle urlfile=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataWBT=read.csv(urlfile) #URL sil rm(urlfile) dataWBT_USAK=dataWBT[dataWBT$city==&quot;USAK&quot;,] # factor ve droplevels fonksiyonları bölüm 5.2.4 ile verilmiştir. # yeni oluşturulan HEF (Higher Education Factor) # katılımcı lise veya altı diplomaya sahipse 0, non-college # katılımcı lise üstü diplomaya sahip ise 1, college dataWBT_USAK$HEF=droplevels(factor(dataWBT_USAK$higher_ed, levels = c(0,1), labels = c(&quot;non-college&quot;, &quot;college&quot;))) require(ggplot2) plotdata=na.omit(dataWBT_USAK[,c(&quot;gen_att&quot;,&quot;HEF&quot;)]) ggplot(plotdata, aes(x = gen_att)) + geom_histogram(aes(y = ..density..),col=&quot;black&quot;,binwidth = 0.2,alpha=0.7) + geom_density(size=2) + theme_bw()+labs(x = &quot;Gender Attitude by HEF in USAK&quot;)+ facet_wrap(~ HEF)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 8.1: Yüksek Ögretim Durumuna göre TCA puanlari 8.1.1 Bağımsız gruplar t testi için R betiği Takip edilen basamaklar; Betimsel istatistikler Test istatistiğinin hesabı \\[t=\\frac{\\bar{Y_1}-\\bar{Y_2}}{S_p \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}\\] \\[ S_p = \\sqrt{\\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2 }{n_1+n_2-2}} \\] 3. Kritik değerin hesabı \\(\\pm t_{\\alpha/2,n_1+n_2-2}\\) \\[H_0:\\mu_1-\\mu_2=0\\] \\[H_1:\\mu_1-\\mu_2 \\neq0\\] library(psych) descIDT=with(dataWBT_USAK,describeBy(gen_att, HEF,mat=T,digits = 2)) descIDT ## item group1 vars n mean sd median trimmed mad min max range ## X11 1 non-college 1 86 1.83 0.54 1.8 1.80 0.59 1 3.8 2.8 ## X12 2 college 1 51 1.64 0.61 1.6 1.54 0.59 1 3.4 2.4 ## skew kurtosis se ## X11 0.72 0.90 0.06 ## X12 1.19 1.09 0.09 # rapor etmek için #write.csv(descIDT,file=&quot;independent_t_test_desc.csv&quot;) # ss sp=sqrt((85*.543^2 + 50*.608^2)/(86+51-2)) # t-istatistik tstatistic=(1.832-1.635)/(sp*sqrt(1/86+1/51)) # alfa=0.05 kritik değer qt(.975,df=135) ## [1] 1.977692 1.963 kritik değer \\(t_{.975,135}=1.978\\)’den küçük olduğu için, \\(H_0\\) kabul edilir. \\(H_1:\\mu_1-\\mu_2 &gt; 0\\) alternatif hipotezi kurulsa idi, kritik değer \\(t_{.95,135}=1.66\\), 1.963’ten küçük olduğu için \\(H_0\\) terkedilirdi. \\(H_1:\\mu_1-\\mu_2 &lt; 0\\) alternatif hipotezi kurulsa idi, 1.963 kritik değer olan \\(t_{.05,135}=-1.66\\)’ ten küçük olmadığı için \\(H_0\\) kabul edilirdi (Burada alternatif hipotez ile örneklem arası farklılık zıt yönde). Daha kullanışlı bir R betiği; # dataWBT HEF faktörünü içermez, yukarıda HEF faktörü oluşturulmuştur. t.test(gen_att~HEF,data=dataWBT_USAK,var.equal=T, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## Two Sample t-test ## ## data: gen_att by HEF ## t = 1.9587, df = 135, p-value = 0.05221 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.001903268 0.394880924 ## sample estimates: ## mean in group non-college mean in group college ## 1.831783 1.635294 # büyüktür t.test(gen_att~HEF,data=dataWBT_USAK,var.equal=T, alternative=&quot;greater&quot;, conf.level=0.95) ## ## Two Sample t-test ## ## data: gen_att by HEF ## t = 1.9587, df = 135, p-value = 0.0261 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.03034529 Inf ## sample estimates: ## mean in group non-college mean in group college ## 1.831783 1.635294 # küçüktür t.test(gen_att~HEF,data=dataWBT_USAK,var.equal=T, alternative=&quot;less&quot;, conf.level=0.95) ## ## Two Sample t-test ## ## data: gen_att by HEF ## t = 1.9587, df = 135, p-value = 0.9739 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf 0.3626324 ## sample estimates: ## mean in group non-college mean in group college ## 1.831783 1.635294 8.1.1.1 Yönsüz alternatif için rapor örneği Uşak ilinde yaşayan katılımcılardan yüksek öğretim diplomasına sahip olan 51 kişi için TCA puanları ortalaması 1.64, standart sapması 0.61, puanlara ait dağılım çarpıklık değeri 1.19 ve basıklık değeri 1.09 olarak bulunmuştur. Aynı ilde yüksek öğretim diploması olmayan 86 katılımcının ise TCA puanları ortalaması 1.83, standart sapması 0.54, puanlara ait dağılımın çarpıklığı 0.72 ve basıklığı 0.90 olarak hesaplanmıştır.Bağımsız gruplar t-testi sonuçları, Uşak ilinde yaşayan katılımcıların Toplumsal Cinsiyet Algısı puanlarının yüksek öğretim durumuna göre değişeceği tezini desteklememiştir, t(135)=1.96, p=0.052. Puanlar arasındaki fark için %95 güven aralığı [-0.002,0.395] olarak hesaplanmıştır.7 8.1.1.2 Yönlü alternatif için rapor örneği Uşak ilinde yaşayan katılımcılardan yüksek öğretim diplomasına sahip olan 51 kişi için TCA puanları ortalaması 1.64, standart sapması 0.61, puanlara ait dağılım çarpıklık değeri 1.19 ve basıklık değeri 1.09 olarak bulunmuştur. Aynı ilde yüksek öğretim diploması olmayan 86 katılımcının ise TCA puanları ortalaması 1.83, standart sapması 0.54, puanlara ait dağılımın çarpıklığı 0.72 ve basıklığı 0.90 olarak hesaplanmıştır. Bağımsız gruplar t testi sonuçları, yüksek öğretim diploması olmayanların TCA puanları yüksek öğretimlere nazaran daha yüksektir tezini desteklemiştir, t(135)=1.96, p=0.026. Puanlar arasındaki fark için %95 güven aralığı [0.030,\\(\\infty\\)] olarak hesaplanmıştır. 8.1.2 Bağımsız gruplar t testi varsayımları Geleneksel t-testi sonuçlarının geçerliği 3 varsayımın ihlal edilmemesi ile mümkündür. Yanıtların bağımsızlığı (independence). Her gruba ait puanların dağılımı birbirinden bağımsız olmalıdır. Yanıtların bağımsızlığını tehdit eden durumlardan biri aynı grup içeresinde yer alan bireylerin birbirlerinin yanıtlarını etkilemesidir (Yantların bağımsızlığı 9.2.1.4 bölümünde daha detaylı ele alınmıştır.) Normallik. Her gruba ait puanlar normal bir dağılımdan çekilmiştir. Myers et al. (2013) grupların örneklem sayısı (n) eşit olduğunda ve toplam örneklemin 40 veya daha fazla olduğu durumlarda t test istatistiğinin normallik varsayımı ihlallerine dirençli olduğunu belirtmiştir. Fakat bu direnç normal dağılımdan büyük çaplı sapmalar (extreme) için geçerli değildir. Bu kitabın yazarları normallik testlerinin bu varsayımı kontrol etmek için kullanılmasına sıcak bakmamaktadır. Görsel bir değerlendirmeden sonra özellikle küçük örneklemlerde, normallik varsayımının ihlal edildiği kaygısı varsa araştırmacılar dirençli tahminleme yöntemlerini kullanmalıdırlar. Eş varyanslılık. Varyans homojenliği olarak da bilinen bu varsayım, iki grupta yer alan puanların evren bazında eşit varyanslı dağılımlardan çekildiğini kabul eder. Myers et al. (2013) grup örneklem sayılarının eşit ve en az 5 olduğu durumlarda varyans eşitliği sağlanamasa dahi 1. tip hata oranlarının önemli ölçüde değişmeyeceğini belirtmiştir. Fakat bu direnç büyük çaplı heterojenlikler için geçerli değildir, örnğin \\(s_1^2/s_2^2&gt;100\\). Field, Miles, and Field (2012) Levene testi gibi eşvaryanslılık testlerinin örneklem sayılarının eşit olmadığı ve küçük örneklemlerde sağlıklı sonuçlar vermediğini belirtmiştir, halbuki bu testlere en çok ihtiyaç durumlar küçük örneklem ve eşit olmayan örneklem sayısı durumlarıdır. Eş varyanslılık testleri ile ilgili bir diğer kaygı, bu test sonucunda varyansların eşit sayılabileceği kararı verilmiş olsa da varyanslar arası farklılığın t test istatistiğini etkileyebileceğidir. t.test fonksiyonu , aksi istenmediği sürece, varyans eşitliği varsayımı yapmaz ve Welch t testini hesaplar. Varsayımlar hakkındaki bu kısa tanıtımın ele almadığı durumlar vardır. Örneğin hem normalliğin hem eş varyanslılığın ihlal edildiği durumlar tartışılmamıştır. Ayrıca direnç konusu tartışmaya açıktır. Önreğin n1=n2=10 örneklem sayısı ve eş olmayan varyans durumu için 100000 tekrarla yaptığımız bir simülasyon, alfa=.01 ve yönsüz bir t testi için 1. tip hata oranını .018 bulmuştur. Bu oranın kabul edilebilir olup olmadığı tartışmaya açıktır. Sonuç olarak, eğer yanıtların bağımsızlığı kabul ediliyorsa, örneklem sayısı eşitse ve her grupta en az 20 ise bağımsız gruplar t istatistiğinin büyük ölçüde dirençli olduğu kabulu makul bir kabuldur. Diğer durumlarda varsayım ihlalleri tespit edildi ise araştırmacılar alternatif çözümleme yöntemlerini kullanabilirler. 8.1.3 Welch t test Normalliğin ciddi ölçüde zedelenmediği ve örneklem sayılarının her grup için en az 20 olduğu durumlarda Welch testi geçerli sonuçlar üretir. Bu test varyans eşdeğerli varsayımı yapmaz. t.test(gen_att~HEF,data=dataWBT_USAK,var.equal=F, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## Welch Two Sample t-test ## ## data: gen_att by HEF ## t = 1.9028, df = 95.885, p-value = 0.06006 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.008484626 0.401462282 ## sample estimates: ## mean in group non-college mean in group college ## 1.831783 1.635294 8.1.3.1 Welch t testi için raporlama örneği Uşak ilinde yaşayan katılımcılardan yüksek öğretim diplomasına sahip olan 51 kişi için TCA puanları ortalaması 1.64, standart sapması 0.61, puanlara ait dağılım çarpıklık değeri 1.19 ve basıklık değeri 1.09 olarak bulunmuştur. Aynı ilde yüksek öğretim diploması olmayan 86 katılımcının ise TCA puanları ortalaması 1.83, standart sapması 0.54, puanlara ait dağılımın çarpıklığı 0.72 ve basıklığı 0.90 olarak hesaplanmıştır.Bağımsız gruplar Welch t-testi sonuçları, Uşak ilinde yaşayan katılımcıların Toplumsal Cinsiyet Algısı puanlarının yüksek öğretim durumuna göre değişeceği tezini desteklememiştir, t(95.89)=1.9, p=0.06. Puanlar arasındaki fark için %95 güven aralığı [-0.082,0.402] olarak hesaplanmıştır. Eğer normallik varsayımı ciddi ölçüde süpheli ise ve özellikle iki grup farklı şekillerde dağılım gösteriyor ise yüzdeli bootstrap prosedürü (percentile bootstrap) kullanılabilir (Wilcox (2012),page 171). #bootstrap ile %95 güven aralığı (normallik varsayımı yok) set.seed(04012017) B=5000 # bootstrap tekrar sayısı alpha=0.05 # alfa # grupları tanımla GroupCollege=na.omit(dataWBT_USAK[dataWBT_USAK$HEF==&quot;college&quot;,&quot;gen_att&quot;]) GroupNONcollege=na.omit(dataWBT_USAK[dataWBT_USAK$HEF==&quot;non-college&quot;,&quot;gen_att&quot;]) output=c() for (i in 1:B){ x1=mean(sample(GroupCollege,replace=T,size=length(GroupCollege))) x2=mean(sample(GroupNONcollege,replace=T,size=length(GroupNONcollege))) output[i]=x2-x1 } output=sort(output) ## yönsüz # D yıldız alt output[as.integer(B*alpha/2)+1] ## [1] -0.01338349 # D yıldız üst output[B-as.integer(B*alpha/2)] ## [1] 0.3899111 ##Yönlü x2&gt;x1 # D yıldız alt output[as.integer(B*alpha)+1] ## [1] 0.02202462 #hatalı yön x2&lt;x1 # D yıldız üst output[as.integer(B*(1-alpha))] ## [1] 0.3575695 8.1.3.2 Yüzdeli bootstrap yöntemi için raporlama örneği Uşak ilinde yaşayan katılımcılardan yüksek öğretim diplomasına sahip olan 51 kişi için TCA puanları ortalaması 1.64, standart sapması 0.61, puanlara ait dağılım çarpıklık değeri 1.19 ve basıklık değeri 1.09 olarak bulunmuştur. Aynı ilde yüksek öğretim diploması olmayan 86 katılımcının ise TCA puanları ortalaması 1.83, standart sapması 0.54, puanlara ait dağılımın çarpıklığı 0.72 ve basıklığı 0.90 olarak hesaplanmıştır.Puanlar arasındaki fark için %95 bootstrap güven aralığı [-0.013,0.390] olarak hesaplanmıştır. Güven aralığı 0 değerini içerdiği için puanlar arasındaki farkın istatistiksel olarak anlamlı olduğu savunulamaz. Yönlü test Alternatif hipotez, yüksek öğretim mezunu olmayan katılımcıların puanlarının yüksek olacağını belirtmiş ise; Puanlar arasındaki fark için %95 bootstrap güven aralığı [0.022,\\(\\infty\\)] olarak hesaplanmıştır. Eldeki veri yüksek öğretim mezunu olmayanların puanlarının daha yüksek olacığı tezini desteyecek kanıt sunmuştur, \\(H_0:\\mu_{non-college} = \\mu_{college}\\) in favor of \\(H_1:\\mu_{non-college}-\\mu_{college} &gt; 0\\). Yönlü test Alternatif hipotez, yüksek öğretim mezunu olmayan katılımcıların puanlarının düşük olacağını belirtmiş ise; Puanlar arasındaki fark için %95 bootstrap güven aralığı [\\(-\\infty\\),0.358] olarak hesaplanmıştır. Eldeki veri yüksek öğretim mezunu olmayanların puanlarının daha düşük olacağı tezini desteklememektedir. \\(H_0:\\mu_{non-college} = \\mu_{college}\\) ve \\(H_1:\\mu_{non-college}-\\mu_{college} &lt; 0\\). Yönlü ve yönsüz alternatif testler farklı kriterler kullanır. Yönlü testlerde yönün nasıl belirlendiği savunulmalıdır. Kullanılan örnekte yönsüz alternatif kullanıldığında Welch t testi p değeri 0.06 bulunmuştur. Bu sonuç marjinal anlamlılık olarak yorumlanabilir. Ülkemizde TCA puanları ve yüksek öğretim ilişkisi hakkında alanyazın sınırlı olduğu için yönlü bir alternatif savunulması zordur. 8.1.4 Bağımsız gruplar t testi için etki büyüklüğü Bir t testi istatistiği ortalamaların birbirinden farklı olup olmadığı hakkında karar vermeye yardımcı olsa da, bu farklılığın büyüklüğünü yorumlamak için etki büyüklüğü hesaplamaları geliştirilmiştir. Bağımsız gruplar t testi için Cohen etki büyüklüğü , ortalamarın farkını bileşik standart sapmaya (pooled) bölünmesi ile hesaplanır. \\[EB=\\frac{t}{\\sqrt{\\frac{n_1n_2}{n_1+n_2}}}\\] Cohen (1962) etki büyüklüğü sınıflaması Etki büyüklüğü Tanım .2 Küçük .5 Orta .8 Büyük ## normallik ve eş varyanslılık varsayımı yapıldığında ## (dirençli yöntem benzer sonuç verdiğiiçin varsayımların kabulü makuldür.) n1=51 n2=86 tval=1.96 EB=tval/sqrt((n1*n2)/(n1+n2)) EB ## [1] 0.3464033 #veya effsize paketi ile t.test(gen_att~HEF,data=dataWBT_USAK,var.equal=F, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## Welch Two Sample t-test ## ## data: gen_att by HEF ## t = 1.9028, df = 95.885, p-value = 0.06006 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.008484626 0.401462282 ## sample estimates: ## mean in group non-college mean in group college ## 1.831783 1.635294 library(effsize) cohen.d(gen_att~HEF,data=dataWBT_USAK, paired=F, conf.level=0.95,noncentral=F) ## ## Cohen&#39;s d ## ## d estimate: 0.346177 (small) ## 95 percent confidence interval: ## inf sup ## -0.008425638 0.700779597 # noncentral=T argümanını araştırabilirsiniz. effsize paketi (Torchiano 2016) etki büyüklüğünü 0.35 ve ilgili %95 güven aralığını [-0.008, 0.701] olarak hesaplamıştır. 8.1.5 Extra: Pratikte anlamlılık ve istatistiksel anlamlılık Bir çalışma sonucunda elde edilen sonuçların istatistiksel olarak anlamlı olmadığı fakat prtaikte anlamlı olduğu öne sürülebilir. Bu sakıncalı bşr durumdur ve sadece küçük örneklemlerde görülür. Küçük bir örneklem ile yapılan çalışmadan sonra pratikte anlamlılıktan bahsetmek tezat oluşturur. Bir çalısma sonucunda elde edilen sonuçların istatistiksel olarak anlamlı olduğu fakat pratikte anlamlı olmadığı öne sürülebilir. Bu doğru olabilir. 400 kişi ile tamamlanan bir çalışmada istatistiksel anlamlı farklılık .05 etki büyüklüğüne sahip olabilir. Eğer .05 etki büyüklüğü çalışmanın yapıldığı alanda küçük adlediliyorsa istatististiksel anlamlılık pratikte anlamlılığı desteklemez. 8.1.6 Kayıp veriler ile bağımsız gruplar t testi Eklenecek 8.1.7 Destekleyici grafikler Eklenecek 8.1.8 İstatisksel güç İstatistiksel güç konusunun ana hatlarına bölüm 7.3.8’de değinilmiştir. #power.t.test power.t.test(delta=.35, sd=.6,sig.level=0.05, power=0.95, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;) ## ## Two-sample t test power calculation ## ## n = 77.35093 ## delta = 0.35 ## sd = 0.6 ## sig.level = 0.05 ## power = 0.95 ## alternative = two.sided ## ## NOTE: n is number in *each* group Bu örnekte belirlenmiş değerler ortalamalar farkı 0.35, standart sapma 0.6, alfa 0.05, yönsüz test ve hedeflenen güç 0.95 seçildiğinde gereken örneklem sayısı her grup için 78’dir. Diğer bir ifade ile, 156 katılımcı ile belirlenen değerlere (ortalamalar farkı 0.35, standart sapma 0.6, alfa 0.05, yönsüz test) ulaşılması durumunda \\(H_0:\\mu_1-\\mu_2=0\\) boş hipotezinin terkedilme olasılığı %95’tir. 8.2 Bağlı gruplar t-testi (Within-subjects t-test) 20 tavşan ile gerçekleştirilen deneyde, yara bandı ve dikiş yöntemlerinin yara kapandıktan 10 gün sonra ölçülen germe mukavemeti değerleri üzerinde etkisi araştırılmıştır. gerMUK=data.frame(tavid=1:20, bant=c(6.59,9.84 ,3.97,5.74,4.47,4.79,6.76,7.61,6.47,5.77, 7.36,10.45,4.98,5.85,5.65,5.88,7.77,8.84,7.68,6.89), dikis=c(4.52,5.87,4.60,7.87,3.51,2.77,2.34,5.16,5.77,5.13, 5.55,6.99,5.78,7.41,4.51,3.96,3.56,6.22,6.72,5.17)) # Grafik verisi library(tidyr) plotdata=gather(gerMUK, metot, mukavemet, bant:dikis, factor_key=TRUE) require(ggplot2) ggplot(plotdata, aes(x = mukavemet)) + geom_histogram(aes(y = ..density..),col=&quot;black&quot;,alpha=0.7) + geom_density(size=2) + theme_bw()+labs(x = &quot;mukavemet&quot;)+ facet_wrap(~ metot)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 8.2: Bagli gruplar örnegi 8.2.1 Bağlı gruplar için t testi Takip edilen basamaklar; Betimsel istatistikler Test istatistiğinin hesabı \\[t=\\frac{\\bar{Y_1}-\\bar{Y_2}}{\\sqrt{\\frac{S_1^2+S_2^2-2S_1 S_2 r_{12}}{n}}}\\] 3.Kritik değerin hesabı \\(\\pm t_{\\alpha/2,n-1}\\), \\[H_0:\\mu_1-\\mu_2=0\\] \\[H_1:\\mu_1-\\mu_2 \\neq0\\] library(psych) descDT=with(gerMUK,describe(cbind(bant,dikis))) descDT ## vars n mean sd median trimmed mad min max range skew ## bant 1 20 6.67 1.71 6.53 6.54 1.45 3.97 10.45 6.48 0.55 ## dikis 2 20 5.17 1.49 5.17 5.19 1.30 2.34 7.87 5.53 -0.08 ## kurtosis se ## bant -0.45 0.38 ## dikis -0.87 0.33 corDT=with(gerMUK,cor(bant,dikis,use=&quot;complete.obs&quot;)) corDT ## [1] 0.3536491 # tahmin edilen standart hata (tsh) tsh=sqrt(((1.71^2+1.49^2)-(2*1.71*1.49*corDT))/(20)) # t-istatistik tstatistic=(6.67-5.17)/tsh # alfa=0.05 kritik değer qt(.975,df=19) ## [1] 2.093024 Hesaplanan 3.67, kritik değerden (\\(t_{.975,19}=2.09\\)) büyük olduğu için boş hipotez terkedilebilir. Daha kolay bir R satırı; library(psych) with(gerMUK, t.test(bant,dikis,paired=T, alternative=&quot;two.sided&quot;, conf.level=0.95)) ## ## Paired t-test ## ## data: bant and dikis ## t = 3.6678, df = 19, p-value = 0.001636 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.6429426 2.3520574 ## sample estimates: ## mean of the differences ## 1.4975 8.2.1.1 Raporlama örneği: Bağlı gruplar t testi hesaplarına dayanarak, gerilim mukavemetinin bant tedavisi (ort=6.67,SS=1.71,çarpıklık=0.55,basıklık=-0.45) ve dikiş tedavisi (ort=5.17,SS=1.49,çarpıklık=-0.08,basıklık=-0.87) arasında farklılık gösterdiği sonucuna varılmıştır, t(19)=3.67, p=0.002 ,r=0.35. Aritmetik ortalamaların farkı için 95% güven aralığı [0.64,2.35] olarak hesaplanmıştır. 8.2.2 Varsayımlar: bağlı gruplar için t testi Puanların farkı (\\(Y_{1i} - Y_{2i}\\)) normal bir dağılımdan çekilmiş olmalıdır. Puanların farkları her birey için bağımsız olmalıdır. Bağlı gruplar t testi , örneklem küçük değil ise, normallik varsayımı ihlallerine karşı genellikle dirençlidir. 8.2.3 Dirençli yöntem: bağlı gruplar için t testi Eğer dağılım normallikten büyük ölçüde ayrılıyor ise, yüzdeli bootstrap prosedürü kullanılabilir (Wilcox (2012),page 201). #bootstrap ile %95 güven aralığı (normallik varsayımı yok) set.seed(04012017) B=5000 # bootstrap tekrar sayısı alpha=0.05 # alfa gerMUK=data.frame(ratid=1:20, bant=c(6.59,9.84 ,3.97,5.74,4.47,4.79,6.76,7.61,6.47,5.77, 7.36,10.45,4.98,5.85,5.65,5.88,7.77,8.84,7.68,6.89), dikis=c(4.52,5.87,4.60,7.87,3.51,2.77,2.34,5.16,5.77,5.13, 5.55,6.99,5.78,7.41,4.51,3.96,3.56,6.22,6.72,5.17)) output=c() for (i in 1:B){ #satırları örnekle bs_rows=sample(gerMUK$ratid,replace=T,size=nrow(gerMUK)) bs_sample=gerMUK[bs_rows,] mean1=mean(bs_sample$bant) mean2=mean(bs_sample$dikis) output[i]=mean1-mean2 } output=sort(output) ## yönsüz # d yıldız alt output[as.integer(B*alpha/2)+1] ## [1] 0.6865 # d yıldız üst output[B-as.integer(B*alpha/2)] ## [1] 2.2415 ##Yönlü x2&gt;x1 # d yıldız alt output[as.integer(B*alpha)+1] ## [1] 0.837 #yanlış yön x2&lt;x1 # d yıldız üst output[as.integer(B*(1-alpha))] ## [1] 2.1445 8.2.3.1 Yönsüz yüzdeli bootstrap için örnek rapor: Yaraların tedavisinden 10 gün sonra gerilim mukavemeti ölçümleri yapılmıştır. Yara bandı ile (ort=6.67,SS=1.71,çarpıklık=0.55,basıklık=-0.45) dikiş tedavisi (ort=5.17,SS=1.49,çarpıklık=-0.08,basıklık=-0.87) ölçümleri arasındaki fark için 5000 tekrarlı bootstrap prosedürü %95 güven aralığı [0.667,2.2555] olarak hesaplanmıştır. Yeni geliştirilen yara bandı sonrası gerilim mukavemetinin daha yüksek olduğu ve bu farklılığın istatistiksel olarak anlamlı olduğu sonucuna varılmısştır. 8.2.4 Effect size for the dependent groups t-test En basit etki büyüklüğü hesaplama yöntemlerinden biri;8 \\[ES=\\frac{t}{\\sqrt{n}}\\] ## dirençli prosedürler farklı sonuç vermediği için ## normallik ve varyans eşitliği varsayımları yapılmıştır. n=20 tval=3.6678 EB=tval/sqrt(n) EB ## [1] 0.820145 library(effsize) cohen.d(gerMUK$bant,gerMUK$dikis, paired=T, conf.level=0.95,noncentral=F) ## ## Cohen&#39;s d ## ## d estimate: 0.820134 (large) ## 95 percent confidence interval: ## inf sup ## 0.1348856 1.5053823 effsize paketi (Torchiano 2016) etki büyüklüğünü 0.820 ve ilgili %95 güven aralığını [0.135, 1.505] olarak hesaplamıştır. 8.2.5 Kayıp veriler ile bağlı gruplar t testi Eklenecek 8.2.6 Destekleyici grafikler Eklenecek 8.2.7 İstatistiksel güç: bağlı gruplar t testi #power.t.test power.t.test(delta=.35, sd=.6,sig.level=0.05, power=0.95, type=&quot;paired&quot;, alternative=&quot;two.sided&quot;) ## ## Paired t test power calculation ## ## n = 40.16447 ## delta = 0.35 ## sd = 0.6 ## sig.level = 0.05 ## power = 0.95 ## alternative = two.sided ## ## NOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs Bu örnekte belirlenmiş değerler ortalamalar farkı 0.35, standart sapma 0.6, alfa 0.05, yönsüz test ve hedeflenen güç 0.95 seçildiğinde gereken örneklem sayısı 41’dir. Diğer bir ifade ile, 41 katılımcı ile belirlenen değerlere (ortalamalar farkı 0.35, standart sapma 0.6, alfa 0.05, yönsüz test) ulaşılması durumunda \\(H_0:\\mu_1-\\mu_2=0\\) boş hipotezinin terkedilme olasılığı %95’tir. 8.3 Yaygın Tasarılar Sosyal bilimlerde iki ortalamayı kıyaslamak üzere kurulan tasarılardan yaygın olanları özetlenmiştir. 8.3.1 Grupların ilişkili olduğu durumlar Ortalamaların hesaplandığı puanların farklı gruplar altında ilişkili olup olmadğı önemlidir. 8.3.1.1 Tekrarlanan ölçümler Aynı katılımcı içiin aynı değişkenin birden fazla ölçülmesi durumu. Bireylerin kendi kontrol grubunu oluşturması: Semantik hafızanın aktivasyon hızını ölçmek üzere 100 üniversite öğrencisi ile araştırma yapılmıştır. Her öğrenci çiftler halinde verilen kelimeleri okumuştur. Okudukları ilk kelime ya bir silah (örneğin mermi, hançer) ya da silah olmayan bir kelimedir. Okudukları ikinci kelime mutlaka agresif bir kelimedir (örneğin yarala, imha et). Her bir öğrenci 192 çift kelimeyi bilgisayarda görüp sesli olarak okumuştur. Bilgisayar ilk kelimeyi 1.25 saniye ekranda tutmuş, .5 saniye siyah ekran göstermiş ve ikinci kelimeyi ekranda göstermiş, her ikinci kelimeden önce reaksiyon zamanını ölçmüştür. Her bireyin reaksiyon zamanı ortalamaları alınmış ve analiz edilmiştir. İlk kelime Öğrenci Silah Silah Değil 1 2 … 100 Her öğrencinin kendi okuma hızı olduğundan, Silah ve Silah olmayan kelimeleri okumak için gereken reaksiyon zamanları birbiri ile ilişkilidir. Boylamsal tasarılar: 6. sınıf öğrencilerinin matematik başarısı dönem başında ve dönem sonunda ölçülmüştür. Amaç puanların değişip değişmediğini görmektir. Zaman Öğrenci Dönem başı Dönem sonu 1 2 … 48 Ölçümler aynı öğrenciler ile tekrarlandığı için puanlar ilişkilidir. 8.3.1.2 Blok tasarıları Katılımcıların blok olarak ikili eşleştirilmesidir. Her çiftin (blok içindeki) benzer davranması beklenir. Rassal blok tasarı: Okuma hızını artırmak için bir program geliştirilmiştir, etkililiğini araştırmak üzere, 30 ikinci sınıf öğrencisi bir okuma testini cevaplamış, ve puanlarına göre çiftler oluşturmuştur. Çift Okuma testi puan sırası 1 1,2 2 3,4 … … 15 29,30 Görüldüğü gibi en hızlı okuyan 2 öğrenci ilk çifti, en yavas okuyan iki öğrenci son çifti oluşturmuştur.Çiftlerden her biri rassal olarak yeni program grubuna veya kontrol grubuna atanmıştır. As shown, the students with the two highest scores were in the first pair, the students with the Yeni program son bulduktan sonra öğrencilerin okuma hızları ölçülmüştür |:——–:|:————-:|:——-:| | Çift | Yeni Program | Kontrol | | 1 | | | | 2 | | | | … | | | | … | | | | 15 | | | Rassal olmayan blok tasarı: Şiddete maruz kalmış grup çocuğun, şiddet görmemiş daha kalabalık bir gruptan çocuklar ile genel kaygı düzeyi üzerinden eşleştiğini düşünelim. Sonrasında stres anında gösterdikleri endişe durumlarını ölçelim Çift Şiddete maruz kalan Kontrol 1 2 … 20 Kalıtsal tasarılar (Familial): 25 anne ve erişkin kızlarının politik görüşleri alınmıştır. Çift Anne Kız 1 2 … 25 Dyadik tasaıları: Afrikalı-Amerikalı ve Avrupalı-Amerikalı çocuklardan oluşturulan çiftler işbirliği gerektiren küçük oyunlar oyamışlardır. Her bir çocuk eşinin işbirlikçiliğini puanlamıştır. Etnisite Çift Afrikalı-Amerikalı Avrupalı-Amerikalı 1 2 … 25 8.3.2 Bağlı olmayan grup tasarılarına örnekler Tamamen rassal tasarı İki farklı manyetik ağrı kesici makinesinin performansı karşılaştırılacaktır. 50 hasta rassal olarak, 25-25, iki makineye alınmış, tedaviden sonra ağrı düzeylerini rapor etmişlerdir. Makine 1 2 . . . Rassal olmayan tasarı: Sekizinci sınıf öğrencilerinden 50 kız ve 50 erkek seçilmiş 2 basamaklı toplama işlemi yapma hızları ölçülmüştür. References "],
["analysis-of-variance-anova.html", " 9 Analysis of Variance (ANOVA) 9.1 Terminology 9.2 Between Subjects ANOVA 9.3 Within Subjects ANOVA 9.4 Mixed Design", " 9 Analysis of Variance (ANOVA) 9.1 Terminology Designs are usually described using a standard terminology. The following is an introduction to this terminology. Factor a collection of treatments. For example, in the Magnetic vs. Inactive device study, device is a factor. In the priming study, type of prime word is a factor. Level an instance of a factor. In the Magnetic vs. Inactive device study 8.3.2, magnetic device is a level of the type of instruction factor, as is inactive device. In the priming study, weapon word is a level of the type of prime word factor, as is non-weapon word. Crossed factors two factors are crossed if each level of one factor occurs in combination with every level of the second factor. For example, consider the diagram, on the following page, of a repeated measures design in which the treatment factor has two levels. Levels of Treatment Factor 1 2 Subjects 1 2 . n Subjects can be considered a factor and is crossed with the treatment factor since each subject occurs in combination with each treatment. Nesting one factor is nested in a second factor if each level of the first factor occurs in combination with only one level of the second factor. For example, consider the following diagram of an independent samples design in which the treatment factor has two levels. Levels of Treatment Factor 1 2 \\(S_1\\) \\(S_{n+1}\\) \\(S_2\\) \\(S_{n+2}\\) \\(S_3\\) \\(S_{n+3}\\) … \\(S_n\\) \\(S_{2n}\\) Subjects are nested in treatments because each subjects appears in only one treatment. Within-subjects factor a factor that is crossed with subjects. The name derives from the fact that the levels of the factor vary within a subject as can be seen in the diagram for the repeated measures design. The following designs have a within-subjects factor: subjects as own control and longitudinal, both of which are examples of repeated measures designs. Within-blocks factor a factor that is crossed with blocks. The name derives from the fact that the levels of the factor vary within a block as can be seen in the following diagram. Block Levels of factor 1 2 1 2 … n The following designs have a within-blocks factor: randomized block, nonrandomized block, familial, and dyads. Many people do not distinguish between within-subjects and within-blocks factors, because they lead to the same method of analysis. Typically, we will not distinguish between the two types of factors and will label both as a within-subjects factor. Between-subjects factor a factor that has subjects nested in its levels; the subjects in the levels are not crossed with blocks. The qualifier following the semi-colon is necessary to distinguish a between-subjects factor from a within-blocks factor because in both factors a subject is assigned to only one level of a factor. This can be seen from the diagram for the independent samples design: Levels of Treatment Factor 1 2 \\(S_1\\) \\(S_{n+1}\\) \\(S_2\\) \\(S_{n+2}\\) \\(S_3\\) \\(S_{n+3}\\) … \\(S_n\\) \\(S_{2n}\\) 9.2 Between Subjects ANOVA The name between-subjects derives from the fact that the levels of the factor vary between subjects. 9.2.1 One-way Between Subjects ANOVA The structural model for a one-factor between subjects ANOVA is \\(Y_{ij}=\\mu+\\alpha_{j}+\\epsilon_{ij}\\), in which \\(Y_{ij}\\) is the score for the participant i in group j, \\(\\mu\\) is the grand mean of the scores, \\(\\alpha_j\\) is the effect of the level j, and \\(\\epsilon_{ij}\\) is the error term (nuisance). It can be shown that \\(\\mu_j=\\mu+\\alpha_j\\), where \\(\\mu_j\\) is the the mean for the jth level of the factor. Generally, the interest is on \\(\\alpha_j\\) because it represents \\(\\mu_j-\\mu\\). This interest leads to hypothesis testing: \\(H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_j\\) The alternative hypothesis states that at least one population mean is different. It is possible to test the null by partitioning the variance, for a one factor model using the notation by Myers et al. (2013) SV df SS MS F Total \\(N-1\\) \\(\\sum_{j=1}^{J}\\sum_{i=1}^{n_j}(Y_{ij} - \\bar{Y}_{\\cdot \\cdot})^2\\) A \\(J-1\\) \\(\\sum_{j=1}^{J}n_j(\\bar{Y}_{\\cdot j}-\\bar{Y{\\cdot \\cdot}})^2\\) \\(SS_A/df_{A}\\) \\(MS_A/MS_{S/A}\\) S/A \\(N-J\\) \\(\\sum_{j=1}^{J}\\sum_{i=1}^{n_j}(Y_{ij} - \\bar{Y}_{\\cdot j})^2\\) \\(SS_{S/A} / df_{S/A}\\) SV EMS Total A \\(\\sigma_{S/A}^2 + \\frac{1}{J-1} \\sum_{j} n_j (\\mu_j-\\mu)^2\\) S/A \\(\\sigma_{S/A}^2\\) where SV=Source of Variance, df=degrees of freedom, SS=Sum of squares, MS= Mean Square, EMS= Expected Mean Square, A is the between subjects factor with J levels, S/A is the subjects within A, N is the total sample size, j=1,…,J factor level indicator, i=1,…,\\(n_j\\) individual indicator, \\(Y_{ij}\\) is the individual score, \\(\\bar{Y}_{\\cdot \\cdot}\\) is the grand mean, \\(\\bar{Y}_{\\cdot j}\\) is the group j’s mean. The ratio of \\(MS_{A}/ MS_{S/A}\\) , when the null is true and assumptions are met, follows an F distribution with J-1 and N-J degrees of freedom; hence, if \\(MS_{A}/ MS_{S/A}\\) is larger than the \\(F_{\\alpha,J-1,N-J}\\) the null is rejected. 9.2.1.1 Effect size for one-way between-subjects ANOVA To simplify the illustration, let us assume each treatment level has the same number of participants, \\(n_1=n_2=\\cdots=n_j=n\\). Hence, the expected mean square for A is \\(\\sigma^2+n\\theta^2_A\\) in which \\[\\theta^2_A=\\sum_{j=1}^{J}\\frac{(\\mu-\\mu_j)^2}{J-1}\\]. The estimate of \\(\\theta^2_A\\), the \\(\\hat\\theta^2_A\\) is equal to \\(\\frac{MS_A-MS_{S/A}}{n}\\), and the estimate of \\(\\sigma_{S/A}^2\\), the \\(\\hat\\sigma_{S/A}\\) is equal to \\(MS_{S/A}\\) As stated in Section 8.1.4 to judge whether a mean difference is large in a substantive sense one can use an effect size. For a one-way between subjects ANOVA, reporting at least one type of effect size is a general practice. Among them, omega-hat-squared (\\(\\hat\\omega^2\\)), eta-hat-squared (\\(\\hat\\eta^2\\)) and \\(f\\) are well known. 9.2.1.1.1 Omega-squared for one-way between-subjects ANOVA Omega-hat-squared is the proportion of total variance that is due to the factor. \\(\\hat\\omega^2=\\frac{(J-1)\\hat\\theta^2/J}{((J-1)\\hat\\theta^2/J)+\\hat\\sigma^2_{S/A})}\\) An omega-squared is considered small if it is 0.01, medium if 0.06, large if 0.14 Myers et al. (2013). 9.2.1.1.2 Eta-squared for one-way between-subjects ANOVA \\(\\hat\\eta^2=\\frac{SS_A}{SS_{Total}}\\) also attempts to estimate the proportion of total variance that is due to the factor. \\(\\hat\\eta^2\\) is larger than \\(\\hat\\omega^2\\) because \\(\\hat\\eta^2\\) is a positively biased statistics, that is, it tends to be too large, especially when n is small. \\(\\hat\\eta^2\\) is probably the most widely used effect size for ANOVA and also reported in a regression fashion as \\(R^2\\). 9.2.1.1.3 Effect size f for one-way between-subjects ANOVA Cohen’s \\(f=\\frac{\\hat\\theta_A}{\\hat\\sigma_{S/A}}\\). An f value is considered small if it is 0.10, medium if 0.25, large if 0.40. 9.2.1.1.4 A general note on the Effect Size Measures For illustrative purposes, we briefly summarized effect size measures for equal sample size in each group. In practice it is generally not common to have equal sample sizes. It is also not common to have a single factor design. In addition, factors in a design are either measured or manipulated, which which affect the effect size computation. The ezANOVA function (Lawrence (2016)) reports generalized eta-squares based on Bakeman (2005). The work by Bakeman (2005) encourages researchers to use generalized eta-squared defined by Olejnik and Algina (2003). Hence, a convenient choice for a researcher is to use the ezANOVA function, while paying attention to the observed argument to declare the measured factors. On the other hand, if it is not desired to be dependent on an R package, the researcher can examine and apply the formulae by Olejnik and Algina (2003). 9.2.1.2 Testing specific contrasts of means Either in addition to or in place of the ANOVA, specific contrasts (comparisons) of means may be tested. A contrast is a weighted sum of means in which the weights sum to zero. There are two classes of contrasts: pairwise contrasts and complex contrasts. To illustrate these classes consider a one-way design in which the factor has three levels, a control treatment and two active treatments. Let the population means for these levels be \\(\\mu_1\\), \\(\\mu_2\\), and \\(\\mu_3\\), respectively. In a pairwise contrast two means are compared and the weights are 1 for one mean, -1 for another and zero for all others. A pairwise contrast of the means for the active treatments is \\((0)\\mu_1+(1)\\mu_2+(-1)\\mu_3\\). The complex contrast \\((-1) \\mu_1+(-.5)\\mu_2+(-.5)\\mu_3\\) is a comparison of the mean for the control group to the average of the means for the two active treatments. Under the assumptions of a one-way between-subjects ANOVA, the null hypothesis that a contrast is equal to zero can be tested using \\[t=\\frac{\\sum_{j=1}^J(w_j\\bar{Y})}{\\sqrt{MS_{S/A}\\sum_{j=1}^J(\\frac{w_j^2}{n_j})}}\\] 9.2.1.3 Testing all possible pairwise comparisons There are several procedures for testing all possible pairwise contrasts. An important issue in such testing is the error rate to control. Controlling an error rate means keeping it at or below some conventional level (e.g., .05). Two of the most common error rates are the per comparison error rate and the familywise error rate. The per comparison error rate is the probability of making a Type I error when one of the contrasts is tested. To control the per comparison error rate the critical value for a pairwise comparison is \\(\\pm t_{(1-\\alpha⁄2),N-J}\\). When this critical value is used, the per comparison error rate is \\(\\alpha\\). The family wise error rate is the probability of falsely rejecting one of more of the contrasts. If all pairwise contrasts are equal to zero, the family wise error rate is between \\(\\alpha\\) and \\([J(J-1)⁄2]\\alpha\\). The upper limit can be quite high even when the number of levels of the factor is small. For example if there are J=3 levels, the upper limit is \\(3\\alpha\\). There are several procedures for controlling the familywise error rate. 9.2.1.3.1 Trend analyses following one-way between-subjects ANOVA To be added. 9.2.1.4 Assumptions of the one-way between-subjects ANOVA The assumptions of the one-way between-subjects ANOVA are the same as the assumptions of the independent samples t test. Independence. The scores in each group should be independently distributed and the scores in different groups should also be independent. The validity of this assumption in regard to independence within groups is questionable when (a) scores for participants within a group are collected over time or (b) the participants within a group work together in a manner such that a participant’s response could have been influenced by another participant in the study. The validity of this assumption in regard to independence between groups is questionable when the factor is a within-subjects factor rather than a between-subjects factor. Violating the independence assumption is a critical violation that usually can be addresses by adopting an analysis appropriate for the lack of independence. For example, if there are different participants in each group, but within each group there are subgroups of participants who work together then according to (b) above independence is likely to have been violated. This violation can be addressed by using multilevel analysis. If there are different participants in each group, but the participants in the groups have been matched, using a randomized block ANOVA can address the violation of independence. Normality. The scores with each group are drawn from a normal distribution. Statistical power is likely to be compromised if the distributions of scores have long tails. When the sample sizes are equal violating normality is not likely to affect the type I error rate, unless the non-normality is severe and the sample sizes are small. Equal variance. This assumption is also called the homogeneity of variance assumption and means it is assumed that samples in the J groups are drawn from J populations with equal variances. Violation of the equal variance assumption is likely to affect the Type I error rate except when the sample sizes are equal and fairly large. Even though we briefly summarized the assumptions of the one-way between subjects ANOVA above, they were only introductory. If independence does not appear to be violated, then when the sample sizes are equal and at least 20 in each group and the scores are approximately normally distributed the one-way between subjects ANOVA can be used. In other situations alternatives should be used. When the robust analyses (e. g. Wilcox (2012)) and conventional analyses yield the same decisions about all hypothesis tests, results of the conventional analyses can be reported due to their greater familiarity to most readers. 9.2.1.5 R codes for a one-way between-subjects ANOVA For illustrative purposes, the city of KOCAELI is subsetted from the DataWBT (Section 2.3). The gender attitudes scores is the dependent variable and the highest degree completed is the between subjects factor. This factor had seven levels; no-degree, primary school, middle school, high school,vocational high school, 2 year college and bachelors. However, there is only one participant in the no-degree group. We combined the no-degree and primary school groups. The gender attitude score for this participant is 1.6.9 For illustrative purposes, the city of KOCAELI is subsetted from the DataWBT (Section 2.3). The gender attitudes scores is the dependent variable and the highest degree completed is the between subjects factor. This factor had seven levels; no-degree, primary school, middle school, high school,vocational high school, 2 year college and bachelors. However, there is only one participant in the no-degree group. We relocated this individual into primary school level. The gender attitude score for this participant is 1.6. Removing this participant from the ANOVA has no substantial effect on the results. Step 1: Set up data and report descriptive # load csv from an online repository urlfile=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataWBT=read.csv(urlfile) #remove URL rm(urlfile) #select the city of KOCAELI # listwise deletion for gen_att and education variables dataWBT_KOCAELI=na.omit(dataWBT[dataWBT$city==&quot;KOCAELI&quot;, c(&quot;id&quot;,&quot;gen_att&quot;,&quot;education&quot;)]) #There is only 1 participant in the level &quot;None&quot;, merge it into Primary school # the gender attitude score for this participant is 1.6 library(car) dataWBT_KOCAELI$eduNEW &lt;- recode(dataWBT_KOCAELI$education, &quot;&#39;None&#39;=&#39;Primary School (5 years)&#39;&quot;) dataWBT_KOCAELI$eduNEW &lt;- recode(dataWBT_KOCAELI$eduNEW, &quot;&#39;High School (Lycee)&#39;= &#39;High School (Lycee) (4 years)&#39;&quot;) dataWBT_KOCAELI$eduNEW &lt;- recode(dataWBT_KOCAELI$eduNEW, &quot;&#39;Vocational School&#39;= &#39;Vocational High School (4 years)&#39;&quot;) #table(dataWBT_KOCAELI$eduNEW) ##optional re-order levels (cosmetic) #levels(dataWBT_KOCAELI$eduNEW) dataWBT_KOCAELI$eduNEW = factor(dataWBT_KOCAELI$eduNEW, levels(dataWBT_KOCAELI$eduNEW)[c(4,3,1,6,2,5)]) #which(dataWBT_KOCAELI$education==&quot;None&quot;) #drop empty levels dataWBT_KOCAELI$eduNEW=droplevels(dataWBT_KOCAELI$eduNEW) #get descriptives library(psych) desc1BW=data.frame(with(dataWBT_KOCAELI, describeBy(gen_att, eduNEW,mat=T,digits = 2)), row.names=NULL) #select relevant descriptives # Table 1 desc1BW[,c(2,4,5,6,7,13,14)] ## group1 n mean sd median skew kurtosis ## 1 Primary School (5 years) 70 2.11 0.41 2.2 -0.19 0.81 ## 2 Junior High/ Middle School (8 years) 94 2.08 0.52 2.1 -0.35 -0.37 ## 3 High School (Lycee) (4 years) 158 1.84 0.58 2.0 0.29 0.64 ## 4 Vocational High School (4 years) 74 2.04 0.50 2.0 -0.14 0.41 ## 5 Higher education of 2 years 112 1.80 0.53 1.8 0.28 -0.36 ## 6 University - Undergraduate degree 62 1.78 0.53 1.8 0.06 -0.63 #write.csv(desc1BW,file=&quot;onewayB_ANOVA_desc.csv&quot;) Step 2: Check assumptions require(ggplot2) ggplot(dataWBT_KOCAELI, aes(x = gen_att)) + geom_histogram(aes(y = ..density..),col=&quot;black&quot;,binwidth = 0.2,alpha=0.7) + geom_density(size=1.5) + theme_bw()+labs(x = &quot;Gender Attitude by Degree in Kocaeli&quot;)+ facet_wrap(~ eduNEW)+ theme(axis.text=element_text(size=14), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 9.1: Gender Attitudes by Degree Departures from the normality do not seem to be severe. require(ggplot2) ggplot(dataWBT_KOCAELI, aes(eduNEW,gen_att)) + geom_boxplot() + labs(x = &quot;Education&quot;,y=&quot;Gender Attitude by degree in Kocaeli&quot;)+coord_flip() Figure 9.2: Gender Attitudes by Degree Homogeneity of variance is questionable but not severely violated. Step 3: Run ANOVA For illustrative purposes, let us ignore the violations first. The ezANOVA function (Lawrence (2016)) reports the F test, the Levene Test and an effect size. Type of the effect size depends on the model. For further details, please carefully study the Table 1 in Bakeman (2005), an open access article, or Olejnik and Algina (2003). The Levene test rejects the null hypothesis of equal variances across factor levels. library(ez) #the ezANOVA function throws a warning if id is not a factor dataWBT_KOCAELI$id=as.factor(dataWBT_KOCAELI$id) # set the number of decimals (cosmetic) options(digits = 3) #alternative 1 the ezANOVA function alternative1 = ezANOVA( data = dataWBT_KOCAELI, wid=id, dv = gen_att, between = eduNEW,observed=eduNEW) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). alternative1 ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 eduNEW 5 564 7.27 1.31e-06 * 0.0605 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 5 564 1.35 63.5 2.4 0.0361 * # critical F value qf(.95,5,564) ## [1] 2.23 ABOUT the warning of ez function; #Warning: Data is unbalanced (unequal N per group). Make sure you specified #a well-considered value for the type argument to ezANOVA(). ezANOVA can calculate three different types of sums of squares for main effects and interactions. For a one-way between-subjects design the F test is the same for all three types and this warning can be ignored. The same results can be obtained with the lm (linear model) function in R Core Team (2016b). # alternative 2 the lm function alternative2=lm(gen_att~eduNEW,data=dataWBT_KOCAELI) #Table 2 anova(alternative2) ## Analysis of Variance Table ## ## Response: gen_att ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## eduNEW 5 10.13 2.02610 7.2676 1.306e-06 *** ## Residuals 564 157.24 0.27879 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The aov function in R Core Team (2016b) is the third alternative. #alternative 3 the aov function alternative3=aov(gen_att~eduNEW,data=dataWBT_KOCAELI) summary(alternative3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## eduNEW 5 10.13 2.0261 7.268 1.31e-06 *** ## Residuals 564 157.24 0.2788 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The pairwise.t.test function in the stats package (R Core Team (2016b)) is convenient. Provide the preferred procedure by using p.adjust.method argument, for example p.adjust.method =“Holm” to use the adjustment given by Holm (1979). Five other procedures are available with this function, please see ?p.adjust. # pairwise comparisons # Table 3 with(dataWBT_KOCAELI, pairwise.t.test(gen_att,eduNEW,p.adjust.method =&quot;holm&quot;)) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: gen_att and eduNEW ## ## Primary School (5 years) ## Junior High/ Middle School (8 years) 1.0000 ## High School (Lycee) (4 years) 0.0040 ## Vocational High School (4 years) 1.0000 ## Higher education of 2 years 0.0014 ## University - Undergraduate degree 0.0043 ## Junior High/ Middle School (8 years) ## Junior High/ Middle School (8 years) - ## High School (Lycee) (4 years) 0.0046 ## Vocational High School (4 years) 1.0000 ## Higher education of 2 years 0.0017 ## University - Undergraduate degree 0.0057 ## High School (Lycee) (4 years) ## Junior High/ Middle School (8 years) - ## High School (Lycee) (4 years) - ## Vocational High School (4 years) 0.0435 ## Higher education of 2 years 1.0000 ## University - Undergraduate degree 1.0000 ## Vocational High School (4 years) ## Junior High/ Middle School (8 years) - ## High School (Lycee) (4 years) - ## Vocational High School (4 years) - ## Higher education of 2 years 0.0176 ## University - Undergraduate degree 0.0357 ## Higher education of 2 years ## Junior High/ Middle School (8 years) - ## High School (Lycee) (4 years) - ## Vocational High School (4 years) - ## Higher education of 2 years - ## University - Undergraduate degree 1.0000 ## ## P value adjustment method: holm 9.2.1.6 Robust estimation and hypothesis testing for a one-way between-subjects design Several approaches to conducting a robust one-way between subjects ANOVA, have been presented by Wilcox (2012) One of the convenient robust procedure , a heteroscedastic one-way ANOVA for trimmed means, has been compressed into the t1way function, available via WRS-2 (Mair and Wilcox (2016)). Please use ?t1way for the current details, this promising package is being improved frequently . library(WRS2) #t1way # 20% trimmed t1way(gen_att~eduNEW,data=dataWBT_KOCAELI,tr=.2,nboot=5000) ## Call: ## t1way(formula = gen_att ~ eduNEW, data = dataWBT_KOCAELI, tr = 0.2, ## nboot = 5000) ## ## Test statistic: 7.5658 ## Degrees of Freedom 1: 5 ## Degrees of Freedom 2: 143.78 ## p-value: 0 ## ## Explanatory measure of effect size: 0.29 # 10% trimmed t1way(gen_att~eduNEW,data=dataWBT_KOCAELI,tr=.1,nboot=5000) ## Call: ## t1way(formula = gen_att ~ eduNEW, data = dataWBT_KOCAELI, tr = 0.1, ## nboot = 5000) ## ## Test statistic: 9.5355 ## Degrees of Freedom 1: 5 ## Degrees of Freedom 2: 187.52 ## p-value: 0 ## ## Explanatory measure of effect size: 0.3 # 5% trimmed t1way(gen_att~eduNEW,data=dataWBT_KOCAELI,tr=.05,nboot=5000) ## Call: ## t1way(formula = gen_att ~ eduNEW, data = dataWBT_KOCAELI, tr = 0.05, ## nboot = 5000) ## ## Test statistic: 9.415 ## Degrees of Freedom 1: 5 ## Degrees of Freedom 2: 211.55 ## p-value: 0 ## ## Explanatory measure of effect size: 0.31 ## heteroscedastic pairwise comparisons #level order lincon(gen_att~eduNEW,data=dataWBT_KOCAELI,tr=.1)[[2]] ## [1] &quot;Higher education of 2 years&quot; ## [2] &quot;Junior High/ Middle School (8 years)&quot; ## [3] &quot;University - Undergraduate degree&quot; ## [4] &quot;Vocational High School (4 years)&quot; ## [5] &quot;High School (Lycee) (4 years)&quot; ## [6] &quot;Primary School (5 years)&quot; round(lincon(gen_att~eduNEW,data=dataWBT_KOCAELI,tr=.1)[[1]][,c(1,2,6)],3) ## Group Group p.value ## [1,] 1 2 0.701 ## [2,] 1 3 0.000 ## [3,] 1 4 0.360 ## [4,] 1 5 0.000 ## [5,] 1 6 0.000 ## [6,] 2 3 0.000 ## [7,] 2 4 0.597 ## [8,] 2 5 0.000 ## [9,] 2 6 0.000 ## [10,] 3 4 0.004 ## [11,] 3 5 0.460 ## [12,] 3 6 0.467 ## [13,] 4 5 0.001 ## [14,] 4 6 0.003 ## [15,] 5 6 0.911 9.2.1.7 Example writeup for one-way between-subjects ANOVA For our illustrative example, results of hypothesis tests conducted using robust procedures did not disagree with the results of the ANOVA and pairwise comparisons of means. This was expected given the assumptions were not severely violated. When the robust analyses and conventional analyses yield the same decisions about all hypothesis tests, results of the conventional analyses can be reported due to their greater familiarity to most readers. A possible write up for our illustrative example would be: An ANOVA was performed to investigate whether the gender attitudes scores differ across education level. The means,standard deviations, skewness and kurtosis values of the gender scores, grouped by the highest-degree obtained, are presented in Table 1. The analysis of variance indicated a significant difference in the gender attitudes scores , F(5,564) = 7.27, p &lt; .001, \\(\\hat\\eta^2_G=.06\\). Table 2 is the ANOVA table for this analysis. Pairwise comparisons were planned a’ priori. The familywise error rate was selected for control and the Holm procedure (Holm (1979)) was used. The results of the pairwise comparisons are presented in the Table 3. Nine out of fifteen comparisons yielded statistically significant results; (primary school vs lycee, primary school vs 2-year-collage, primary school vs undergraduate,… (provide details). Robust statistical procedures yielded the same conclusions. 9.2.1.8 Missing data techniques for one-way between-subjects ANOVA To be added 9.2.1.9 Power calculations for one-way between-subjects ANOVA To be added 9.2.2 Two-Factor Between Subjects ANOVA This topic concerns designs in which there are two between-subjects factors: factor A with J levels and factor B with K levels for a total of JK combinations of levels; each combination is called a cell. The factors are between-subjects if (a) different subjects appear in each cell and (b) subjects are not matched in any way. In the simplest version of this design, each factor has two levels. For example, consider if a researcher is interested in the effect of the gender and college education on the gender attitudes scores. The following is a depiction of a study designed to investigate these two factors. non-college college Female \\(\\mu_{11}\\) \\(\\mu_{12}\\) \\(\\mu_{1\\cdot}\\) Male \\(\\mu_{21}\\) \\(\\mu_{22}\\) \\(\\mu_{2\\cdot}\\) \\(\\mu_{\\cdot 1}\\) \\(\\mu_{\\cdot 2}\\) Also shown are the parameters about which hypotheses will be tested: the population cell means (\\(\\mu_{11}, \\mu_{12}, \\mu_{21},\\mu_{22}\\)), row means ( \\(\\mu_{1 \\cdot}\\), \\(\\mu_{2 \\cdot}\\)) and column means (\\(\\mu_{\\cdot 1}\\), \\(\\mu_{\\cdot 2}\\)). The general term for a row or column mean is a marginal mean. Symbolically the hypothesis of no interaction can be written as \\(H_0: \\mu_{11} - \\mu_{12} = \\mu_{21} - \\mu_{22}\\). The interation is also a comparison of the two simple effects of gender \\((\\mu_{21}−\\mu_{11} and \\mu_{22} − \\mu_{12})\\) leading to the null hypothesis \\(H_0: \\mu_{21}−\\mu_{11}= \\mu_{22}- \\mu_{12}\\). If one of the null hypotheses is true the other must also be true and if one is false the other must also be false. Interaction The first null hypothesis of interest is the hypothesis of no interaction between the two factors. Before defining an interaction, we first define a simple main effect. A simple main effect refers to differences among the cell means in a particular row or in a particular column. In the current example, there are two types of simple main effects: simple main effects of gender and simple main effects of college education. For each level of graduation from college type there are two simple main effects gender: the simple main effect of gender at college graduates (\\(\\mu_{12}\\) versus \\(\\mu_{22}\\)) and the simple main effect of gender at non-college graduates (\\(\\mu_{11}\\) versus \\(\\mu_{21}\\)). The interaction is a comparison of these two effects. For each type there are two simple main effects. There is a simple main effect of gender at college graduates (\\(\\mu_{12}\\) versus \\(\\mu_{22}\\)) and a simple main effect of gender at non-college graduates (\\(\\mu_{11}\\) versus \\(\\mu_{21}\\)). There is a simple main effect of education for Female (\\(\\mu_{11}\\) versus \\(\\mu_{12}\\)) and a simple main effect of education for Male (\\(\\mu_{21}\\) versus \\(\\mu_{22}\\)). The main effects Effects defined in terms of marginal (row and column) means are called main effects. Symbolically, the main effect of gender is \\(\\mu_{1\\cdot} - \\mu_{2\\cdot}\\), and the hypothesis of no main effect due to gender is \\(H_0:\\mu_{1\\cdot} - \\mu_{2\\cdot} = 0\\). Similarly, the hypothesis of no main effect due to college education is \\(H_0:\\mu_{\\cdot 1} - \\mu_{\\cdot 2} = 0\\). When there is an interaction: Inspection of the main effect for a factor is misleading when the directions of the simple main effects of the factor are not the same at all levels of the second factor. It is a matter of opinion as to whether it is misleading to inspect the main effect for a factor the directions of the simple main effects of the factor are the same at all levels of the second factor. When the main effect is misleading about the effect of a factor, the cell means are the proper basis for studying the effects of the factor. The structural model for a two-factor between subjects ANOVA is \\(Y_{ijk}=\\mu+\\alpha_{j}+\\beta_k + \\alpha\\beta_{jk}+ \\epsilon_{ij}\\), in which \\(Y_{ijk}\\) is the score for the participant i in first factor level j , and the second factor level k; \\(\\mu\\) is the grand mean of the scores, \\(\\alpha_j\\) is the effect of the level j of the first factor, \\(\\beta_k\\) is the effect of the level k of the second factor, \\(\\alpha\\beta_{jk}\\) is the interaction effect and \\(\\epsilon_{ij}\\) is the error term (nuisance). SV df F A \\(J-1\\) \\(\\frac{MS_A}{MS_{S/AB}}\\) B \\(K-1\\) \\(\\frac{MS_B}{MS_{S/AB}}\\) AB \\((J-1)(K-1)\\) \\(\\frac{MS_{AB}}{MS_{S/AB}}\\) S/AB \\(N-JK\\) Total \\(N-1\\) 9.2.2.1 Type I, II and III sum of squares As we pointed out in the section on one-way between-subjects designs, the F test of the main effect is the same for all three types of sums of squares. This is not true in designs with two or more between-subjects factors. In designs with three or more between-subjects of effects F tests for interaction other than the highest order interaction can vary across the types of sums of squares. Selecting among the three types can be an important decision and we refer the reader to Carlson and Timm (1974) for a discussion of the issues in selecting among the three types of sums of squares in experimental studies and to Appelbaum and Cramer (1976) for a discussion of the issues in survey studies. 9.2.2.2 R codes for a two-way between-subjects ANOVA For illustrative purposes, the city of Kayseri is subsetted from the DataWBT (Section 2.3). The gender attitudes scores is the dependent variable, gender and higher education indicator are the between subjects factors. Step 1: Set up data and report descriptive # load csv from an online repository urlfile=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataWBT=read.csv(urlfile) #remove URL rm(urlfile) #select the city of Izmir # listwise deletion for gen_att and education variables dataWBT_Kayseri=na.omit(dataWBT[dataWBT$city==&quot;KAYSERI&quot;,c(&quot;id&quot;,&quot;gen_att&quot;,&quot;higher_ed&quot;,&quot;gender&quot;)]) # Higher education is coded as 0 and 1, change it to non-college, college dataWBT_Kayseri$HEF=droplevels(factor(dataWBT_Kayseri$higher_ed, levels = c(0,1), labels = c(&quot;non-college&quot;, &quot;college&quot;))) #table(dataWBT_Kayseri$gender) #table(dataWBT_Kayseri$HEF) #drop empty levels dataWBT_Kayseri$gender=droplevels(dataWBT_Kayseri$gender) with(dataWBT_Kayseri, table(gender,HEF)) ## HEF ## gender non-college college ## Female 99 50 ## Male 67 36 # set the number of decimals (cosmetic) options(digits = 3) #get descriptives library(doBy) library(moments) desc2BW=as.matrix(summaryBy(gen_att~HEF+gender, data = dataWBT_Kayseri, FUN = function(x) { c(n = sum(!is.na(x)), mean = mean(x,na.rm=T), sdv = sd(x,na.rm=T), skw=moments::skewness(x,na.rm=T), krt=moments::kurtosis(x,na.rm=T)) } )) # Table 4 desc2BW ## HEF gender gen_att.n gen_att.mean gen_att.sdv gen_att.skw ## 1 &quot;non-college&quot; &quot;Female&quot; &quot;99&quot; &quot;1.93&quot; &quot;0.424&quot; &quot;-0.548&quot; ## 2 &quot;non-college&quot; &quot;Male&quot; &quot;67&quot; &quot;2.32&quot; &quot;0.419&quot; &quot;-0.191&quot; ## 3 &quot;college&quot; &quot;Female&quot; &quot;50&quot; &quot;1.80&quot; &quot;0.346&quot; &quot; 0.263&quot; ## 4 &quot;college&quot; &quot;Male&quot; &quot;36&quot; &quot;2.13&quot; &quot;0.543&quot; &quot; 0.159&quot; ## gen_att.krt ## 1 &quot;2.51&quot; ## 2 &quot;3.18&quot; ## 3 &quot;1.94&quot; ## 4 &quot;2.25&quot; #write.csv(desc2BW,file=&quot;twowayB_ANOVA_desc.csv&quot;) Step 2: Inspect assumptions require(ggplot2) ggplot(dataWBT_Kayseri, aes(x = gen_att)) + geom_histogram(aes(y = ..density..),col=&quot;black&quot;,binwidth = 0.2,alpha=0.7) + geom_density(size=1.5) + theme_bw()+labs(x = &quot;Gender Attitudes by HEF and Gender in Kayseri&quot;)+ facet_wrap(~ HEF+gender)+ theme(axis.text=element_text(size=14), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 9.3: Gender Attitudes by HEF and Gender Departures from the normality do not seem to be severe. require(ggplot2) ggplot(dataWBT_Kayseri, aes(x=gender, y=gen_att))+ geom_boxplot()+ facet_grid(.~HEF)+ labs(x = &quot;Gender&quot;,y=&quot;Gender Attitude by Gender and HEF in Kayseri&quot;) Figure 9.4: Gender Attitudes by Degree Variances look similar. Step 3: Run ANOVA The ezANOVA function (Lawrence (2016)) reports the F test, the Levene Test and an effect size. Type of the effect size depends on the model and indirectly depends on the type of sum of squares used. The type argument (1,2 or 3) transmits the choice. library(ez) #the ezANOVA function throws a warning if id is not a factor dataWBT_Kayseri$id=as.factor(dataWBT_Kayseri$id) #alternative 1 the ezANOVA function alternative1 = ezANOVA( data = dataWBT_Kayseri, wid=id, dv = gen_att, between = .(HEF,gender),observed=.(HEF,gender),type=2) ## Warning: Data is unbalanced (unequal N per group). Make sure you specified ## a well-considered value for the type argument to ezANOVA(). alternative1 ## $ANOVA ## Effect DFn DFd F p p&lt;.05 ges ## 1 HEF 1 248 6.739 9.99e-03 * 0.022436 ## 2 gender 1 248 45.389 1.12e-10 * 0.151106 ## 3 HEF:gender 1 248 0.251 6.17e-01 0.000837 ## ## $`Levene&#39;s Test for Homogeneity of Variance` ## DFn DFd SSn SSd F p p&lt;.05 ## 1 3 248 0.469 17.5 2.22 0.0867 # Type III SS # alternative1b = ezANOVA( # data = dataWBT_Kayseri, # wid=id, dv = gen_att, between = HEF+gender,type=3) # # alternative1b # critical F value qf(.95,1,248) ## [1] 3.88 9.2.2.3 Robust estimation and hypothesis testing for a two-way between-subjects design Several approaches to conducting a robust two-way between subjects ANOVA, have been presented by Wilcox (2012) One of the convenient robust procedure , a heteroscedastic two-way ANOVA for trimmed means, has been compressed into the t2way function, available via WRS-2 (Mair and Wilcox (2016)). Please use ?t2way for the current details, this promising package is being improved frequently . library(WRS2) #t2way # 20% trimmed t2way(gen_att~HEF*gender,data=dataWBT_Kayseri,tr=.2) ## Call: ## t2way(formula = gen_att ~ HEF * gender, data = dataWBT_Kayseri, ## tr = 0.2) ## ## value p.value ## HEF 7.1310 0.011 ## gender 20.2039 0.001 ## HEF:gender 0.0855 0.772 # 10% trimmed t2way(gen_att~HEF*gender,data=dataWBT_Kayseri,tr=.1) ## Call: ## t2way(formula = gen_att ~ HEF * gender, data = dataWBT_Kayseri, ## tr = 0.1) ## ## value p.value ## HEF 8.4235 0.005 ## gender 33.1599 0.001 ## HEF:gender 0.0361 0.850 # 5% trimmed t2way(gen_att~HEF*gender,data=dataWBT_Kayseri,tr=.05) ## Call: ## t2way(formula = gen_att ~ HEF * gender, data = dataWBT_Kayseri, ## tr = 0.05) ## ## value p.value ## HEF 6.1688 0.015 ## gender 29.8383 0.001 ## HEF:gender 0.1642 0.687 9.2.2.4 Example writeup two-way between-subjects ANOVA For our illustrative example, robust procedures did not disagree with our initial analyses. This was expected given the assumptions were not severely violated. When the robust analyses yield very similar results, we prefer to report initial results to ease communication. A possible write up for our illustrative example would be: Descriptive statistics for the gender attitudes scores as a function of gender and higher education in the city of Kayseri are presented in Table 4. A 2x2 ANOVA was reported. F tests were conducted at \\(\\alpha=.05\\). There was a significant difference for gender \\(F(1,248)=45.39, p&lt;.001\\). There was also a significant difference for the college effect \\(F(1,248)=6.24, p=.013\\). However, there was no significant interaction between the gender and higher education status, \\(F(1,248)=0.25, p=.617\\). The ezANOVA (Lawrence (2016)) function reported generalized eta hat squared (\\(\\hat\\eta^2_G\\)) of 0.15 for the gender effect and 0.02 for the college-effect. Table 5 is the ANOVA table for these analyses. 9.2.2.5 Follow ups for two-way between-subjects ANOVA To be added. 9.2.2.5.1 Pairwise comparisons following two-way between-subjects ANOVA To be added. 9.2.2.5.2 Contrats comparisons following two-way between-subjects ANOVA To be added. 9.2.2.6 Missing data techniques for two-way between-subjects ANOVA To be added 9.2.2.7 Power calculations for two-way between-subjects ANOVA To be added 9.3 Within Subjects ANOVA This procedure can be used when there are score on the same participants under several treatments or at several time points and is then called repeated measures ANOVA. It can also be used in blocking designs and is then called randomized block ANOVA. Compared to between-subjects designs, this procedure is expected to eliminate influence of individual differences, in other words, to reduced variability, and thus, to reduce error. This development results in more power than independent-samples ANOVA with the same sample size. Of course there are issues other than power that must be considered in selecting a design. For example, if the goal is to compare reading achievement under three instructional methods, using a design in which each participant is exposed to the three methods will be problematic because the effect of exposure to one treatment will continue to influence reading ability during the other treatments. 9.3.1 One-way Within-Subjects ANOVA The structural model following Myers et al. (2013) notation for a non-additive model; \\[\\begin{equation} Y_{ij}=\\mu + \\eta_i + \\alpha_j + (\\eta \\alpha)_{ij} + \\epsilon_{ij} \\tag{9.1} \\end{equation}\\] where i represents the individual, i=1,…,n; j represents the levels of the within-subjects factor (i.e, the repeated measurement or the treatment factor), j=1,…,P. Y is the score; \\(\\mu\\) is the grand mean; \\(\\eta_i\\) represents the difference between individual’s average score over the levels and the grand mean; \\(\\alpha_j\\) represents the difference between the average score under level j of the within-subjects factor and the grand mean; \\((\\eta \\alpha)_ij\\) represents the interaction, and \\(\\epsilon_{ij}\\) represent the error component. Because \\((\\eta \\alpha)_ij\\) and \\(\\epsilon_{ij}\\) have the same subscripts, they are confounded. Generally, the interest is on \\(\\alpha_j\\). This interest leads to hypothesis testing: \\[H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_P\\] The alternative hypothesis states that at least one population mean is different. The ANOVA table for a one-way with-subjects ANOVA is; SV df F Subjects (S) \\(n-1\\) Waves (A) \\(P-1\\) \\(\\frac{MS_A}{MS_{SA}}\\) SA \\((n-1)(P-1)\\) Total \\(nP-1\\) Note on additivity The simplest explanation of additivity is the situation that would justify \\((\\eta \\alpha)_ij = 0\\) in Equation (9.1). This unrealistic restriction implies that the effect of levels of the within-subject factor waves is the same for all individuals. Shown below in Table 9.1 are data for an experiment in which each person participates in four treatments defined by the amount of alcohol consumed. The dependent variable is a reaction time measure. Table 9.1: Original Alcohol Data id noALC twoOZ fouroz sixoz 1 1 2 5 7 2 2 3 5 8 3 2 3 6 8 4 2 3 6 9 5 3 4 6 9 6 3 4 7 10 7 3 4 7 10 8 6 5 8 11 Treatment means, treatment standard deviations, and subject means are shown below. A subject mean is the average of the four scores for that subject. # set the number of decimals (cosmetic) options(digits = 2) #participants mean apply(owadata,1, mean) ## [1] 3.2 4.0 4.4 4.8 5.4 6.0 6.2 7.6 #treatment mean apply(owadata[,-1],2, mean) ## noALC twoOZ fouroz sixoz ## 2.8 3.5 6.2 9.0 #treatment sd apply(owadata[,-1],2,sd) ## noALC twoOZ fouroz sixoz ## 1.49 0.93 1.04 1.31 Because each participant has a score for each treatment, amount of alcohol is a within-subjects factor and it is possible to calculate a correlation for each pair of treatments. These correlations, which are presented in Table 9.2, indicate that reaction time is highly correlated for each pair of treatments. Recall that corresponding to each correlation there is a covariance; \\[Cov_{pp^`}=S_pS_{p^`}r_{pp^`}\\] where \\(p\\) and \\(p&#39;\\) are two levels of the alcohol consumption factor. For example the correlation between the scores in the first two levels of the alcohol consumption factor is \\(r_{02}=0.93\\). And the corresponding covariance is \\(Cov_{02}=1.5*0.9*0.93=1.26\\) Table 9.2: Correlation Coefficients for Reaction Time Data noALC twoOZ fouroz sixoz noALC 1.00 0.93 0.88 0.88 twoOZ 0.93 1.00 0.89 0.94 fouroz 0.88 0.89 1.00 0.95 sixoz 0.88 0.94 0.95 1.00 The alcohol consumption factor is a within-subjects factor. Consequently the F statistic for comparing the four treatment means should be appropriate for a design with a within-subjects factor. Let P = the number of levels of the within-subjects factor, in the example P=4 ; \\(\\bar C\\) = the average covariance; in the example \\(\\bar C\\) = 1.26. The appropriate F statistic is \\[F_W=\\frac{MS_A}{MS_{SA}}=\\frac{MS_A}{MS_{S/A}- \\bar C}\\] where \\(MS_A\\) and \\(MS_{S/A}\\) are calculated as they are for a between-subjects factor and the W emphasizes the F statistic is for a within-subjects factor. The critical value is \\(F_{\\alpha,P-1,(P-1)(n-1)}\\) . The denominator mean square, \\(MS_{SA}\\) , is read mean square Subjects x A where A is the generic label for the treatment factor. Recall that the F statistic for a between-subjects factor is \\(F_B=MS_A/MS_{S/A}\\). Comparison of \\(F_W\\) and \\(F_B\\) shows that \\(F_W\\) incorporates the correlations between the pairs of treatments and \\(F_B\\) does not. (Recall that, in like fashion, the dependent samples t statistic incorporates the correlation whereas the independent samples t statistic does not.) As a result, when applied to a design with a within-subjects factor \\(F_W \\geq F_B\\).Therefore, incorrectly using will usually result in a loss of power. 9.3.1.1 Assumptions of one-way within-subjects ANOVA Sphericity is an assumption about the pattern of variances and covariances.If the data are spherical, the difference between each pair of repeated measures has the same variance for all pairs. Example covariance matrix; \\(Y_1\\) \\(Y_2\\) \\(Y_3\\) \\(Y_1\\) 10 7.5 10 \\(Y_2\\) 7.5 15 12.5 \\(Y_3\\) 10 12.5 20 Sphericity holds; \\(Y_p-Y_{p&#39;}\\) \\(\\sigma^2_p + \\sigma^2_{p&#39;} - 2\\sigma_{pp&#39;}\\) \\(Y_1-Y_2\\) 10+15-2(7.5)=10 \\(Y_1-Y_3\\) 10+20-2(10)=10 \\(Y_2-Y_3\\) 15+20-2(12.5)=10 Box’s epsilon —measures how severely sphericity is violated. \\[\\frac{1}{P-1}\\leq \\epsilon \\leq 1\\] Estimates of \\(\\epsilon\\) are Greenhouse-Geisser (\\(\\hat \\epsilon\\)) and Huynh-Feldt (\\(\\tilde{\\epsilon}\\)) \\(\\tilde{\\epsilon}\\) can be larger than 1.0; if it is \\(\\tilde{\\epsilon}\\) is set equal to 1.0. Critical value assuming sphericity is \\(F_{alpha,(P-1),(n-1)(P-1)}\\). Approximately correct critical value when sphericity is violated \\(F_{alpha,\\epsilon (P-1),\\epsilon (n-1)(P-1)}\\). normality of errors in Equation (9.1), \\(\\epsilon_{ij}\\) is assumed to be normally and independently distributed with a mean value of zero. normality of \\(\\eta_i\\) in Equation (9.1), \\(\\eta_{i}\\) is assumed to be normally and independently distributed with a mean value of zero. Together the assumptions listed immediately above imply that the repeated measures are drawn from a multivariate normal distribution. 9.3.1.1.1 The relationship between additivity and sphericity Although assumptions can be stated in terms of \\(\\eta_{i}\\) and \\(\\epsilon_{ij}\\), a simpler approach is that the repeated measures are drawn from a multivariate normal distribution with covariance matrix that meets the sphericity assumption. If the data meet the sphericity assumption, the difference between each pair of repeated measures has the same variance for all pairs. Assuming that the data are drawn from a multivariate normal distribution and within each level of the within-subjects factor the scores are independent, having equal variance and covariances (compound symmetry) is a sufficient condition for the F test on the within-subjects factor to be valid. If additivity holds and the equal variance assumption holds then compound symmetry holds. But compund symmetry is a stricter assumption than the sphericity. Considering that sphericity is a necessary and sufficient requirement for the F test on the within-subjects factor to be valid (assuming that data are drawn from a multivariate normal distribution and scores are independent within each level of the within-subjects factor the) checking for spericity is more important than checking for additivity. In addition because there are adjusted degrees of freedom procedures that adjust the F test on the within-subjects factor for violation of sphericity, it is not necessary to test for sphericity. 9.3.1.2 R codes for a one-way within-subjects ANOVA For illustrative purposes, a subsample from an original cluster randomized trial study (for details see Daunic et al. (2012)) was taken. The subsample included 1 control-classroom and 17 students. The variable of interest is the problem solving knowledge. Each wave was approximately one year apart. Higher scores mean higher knowledge. Step 1: Set up data #enter data PSdata=data.frame(id=factor(1:17), wave1=c(20,19,13,10,16,12,16,11,11,14,13,17,16,12,12,16,16), wave2=c(28,27,18,17,29,18,26,21,15,26,28,23,29,18,26,21,22), wave3=c(21,24,14,8,23,15,21,15,12,21,23,17,26,18,14,18,19)) Report descriptive # set the number of decimals (cosmetic) options(digits = 3) ##the long format will be needed #head(PSdata) library(tidyr) data_long = gather(PSdata, wave, PrbSol, wave1:wave3, factor_key=TRUE) #get descriptives library(doBy) library(moments) desc1W=as.matrix(summaryBy(PrbSol~wave, data = data_long, FUN = function(x) { c(n = sum(!is.na(x)), mean = mean(x,na.rm=T), sdv = sd(x,na.rm=T), skw=moments::skewness(x,na.rm=T), krt=moments::kurtosis(x,na.rm=T)) } )) # Table 6 desc1W ## wave PrbSol.n PrbSol.mean PrbSol.sdv PrbSol.skw PrbSol.krt ## 1 &quot;wave1&quot; &quot;17&quot; &quot;14.4&quot; &quot;2.91&quot; &quot; 0.311&quot; &quot;2.10&quot; ## 2 &quot;wave2&quot; &quot;17&quot; &quot;23.1&quot; &quot;4.67&quot; &quot;-0.224&quot; &quot;1.64&quot; ## 3 &quot;wave3&quot; &quot;17&quot; &quot;18.2&quot; &quot;4.77&quot; &quot;-0.315&quot; &quot;2.45&quot; #write.csv(desc1W,file=&quot;onewayW_ANOVA_desc.csv&quot;) The covariance matrix might be helpful. # check covariance Table 7 cov(PSdata[,-1]) ## wave1 wave2 wave3 ## wave1 8.49 8.85 9.87 ## wave2 8.85 21.81 18.49 ## wave3 9.87 18.49 22.78 Step 2: Check assumptions ggplot(data_long, aes(x=wave, y=PrbSol))+ geom_boxplot()+ labs(x = &quot;Wave&quot;,y=&quot;Problem Solving Knowledge scores&quot;) Figure 9.5: Problem Solving Knowledge score by wave We will test for the sphericity assumption using Mauchly’s test integrated in the ezANOVA function, but this graph implies that it might be violated. require(ggplot2) ggplot(data_long, aes(x=wave, y=PrbSol, group=id))+ geom_line() + labs(x = &quot;Wave&quot;,y=&quot;Problem Solving Knowledge scores&quot;) Figure 9.6: Problem Solving Knowledge score by wave, line graph This graph, which plots the problem solving scores by wave, suggests that the \\(\\eta \\beta_{ij}\\) interaction terms are not likely to all be zero; therefore assuming sphericity while testing the hypothesis of equal wave means is not likely to be justified. The tukey.add.test function in asbio (Aho (2016)) investigates \\(H_0\\) : main effect and blocks are additive. library(asbio) with(data_long,tukey.add.test(PrbSol,wave,id)) ## ## Tukey&#39;s one df test for additivity ## F = 5.943 Denom df = 31 p-value = 0.021 # if additivity exists a randomized block approach might be appropriate #additive=with(data_long,lm(PrbSol~id+wave)) #anova(additive) The Tukey additive test rejects the null hypothesis of additivity agrees with the line graph. In other words, a non-additive model is more appropriate for the problem solving knowledge data. Step 3: Run ANOVA (including checks for the sphericity and normality of residuals assumptions) The ezANOVA function (Lawrence (2016)) reports the F test, the Levene Test and an effect size. Type of the effect size depends on the model and indirectly depends on the type of sum of squares used, the type argument (1,2 or 3) transmits the choice. library(ez) #alternative 1 the ezANOVA function alternative1 = ezANOVA( data = data_long, wid=id, dv = PrbSol, within = wave, detailed = T,return_aov=T) alternative1 ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 (Intercept) 1 16 17510 680 412.0 7.62e-13 * 0.954 ## 2 wave 2 32 647 169 61.2 1.16e-11 * 0.433 ## ## $`Mauchly&#39;s Test for Sphericity` ## Effect W p p&lt;.05 ## 2 wave 0.918 0.526 ## ## $`Sphericity Corrections` ## Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF] p[HF]&lt;.05 ## 2 wave 0.924 6.17e-11 * 1.04 1.16e-11 * ## ## $aov ## ## Call: ## aov(formula = formula(aov_formula), data = data) ## ## Grand Mean: 18.5 ## ## Stratum 1: id ## ## Terms: ## Residuals ## Sum of Squares 680 ## Deg. of Freedom 16 ## ## Residual standard error: 6.52 ## ## Stratum 2: id:wave ## ## Terms: ## wave Residuals ## Sum of Squares 647 169 ## Deg. of Freedom 2 32 ## ## Residual standard error: 2.3 ## Estimated effects may be unbalanced PrbSolres=sort(alternative1$aov$id$residuals) qqnorm(PrbSolres);qqline(PrbSolres) Figure 9.7: Inhibit model residuals The distribution of the residuals is not severely non-normal. The aov function is the second alternative. # alternative 2 the aov function summary(aov(PrbSol ~ wave + Error(id/wave), data=data_long)) ## ## Error: id ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Residuals 16 680 42.5 ## ## Error: id:wave ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## wave 2 647 324 61.2 1.2e-11 *** ## Residuals 32 169 5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 9.3.1.3 Robust estimation and hypothesis testing for a one-way within-subjects design One of the convenient robust procedures, a heteroscedastic one-way repeated measures ANOVA for trimmed means, has been compressed into the rmanova function, available via WRS-2 (Mair and Wilcox (2016)). library(WRS2) #rmanova # 20% trimmed with(data_long,rmanova(PrbSol,wave,id,tr=.20)) ## Call: ## rmanova(y = PrbSol, groups = wave, blocks = id, tr = 0.2) ## ## Test statistic: 34.9 ## Degrees of Freedom 1: 1.9 ## Degrees of Freedom 2: 19 ## p-value: 0 9.3.1.4 Example writeup one-way within-subjects ANOVA Descriptive statistics for the problem solving knowledge scores at each wave are presented in Table 6. The covariance matrix is presented in Table 7. A one-way within ANOVA was reported. F test was conducted at \\(\\alpha=.05\\). The assumptions of one-way within subjects ANOVA are satisfied. There was a significant difference between waves \\(F(2,32)=61.2, p&lt;.001\\). The ezANOVA function reported a generalized eta hat squared (\\(\\hat\\eta^2_G\\)) of 0.43. 9.3.1.5 Follow ups for one-way within-subjects ANOVA To be added. 9.3.1.6 Missing data techniques for one-way within-subjects ANOVA To be added. 9.3.1.7 Power calculations for one-way within-subjects ANOVA To be added. 9.4 Mixed Design To be added. References "],
["correlation.html", " 10 Correlation 10.1 Pearson correlation coefficient 10.2 Spearman’s rho and Kendall’s tau 10.3 Biserial and Point-Biserial Correlation Coefficients with R 10.4 Phi Correlation Coefficient with R 10.5 Issues in Interpreting Correlation Coefficients", " 10 Correlation In our chapter 7, we introduced descriptive statistics; mean, variance, median, kurtosis, etc. These descriptive statistics aimed to ease the communication for a single variable. In other words, instead of transferring the entire raw data set to a colleague (or to a machine), providing these descriptives is generally satisfying and easier. However when the interest is in the association between variables, other measures are needed. The sum of cross products, \\(S_{XY}=\\sum(X-\\bar X)(Y- \\bar Y)\\), can provide some information about the association. For example Figure 10.1 depicts an X and a Y variable. The sum of cross products for these two variables is zero. ## x y deviationX deviationY crossPRODUCT ## 1 1.00 0.00 0.93 0.00 0.00 ## 2 0.90 0.43 0.83 0.43 0.36 ## 3 0.62 0.78 0.56 0.78 0.44 ## 4 0.22 0.97 0.16 0.97 0.15 ## 5 -0.22 0.97 -0.29 0.97 -0.28 ## 6 -0.62 0.78 -0.69 0.78 -0.54 ## 7 -0.90 0.43 -0.97 0.43 -0.42 ## 8 -1.00 0.00 -1.07 0.00 0.00 ## 9 -0.90 -0.43 -0.97 -0.43 0.42 ## 10 -0.62 -0.78 -0.69 -0.78 0.54 ## 11 -0.22 -0.97 -0.29 -0.97 0.28 ## 12 0.22 -0.97 0.16 -0.97 -0.15 ## 13 0.62 -0.78 0.56 -0.78 -0.44 ## 14 0.90 -0.43 0.83 -0.43 -0.36 ## 15 1.00 0.00 0.93 0.00 0.00 Figure 10.1: Sum of cross products=0 The covariance between two variable is simply \\(Cov_{XY}=S_{XY}/n-1\\), but its a scale dependent measure, the correlation coefficient on the other hand generally has its bounds. 10.1 Pearson correlation coefficient Pearson introduced a correlation coefficient in 1896. This coefficient ranges between -1 and +1, can be calculated as \\(Cov_{XY}/S_X S_Y\\). This coefficient measures the linear relationship between two variables. Figure 10.1 depicts a correlation of zero. Even though X and Y in this figure are related to form a 14-sided polygon, the relation is not linear. Hence the correlation is zero. Figure 10.2 depicts several other associations; (A) is a perfect positive linear relationship, (B)is a positive correlation of .7, (C) substantially no linear relation, (D) is a correlation of -.4 and (E) is a correlation of -1. Figure 10.2: Correlation examples 10.1.1 Inference on a Pearson correlation coefficient Information from the sample (\\(r\\)) can be utilized to make judgement about the population (\\(\\rho\\)). The z transformation , assuming a bivariate normality and a sample size of at least 10 (Myers et al. (2013)), is a helpful procedure to reach a judgement. The transformation equation is; \\[z_r = \\frac{1}{2}ln \\left( \\frac{1+r}{1-r} \\right)\\] The standard error is; \\[\\sigma_r = \\frac{1}{\\sqrt{n-3}}\\] Hence the confidence intervals are \\(z_r \\pm z_{\\alpha / 2} \\sigma_r\\). Back transformation is needed to make interpretation about the correlation coefficient; \\(r=\\frac{e^{2z_r}-1}{e^{2z_r}+1}\\). Utilizing a normal distribution, a null hypothesis can be tested; \\[z=\\frac{z_r - z_{\\rho_{null}}}{\\frac{1}{\\sqrt{n-3}}}\\] The t distribution can also be utilized to test \\(H_0:\\rho=0\\). \\[t=r\\sqrt{\\frac{n-2}{1-r^2}}\\] The distribution for this statistic follows a t distribution with a degrees of freedom of \\(n-2\\). 10.1.2 R codes for Pearson Correlation coefficent For illustrative purposes we selected the city of Bayburt. The Pearson correlation is computed for the association between the Gender Attitudes scores and the annual income per person. The income per person is calculated as “total household income” divided by the “total number of residents in the house”. # load csv from an online repository urlfile=&#39;https://raw.githubusercontent.com/burakaydin/materyaller/gh-pages/ARPASS/dataWBT.csv&#39; dataWBT=read.csv(urlfile) #remove URL rm(urlfile) #select the city of Elazig # listwise deletion for gen_att and education variables dataWBT_Bayburt=dataWBT[dataWBT$city==&quot;BAYBURT&quot;,] #hist(dataWBT_Bayburt$income_per_member) The bivariate distribution can be seen in 10.3. This is an interactive graph, please use your mouse to inspect it, created with the rgl package (Adler and Murdoch (2017)). ## wgl ## 1 Figure 10.3: Gender Attitudes and Income Bivariate normality seems to be violated. For comparison, below graph 10.4.depicts a bivarite normal distribution with r=0.7. Nevertheless, for illustrative purposes we use these data to test the null hypothesis \\(H_0: \\rho=0\\) against the non-directional alternative hypothesis \\(H_1: \\rho \\neq0\\).The scatter plot is provided in 10.5. Figure 10.4: Bivariate Normal Distribution Figure 10.5: Bayburt: Gender attitudes vs income scatterplot The correlation between these two variables is computed by the cor function in the stats package (R Core Team (2016b)). The cor.test function in the same package performs the t-test and provides a confidence interval based on Fisher’s z transformation. #use ?cor to see use=&quot;complete.obs&quot; is doing casewise deletion with(dataWBT_Bayburt,cor(gen_att,income_per_member, use = &quot;complete.obs&quot;,method=&quot;pearson&quot;)) ## [1] 0.0664 with(dataWBT_Bayburt,cor.test(gen_att,income_per_member, alternative = &quot;two.sided&quot;, method=&quot;pearson&quot;, conf.level = 0.95, na.action=&quot;na.omit&quot;)) ## ## Pearson&#39;s product-moment correlation ## ## data: gen_att and income_per_member ## t = 0.8, df = 100, p-value = 0.4 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.102 0.232 ## sample estimates: ## cor ## 0.0664 These procedures can easily be hard coded.Stating \\(H_0: \\rho=0\\) and \\(H_0: \\rho \\neq 0\\) sample_r=0.06641641 r0=0 #the null sample_n=137 # the number of complete.cases zr=(0.5)*log((1+sample_r)/(1-sample_r)) # Z transformasyonu z0=(0.5)*log((1+r0)/(1-r0)) # Z transformasyonu sigmar=1/(sqrt(sample_n-3)) #the z test statistic (zr-z0)/sigmar ## [1] 0.77 ll=zr-(qnorm(0.975)*sigmar) # lower limit ul=zr+(qnorm(0.975)*sigmar) # upper limit (exp(2*ll)-1)/(exp(2*ll)+1) #transformback ## [1] -0.102 (exp(2*ul)-1)/(exp(2*ul)+1) #transformback ## [1] 0.232 t=sample_r*(sqrt((sample_n-2)/(1-sample_r^2))) qt(c(.025, .975), df=(sample_n-2)) ## [1] -1.98 1.98 p.value = 2*pt(-abs(t), df=sample_n-2) p.value ## [1] 0.441 A percentile bootstrap method might perform satisfactorily as a robust approach (Myers et al. (2013)) #Calculate 95% CI using bootstrap (normality is not assumed) set.seed(31012017) B=5000 # number of bootstraps alpha=0.05 # alpha #gender attitudes and income originaldata=dataWBT_Bayburt2 #add id originaldata$id=1:nrow(originaldata) output=c() for (i in 1:B){ #sample rows bs_rows=sample(originaldata$id,replace=T,size=nrow(originaldata)) bs_sample=originaldata[bs_rows,] output[i]=cor(bs_sample$gen_att,bs_sample$income_per_member) } output=sort(output) ## Non-directional # lower limit output[as.integer(B*alpha/2)] ## [1] -0.138 # d star upper output[B-as.integer(B*alpha/2)+1] ## [1] 0.252 # investigate the WRS package # library(WRS2) # pball(originaldata[,-3]) There are alternatives to percentile bootstrapping for a correlation coefficient, extensively discussed by Wilcox (2012). The WRS 2 package offers two alternatives, the percentage bend correlation and the Winsorized correlation. Only for illustrative purposes below is an R code; # investigate the WRS package library(WRS2) pbcor(dataWBT_Bayburt2$gen_att,dataWBT_Bayburt2$income_per_member,beta=.2) ## Call: ## pbcor(x = dataWBT_Bayburt2$gen_att, y = dataWBT_Bayburt2$income_per_member, ## beta = 0.2) ## ## Robust correlation coefficient: -0.0351 ## Test statistic: -0.407 ## p-value: 0.684 wincor(dataWBT_Bayburt2$gen_att,dataWBT_Bayburt2$income_per_member,tr=.2) ## Call: ## wincor(x = dataWBT_Bayburt2$gen_att, y = dataWBT_Bayburt2$income_per_member, ## tr = 0.2) ## ## Robust correlation coefficient: -0.0197 ## Test statistic: -0.229 ## p-value: 0.82 Write up: We tested a null hypothesis stating the gender attitudes scores and income variable are correlated against an non-directional alternative hypothesis. The Pearson correlation coefficient was \\(r=.066,p=.44\\), the confidence interval with a .05 probability of a type I error using the z transformation is -.10 to .23. The null hypothesis is retained. This conclusion is consistent with the bootstrap results, using 5000 iterations, the 95% CI is -.138 to .252. Sign difference note The Pearson correlation coefficent is .066 but not significantly different than zero. The WRS package functions also agreed to retain the null but the coefficent was negative. The income variable was sligthly skewed due to a small number of relatively large income values. In fact, when the World Bank team analyzed the data using a regression, they top-coded and transformed the income variable (for details Hirshleifer et al. (2016)). Let us top-code and transform the income variable, inspect bivariate normality and calculate the Pearson correlation; Figure 10.6: Top-coded and transformed income variable with(dataWBT_Bayburt2,cor.test(gen_att,incomeTC, alternative = &quot;two.sided&quot;, method=&quot;pearson&quot;, conf.level = 0.95, na.action=&quot;na.omit&quot;)) ## ## Pearson&#39;s product-moment correlation ## ## data: gen_att and incomeTC ## t = -0.009, df = 100, p-value = 1 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.169 0.167 ## sample estimates: ## cor ## -0.00081 Top-coding and transforming the income variable produced a distribution relatively closer to normal. The sign of the Pearson correlation coefficent is negative. 10.2 Spearman’s rho and Kendall’s tau When the data is in the rank format, or there is a need for protection against outliers10 when working with continuous data the Spearman correlation coefficient is used. If the number of ties in the ranks is not large, procedures provided for the Pearson correlation coefficient can be utilized. Setting the method argument to “spearman”, the cor.test function first transforms the data into ranks and performs the procedures introduced for the Pearson coefficient. 10.2.1 The R code for Spearman’s rho and Kendall’s tau We calculated the Pearson correlation coefficient to assess the association between the gender attitudes scores and the income for the participants in Bayburt. The Spearman correlation coefficient can conveniently be calculated by R; #use ?cor to see use=&quot;complete.obs&quot; is doing casewise deletion with(dataWBT_Bayburt,cor.test(gen_att,income_per_member, alternative = &quot;two.sided&quot;, method=&quot;spearman&quot;, conf.level = 0.95, na.action=&quot;na.omit&quot;, exact=FALSE)) ## ## Spearman&#39;s rank correlation rho ## ## data: gen_att and income_per_member ## S = 5e+05, p-value = 0.6 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## -0.0508 When there are ties, the cor.test function corrects the Spearman coefficient but the exact p value can not be calculated. Instead exact=FALSE argument yields a p value based on a t distribution. Field, Miles, and Field (2012) suggests using Kendall’s tau with large number of ties; #use ?cor to see use=&quot;complete.obs&quot; is doing casewise deletion with(dataWBT_Bayburt,cor.test(gen_att,income_per_member, alternative = &quot;two.sided&quot;, method=&quot;kendall&quot;, conf.level = 0.95, na.action=&quot;na.omit&quot;, exact=FALSE)) ## ## Kendall&#39;s rank correlation tau ## ## data: gen_att and income_per_member ## z = -0.6, p-value = 0.5 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## -0.0373 The exact=FALSE argument with method=“kendall” uses normal approximation. The Spearman correlation between the gender attitudes scores and income was \\(r_S=-.051, p=.56\\), and the Kendall’s tau was \\(\\tau = -.037,p=.54\\) 10.3 Biserial and Point-Biserial Correlation Coefficients with R The association between a continuous variable and a dichotomously reflected latent continious variable can be examined with a biserial correlation. In psychometrics , for example, biserial correlation is used for calculating the correlation between a total test score (continuous) and a dichotomous item score (assumed to underlie a latent variable). For illustrative purposes let us use dichotomized item111 and the gender attitudes score. The biserial function in the psych (Revelle (2016)) package can calculate the bi-serial correlation; dataWBT_Bayburt$binitem1=ifelse(dataWBT_Bayburt$item1==4,1,0) require(psych) with(dataWBT_Bayburt,biserial(gen_att,binitem1)) ## [,1] ## [1,] 0.317 The point-biserial correlation is calculated for an association between a dichotomous variable and a continuous variable. The cor.test function with method=“pearson” can be used to calculate a point-biserial correlation. The association between the gender and the gender attitudes scores is examined below; dataWBT_Kayseri=dataWBT[dataWBT$city==&quot;KAYSERI&quot;,] dataWBT_Kayseri$genderNUM=ifelse(dataWBT_Kayseri$gender==&quot;Female&quot;,1,0) with(dataWBT_Kayseri,cor.test(gen_att,genderNUM, alternative = &quot;two.sided&quot;, method=&quot;pearson&quot;, conf.level = 0.95, na.action=&quot;na.omit&quot;)) ## ## Pearson&#39;s product-moment correlation ## ## data: gen_att and genderNUM ## t = -7, df = 200, p-value = 2e-10 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.487 -0.277 ## sample estimates: ## cor ## -0.387 10.4 Phi Correlation Coefficient with R When the two variables are dichotomous, a phi (\\(\\phi\\)) correlation coefficient is calculated. For illustrative purposes we calculated the phi coefficent between the gender and the wage variable. This variable equals to “yes” if one of the house members receives wage in the past 12 months. The phi function in the psych package requires the 2 x 2 matrix of frequencies to calculate the phi coefficient. dataWBT_Kayseri=dataWBT[dataWBT$city==&quot;KAYSERI&quot;,] table(dataWBT_Kayseri$gender,dataWBT_Kayseri$wage01) ## ## No Yes ## Female 52 97 ## Male 49 54 ## Unknown 0 0 genderWAGE=matrix(c(52,49,97,54),ncol=2) library(psych) phi(genderWAGE) ## [1] -0.13 phi(genderWAGE) ## [1] -0.13 10.5 Issues in Interpreting Correlation Coefficients Several issues arise in interpreting correlation coefficients. Causation A correlation coefficient does not imply causation. For any correlation there are at least four possible interpretations involving cuasation: (a) X causes Y, (b) Y causes X, (c) both X and Y share one or more common causes, and (d) X and Y have different causes, but these causes are correlated. The magnitude Whether a correlation of .6 is large or not depends on the context. For example suppose the .6 is the correlation between scores on two forms of a standardized achievement tests. This correlation is called an alternate forms reliability coefficient. Alternate forms reliability coefficients for standardized tests are expected to be at least .70 and preferably higher, so the .6 correlation would be regarded as small. Now suppose the correlation is between GRE scores and GPA. The correlation between GRE scores and GPA is typically somewhere between .10 and .30, so a .60 correaltion would be a very large correlation coefficient. Outliers Correlation coefficients can be misleading when the data set contains outliers. Reliability If either X or Y contains measurement error, the effect of the measurement error is to attenuate the correlation coefficient. Attenuate means to make the correlation coefficient closer to zero than it would have been if there had been no measurement error. Its possible to correct for attenuation using \\[r_{T_x T_y}=\\frac{r_{xy}}{\\sqrt(r_{xx}r_{yy})}\\] where \\(r_{xx}\\) and \\(r_{yy}\\) is the reliability coefficients. • When NOT to correct for attenuation: When a variable is used for practical decision making and we are interested in the validity of those decisions, we should NOT correct for attenuation because the decisions are made on the basis of an observed variable, not a true variable. • When to correct for attenuation: We can correct for attenuation when our motivation is to examine theory. • Comparison of Correlation Coefficients: A comparison of correlation coefficients for two variables with a third variable can be affected by differences in reliability for the first two variables. If we are interested in theoretical relationships between variables and we want to compare the strength of relationship of two constructs (call these A and B and let them be measured by X1 and X2 ) with a third (call this C and let it be measured by Y), the comparison of the strength of relationship between A and C to the strength of relationship between B and C is compromised if X1 and X2 have different reliability coefficients. To compare strength of relationship we want the reliability of X1 and X2 to be the similar. Of course, it is best if both reliability coefficients are high, but it is critical that that are quite similar. Unit of analysis A correlation calculated for one unit of analysis (e.g., individuals without regard to school) should not be applied to other units of analysis (i.e., individuals within schools or school means). Variance in the two variables being correlated The correlation coefficient for two variables can be strongly affected by the amount of variance for the variables being correlated. Other things being equal when the variance of either or both variables is small, the correlation will tend to be small. If the variance for either or both variables is artificially small, misleading small correlation coefficients can occur. Variance can be artificially small due to • Categorizing Based on Quantitative Variables • Limited Range Scales • Restriction of range • Floor and Ceiling Effects References "],
["multiple-linear-regression-a-short-introduction.html", " 11 Multiple Linear Regression, A Short Introduction 11.1 Matricies and Least Square Estimation", " 11 Multiple Linear Regression, A Short Introduction Scientiﬁc development requires that knowledge be transferred reliably from one study to another and, as Galileo showed 350 years ago, such transference requires the precision and computational beneﬁts of a formal language. Pearl (2009) The formal language in the quote refers to mathematical equations. Galton for example, in late 1800s, used equations to describe the relationship between the weights of mother and daughter pea seeds. Galton’s work followed by Pearson’s contributions led to initial idea of regression.12 In the year 2016, the Web of Science reported that 60000+ abstracts of academic articles included the term “regression”. The literature is vast, oftentimes the regression is mentioned as the workhorse. It is extensively used by frequentist and Bayesian statisticians, and more generally by data scientists in hundreds of different disciplines. The explanation of the popularity of regression analysis is simple, unless they are simulated by a machine, connections between variables, whether observed or latent variables, in a data set requires more complex statistical solutions than are provided by correlation coefficients. It is not feasible to cover regression in a book chapter. We briefly introduce basics of a relatively simple multiple regression model. 11.1 Matricies and Least Square Estimation In a multiple regression framework, demonstrating process of model fitting based on matrices and least squares estimation should have at least two benefits; (a) a simple demystification of the procedure, (b) a workable and sensible foundation for readers with a desire to move further in the advanced topics. The following sections use two different data sets. The first data set includes only 12-cases to show calculations and is named the synthetic data. The second data is simulated with a larger sample size for illustrative purposes and is named the simulated data. Consider a case in which data on three variables are collected and the researcher is interested in the relationship of one of the variables (i.e., the dependent variable) to the other two variables (i.e., the independent variables). Further, these three variables as continuous. The regression model in this scenario is \\[Y_i=\\beta_0 + \\beta_1X_{i1}+ \\beta_2X_{i2}+ \\epsilon_i\\] where i represents individuals i=1,…,n, Y is the dependent variable, \\(X_1\\) and \\(X_2\\) are independent variables, \\(\\beta\\)s are the regression coefficients and \\(\\epsilon\\) is the random error term(residuals) . This model can be presented in a matrix equations \\[Y=X\\beta+\\epsilon\\] In this more general form, all the independent variables are represented in the X matrix and the regression coefficients are represented by the \\(\\beta\\) matrix. Let us assume the researcher has the following data id Y X1 X2 ind 1 8 0 3 ind 2 4 -2 1 ind 3 6 6 3 ind 4 6 -2 0 ind 5 5 5 0 ind 6 9 4 2 ind 7 7 3 3 ind 8 -6 -4 -5 ind 9 -8 -4 -6 ind 10 -1 -3 0 ind 11 0 -2 -2 ind 12 5 -1 1 This synthetic data set has only 12 cases. The researcher can form 2 matrices and use these to calculate \\(\\hat\\beta\\), the estimate of \\(\\beta\\). \\[Y=\\begin{bmatrix} 8\\\\ 4\\\\ 6\\\\ 6\\\\ 5\\\\ 9\\\\ 7\\\\ -6\\\\ -8\\\\ -1\\\\ 0\\\\ 5 \\end{bmatrix},X=\\begin{bmatrix} 1 &amp; 0 &amp; 3\\\\ 1 &amp; -2 &amp; 1\\\\ 1 &amp; 6 &amp; 3\\\\ 1 &amp; -3 &amp; 0\\\\ 1 &amp; 5 &amp; 0\\\\ 1 &amp; 4 &amp; 2\\\\ 1 &amp; 3 &amp; 3\\\\ 1 &amp; -4 &amp; -5\\\\ 1 &amp; -4 &amp; -6\\\\ 1 &amp; -3 &amp; 0\\\\ 1 &amp; -2 &amp; -2\\\\ 1 &amp; -1 &amp; 1 \\end{bmatrix}\\] Using the least square procedure the \\(\\beta\\) coefficients can easily be estimated; \\[\\begin{equation} \\hat\\beta=(X&#39;X)^{-1}X&#39;Y \\tag{11.1} \\end{equation}\\] Let’s calculate this with R for the synthetic-data; Y=matrix(c(8,4,6,6,5,9,7,-6,-8,-1,0,5),ncol=1) X=matrix(cbind(rep(1,12), c(0,-2,6,-2,5,4,3,-4,-4,-3,-2,-1), c(3,1,3,0,0,2,3,-5,-6,0,-2,1)),ncol=3) solve(t(X)%*%X)%*%t(X)%*%Y ## [,1] ## [1,] 2.917 ## [2,] 0.199 ## [3,] 1.552 The regression equation is \\[\\hat Y_i=2.9167 + 0.1989X_{i1} + 1.5519X_{i2} \\] where \\(\\hat Y_i\\) is the predicted value for the \\(i^{th}\\) individual. Equation (11.1) was derived to minimize the error sum of squares: \\(\\sum_{i=1}^n(Y_i-\\hat{Y_i})^2=Y&#39;Y-\\beta&#39;X&#39;X\\beta\\).These estimates are Best Linear Unbiased Estimates. Each independent variable has a mean of zero because they are mean-centered. Therefore, zero represents a score at the center of the distribution for both \\(X_1\\) and \\(X_2\\) and is therefore an interpretable score for both \\(X_1\\) and \\(X_2\\). When both predictors are zero (at their mean), the \\((\\hat{Y_i})\\) is 2.92. That is, for participants with independent variables scores equal to the mean on both independent variables the expected dependent variable score is 2.92. An increase in \\(X_1\\) of 1 unit is predicted to correspond to an increase of 0.20 units in Y when the \\(X_2\\) variable is held constant. Similarly, an increase in \\(X_2\\) of 1 unit is predicted to correspond to an increase of 1.55 units in Y while controlling for \\(X_1\\). The term “controlling for” (“ceteris paribus”) is necessary to describe the effect of an independent variable in a multiple regression. The coefficients .20 and 1.55 would provide information about the association of the dependent and independent variables, if the researcher had substantial understanding of the unit of measurement for the independent variables, that is, the importance of a “1 unit” change in each variable. 11.1.1 a) “Essentially, all models are wrong, but some are useful.” This aphorism belongs to Box and Draper (1987). The researcher should provide a convincing discussion about the relevance of the variables included in the regression model to the research questions addressed by the research. If there are important omitted variables, the beta coefficients are probably not valid. Hence the researcher is obligated to provide justifications on variable selections to claim usefulness of the results. Consider the case below ; #omit X2 from the synthetic-data X2omitted=matrix(cbind(rep(1,12),c(0,-2,6,-2,5,4,3,-4,-4,-3,-2,-1)),ncol=2) solve(t(X2omitted)%*%X2omitted)%*%t(X2omitted)%*%Y ## [,1] ## [1,] 2.92 ## [2,] 1.09 For our synthetic data, \\(X_1\\) and \\(X_2\\) had a correlation of .68. If the researcher fails to include \\(X_2\\) in the model, the coefficient for \\(X_1\\) is estimated to be 1.09. This is a dramatic change from 0.20. Omitting predictors that are related to both the other predictors in the model and the dependent variable will cause the coefficients for the variables that have not been omitted to be misleading. Therefore an important part of the theoretical justification of a regression model is a discussion of variables that may have been omitted.13 In addition to omitted variable issue, the validity of the results from a regression model (the usefulness) is also directly related to the sampling process and appropriate reflection of this process in the model. For example, if sampling weights exist they should not be ignored in the analyses. Sampling and regression is beyond the scope of this chapter. 11.1.2 b) Strength of relationship between the dependent and independent variables The sum of squares for Y, which is also known as the total sum of squares, can be decomposed into two parts, the model sum of squares, which is also the sum of squares for the predicted values, and the error sum of squares. The ratio of the model sum of squares to the total sum of squares, is called the sample squared multiple correlation coefficient and symbolized as \\(R^2\\). The coefficient \\(R^2\\) measures the strength of association between the dependent variable and the independent variables. Examine the R code below given for the synthetic data; # SS total n=length(Y) TotalSS=t(Y)%*%Y-(n*mean(Y)^2) # SS Model betahat=solve(t(X)%*%X)%*%t(X)%*%Y ModelSS=t(betahat)%*%t(X)%*%Y-(n*mean(Y)^2) ModelSS/TotalSS ## [,1] ## [1,] 0.879 Also known as coefficient of determination, \\(R^2\\) is a biased estimator of the population squared multiple correlation coefficient. A more nearly unbiased estimate is the adjusted squared multiple correlation coefficient. One benefit of adjusted \\(R^2\\) is computational simplicity. Examine the R code below given for the synthetic data Rsquared=ModelSS/TotalSS #sample size n=12 #the number of predictors p=2 # include intercept? 1 for yes, 0 for no int_inc=1 AdjustedRsquared=1-(1-Rsquared)*((n-int_inc)/(n-int_inc-p)) AdjustedRsquared ## [,1] ## [1,] 0.852 \\(R^2\\) and \\(R^2_{Adj}\\) are useful coefficients; they provide information on how much of the variance is explained. Note that in this example \\(R^2 = .879\\) and \\(R^2_{Adj}= .852\\) are very similar. However if were \\(R^2 = .25\\) then \\(R^2_{Adj}\\) would be .08. When \\(R^2\\) is 1, the model successfully explains 100% of the variance in Y and when \\(R^2\\) is 0 the model does not explain any of the variance in Y. The coefficients \\(R^2\\) and \\(R^2_{Adj}\\) are also useful for comparing the strength of relationship for different set of predictors to predict a specific outcome. The interpretation of the \\(R^2\\) is similar to the interpretation of a correlation coefficient. Depending on the context a small \\(R^2\\) value might be regarded as substantial, or an \\(R^2\\) value of .7 might be regarded as low. 11.1.3 c) Residuals and influential data points Residuals provide information for assessing potential problems with the model. Inspecting residuals can provide information about deviations from the assumed linearity of the relationships of the dependent variables to the independent variable. Inspecting the distributional properties of residuals is needed to provide evidence for the validity of statistical inference. For example, because the normality assumption is made when conducting significance tests and calculating confidence interval, residuals should follow a straight line on a Quantile-Quantile (QQ) plot. Examine the R code below given for the synthetic data: #Predicted values Yhat=X%*%betahat residuals=Y-Yhat residuals ## [,1] ## [1,] 0.4276 ## [2,] -0.0708 ## [3,] -2.7658 ## [4,] 3.4811 ## [5,] 1.0888 ## [6,] 2.1839 ## [7,] -1.1691 ## [8,] -0.3615 ## [9,] -0.8096 ## [10,] -3.3199 ## [11,] 0.5850 ## [12,] 0.7303 qqnorm(residuals) There are three common types of residuals; • Unstandardized residuals, that is, \\(Y_i-\\hat{Y_i}\\). Unstandardized residuals are on the same scale as Y. • Standardized residuals: The residuals divided by the overall standard deviation of residuals; Standardized residuals are on a z-score scale (M = 0, SD = 1). When residuals are assumed to be normally distributed, it is common practice to identify outliers as Y values for which the absolute value of the standardized residual is larger than 2. However, it should be noted that this practice can be misleading because outliers can cause the regression coefficients to be poorly estimated and/or can increase the standard deviation of the residuals and both effects can cause poor outlier detection. In addition, if the residual are in fact normally distributed approximately %5 of the participants will have residuals beyone +/- 2.00. See Wilcox (2012) for more information about outlier detection. • Studentized residual: A studentized residual is ratio of the unstandardized residual to the estimated standard error of the residual. When investigating residuals , these three types of residuals generally lead to same conclusions. The standardized residual are forced have a z-scale, and thus, -2 and +2 are commonly pronounced cut offs. The studentized residuals are connected to the t distribution; \\(t_{n-p&#39;-1}\\) where n is the sample size \\(p&#39;\\) is the number of coefficients in the model (i.e intercept+two predictors =3). It is argued that when detecting outliers in residuals, investigating the studentized residuals is more convenient (Rawlings, Pantula, and Dickey (1998)). Scatter plots of residuals vs. predicted values can provide information about whether the assumed linear relationships between the independent variables and the dependent variable are adequate. Ideally the scatter plot should not show a detectable pattern. Here is a plot of studentized residuals vs fitted values, from a regression model fitted to simulated-data in which the linearity assumption is adequate. The simulated data have a sample size of 500 and two independent variables. #simulate data library(mvtnorm) sigma &lt;- matrix(c(4,2,2,3), ncol=2) xx &lt;- rmvnorm(n=500, mean=c(0,0), sigma=sigma) yy=5+xx[,1]*2+xx[,2]*-3+rnorm(500,0,1.5) model=lm(yy~xx[,1]+xx[,2]) errors=rstudent(model) predicted=predict(model) #Standardized Residuals vs Yhat library(ggplot2) plotdata=data.frame(errors,predicted) ggplot(plotdata, aes(x = predicted, y = errors)) + geom_point() + geom_hline(yintercept=0)+ ylab(&quot;Studentized residuals&quot;)+ theme_bw()+stat_smooth() The blue line above, which is determined independently from the regression model, should be compared to the horizontal line at 0. The more similar the two lines, the less likely the linearity assumption is violated. Here is a plot, studentized residuals vs fitted values, from a mis-specified regression model on a simulated-data. The sample size is 100, there are two independent variables, and the relationship of Y and X2 is quadratic. #simulate data library(mvtnorm) sigma &lt;- matrix(c(4,2,2,3), ncol=2) xx &lt;- rmvnorm(n=100, mean=c(10,10), sigma=sigma) yy=150+(xx[,1]*4)+(xx[,2]*-3)+(xx[,2]^2*1.2)+rnorm(100,0,3) model=lm(yy~xx[,1]+xx[,2]) errors=rstudent(model) predicted=predict(model) #Studentized Residuals vs Yhat library(ggplot2) plotdata=data.frame(errors,predicted) ggplot(plotdata, aes(x = predicted, y = errors)) + geom_point() + geom_hline(yintercept=0)+ylab(&quot;Studentized residuals&quot;)+ theme_bw()+stat_smooth() There is a pattern indicating that the model is omitting a quadratic association.However, this graph does not inform about the source of the quadratic association, see non-linearity section below. Unusual residuals should be inspected. Even when the residuals are substantially normally distributed and there is substantially no-pattern for the residual vs predicted value plot, there might be unusual residuals. Deciding whether a residual is unusual or not (e.g 3,4 or 5 standard deviation above), and more importantly whether to keep the observation in the data set or not requires justifications. Examine the code below to simulate data and examine the studentized residuals: #simulate data set.seed(04022017) library(mvtnorm) sigma &lt;- matrix(c(4,2,2,3), ncol=2) xx &lt;- rmvnorm(n=100, mean=c(10,10), sigma=sigma) yy=(xx[,1]*4)+(xx[,2]*-3)+rnorm(100,0,3) tempdata=data.frame(yy,xx,id=1:100) model=lm(yy~X1+X2,data=tempdata) tempdata$SUTresiduals=rstudent(model) # how many of the residuals are larger than a critical value? # lets use alpha=.05 sum(abs(tempdata$SUTresiduals)&gt;qt(c(.975), df=100-3-1)) ## [1] 8 #which observations? tempdata[which(abs(tempdata$SUTresiduals)&gt;qt(c(.975), df=100-3-1)),] ## yy X1 X2 id SUTresiduals ## 13 21.39 11.49 10.29 13 2.02 ## 32 8.85 11.96 10.65 32 -2.20 ## 43 15.80 11.14 7.56 43 -1.99 ## 50 9.21 8.00 10.21 50 2.53 ## 51 19.96 10.11 8.97 51 2.02 ## 68 25.33 10.96 8.33 68 2.04 ## 84 2.03 7.94 7.84 84 -2.03 ## 91 5.51 10.74 10.25 91 -2.10 Assume we justified the use of \\(t_{.975,96}\\) as the critical value, in which alpha=.05. We should expect approximately \\(n * .05\\) (in our case 100*.05=5) cases larger than the critical value. In this particular case, even though 8 cases were identified, none of them seems unusual. If the researcher detects an abnormality and further, if the researcher decides to remove the observation from the data, it should be done one observation at a time. The justification of removing a data point should be given clearly. A better alternative, on the other hand, may be to use an estimation method that is robust to outlying data points. R program is convenient for investigating influential data points. Examine ?influence.measures below for the simulated data set; summary(influence.measures(model)) ## Potentially influential observations of ## lm(formula = yy ~ X1 + X2, data = tempdata) : ## ## dfb.1_ dfb.X1 dfb.X2 dffit cov.r cook.d hat ## 12 0.08 -0.02 -0.08 -0.10 1.12_* 0.00 0.08 ## 33 0.09 -0.03 -0.07 -0.11 1.11_* 0.00 0.07 ## 41 -0.01 -0.03 0.03 -0.04 1.10_* 0.00 0.06 ## 42 0.05 -0.12 0.07 0.13 1.11_* 0.01 0.07 ## 50 0.20 -0.40 0.21 0.47 0.88_* 0.07 0.03 ## 64 -0.03 0.03 0.00 0.04 1.10_* 0.00 0.06 ## 100 0.01 0.13 -0.15 -0.18 1.10_* 0.01 0.07 This output reports 5 different measures. In this example, cases 12, 33, 41, 42, 50, 64 and 100 are reported to be potentially influential. As they highlighted by an asterisk, they labeled as potential using the covariance ratio criteria (cov.r). This value reports the impact of an observation on the sampling variances of the regression coefficients. Values larger than \\(1+(3p&#39;/n)\\) and lower than \\(1-(3p&#39;/n)\\) are labeled as influential, in our case, n=100 and p’=3, hence the cut offs are 1.09 and .91. The Dfb (DFBETAS) for each predictor reports how much the coefficient for the predictor changes when the case is removed. It is the difference between the two coefficients divided by an estimate of the standard error of the new coefficient and therefore is on the scale of a t statistic. R places an asterisk if the value is larger than \\(2/\\sqrt(n)\\). For this specific illustration the cut off value is \\(2/\\sqrt(100)=.2\\). The dffit reports the change in the predicted value for the \\(i^{th}\\) case when the \\(i^{th}\\) case is removed from the data. The criterion for identifying potentially influential data points is \\(2*\\sqrt{\\frac{p&#39;}{n}}\\). Cook’s distance (cook.d) measures the influence of a particular case on all of the estimated coefficients and values larger than \\(F_{.5,p&#39;,n-p&#39;}\\) are highlighted. Cook’s distance also measures influence of omitting a particular case of the predicted values for all of the remaining cases. Leverage Values (Hat Diag) measure the distance of an observation compared to other independent variables. Values larger than \\(2p’/n\\) are considered to identify potentially influential data points. It is researcher’s responsibility to examine any potentially influential data points. 11.1.4 d) Equal variance assumption The standard errors of the of the coefficients are calculated as the square roots of the diagonal elements of \\(\\hat\\sigma^2(X′X)^{-1}\\), where \\(\\hat\\sigma^2\\) is the variance of the residuals. Examine the code below given for the synthetic data set: When using the OLS with an assumption of normally distributed Y variable, the distribution of \\(\\beta\\) can be obtained. Examine the code below given for the synthetic-data set; #Residuals s2 &lt;- (t(residuals) %*% residuals)/(nrow(Y)-nrow(betahat)) Var_betahat &lt;- s2[1,1]*solve(t(X)%*%X) The equation \\(\\sigma^2 (X&#39;X)^{-1}\\) is valid under the assumption of homogeneity, that is, observations on the Y variable have a common variance controlling for the independent variables. In other words, every observation of Y has the same amount of information (Rawlings, Pantula, and Dickey (1998)). With this assumption, regression coefficients are selected to minimize \\(\\sum_{i=1}^n(Y_i-\\hat{Y_i})^2\\). In this expression equal weights are given to the residuals for every case.. If homogeneity is questionable the estimator can be modified to allow for unequal weights or replaced. Alternatively the Y variable can be transformed or the estimator of the standard error can be modified (see package ‘sandwich’ Lumley and Zeileis (2015)). Otherwise, the standard error of \\(\\hat\\beta\\) could be underestimated or overestimated. Underestimation results in Type I error rates that are larger than the alpha level used in hypothesis tests and confidence intervals and over estimation results in reduced statistical power. It is common practice to plot residuals against the predicted values to study heterogeneity. Examine the code below to simulate data with unequal variance and examine the studentized residuals: #simulate data set.seed(03032017) library(mvtnorm) sigma &lt;- matrix(c(1,.7,.7,1), ncol=2) xx &lt;- rmvnorm(n=100, mean=c(1,1), sigma=sigma) #heteroscedasticity function hts=function(v1,v2){2+.5*v1+.5*v2} yy=5+xx[,1]*5+xx[,2]*5+rnorm(100,0,hts(xx[,1],xx[,2])) model=lm(yy~xx[,1]+xx[,2]) #summary(model) errors=rstudent(model) predicted=predict(model) #Studentized Residuals vs Yhat library(ggplot2) plotdata=data.frame(errors,predicted) ggplot(plotdata, aes(x = predicted, y = errors)) + geom_point() + geom_hline(yintercept=0)+ylab(&quot;Studentized residuals&quot;)+ geom_segment(mapping=aes(xend = predicted, yend = 0)) + theme_bw() The variance with smaller \\(\\hat Y\\) values are smaller. Below is a graph for a regression model on a simulated data with equal variance. 11.1.5 e) Hypothesis testing The F test is used within a multiple regression framework to test \\(H_0: \\beta_1=...=\\beta_p=0\\) , a hypothesis stating that the p regression coefficients are all equal to zero in the population. The alternative hypothesis states that at least one coefficient is not zero. The null hypothesis can be tested using the statistic \\(MS_{regression}/MS_{residual}\\). This statistic follows an F distribution with \\(p\\) and \\(n-p&#39;\\) degrees of freedom. As mentioned earlier, p is the number of predictors and p’ is the number of coefficients (p’=p if there is no intercept). Examine the code below given for the synthetic data, setting Type I error rate = .05; # Model SS and Total SS calculated before dfREG=2 #(p=2, predictors X1 and X2) dfRES=9 #(n-p&#39;, 12-3) MSreg=ModelSS/dfREG MSres=(TotalSS-ModelSS)/dfRES MSreg/MSres ## [,1] ## [1,] 32.8 #critical F qf(.95,dfREG,dfRES) ## [1] 4.26 1-pf(MSreg/MSres,dfREG,dfRES) ## [,1] ## [1,] 7.39e-05 The t-test is used for investigating \\(H_0:\\beta_{X}=\\beta_{hyp}\\) vs \\(H_1:\\beta_{X}\\neq\\beta_{hyp}\\). Most commonly \\(\\beta_{hyp}=0\\) The statistic \\((b_X-\\beta_{hyp})/SE(b_X)\\) follows a t-distribution with N-p’ degrees of freedom.Examine the code below given for the synthetic-data; # test if the coefficient for X2 is different than 0 Bhyp=0 #hypothesized value # estimated coefficient for X2 (see betahat calculated before) bx2=betahat[3] # estimated SE for X2 (see var_betahat calculated before) se_bx2=sqrt(Var_betahat[3,3]) #t statistic (bx2-Bhyp)/se_bx2 ## [1] 5.33 # t critic qt(.975,9) ## [1] 2.26 #p value 2*(pt(-abs((bx2-Bhyp)/se_bx2),9)) ## [1] 0.000478 11.1.6 f) Variable Selection Broadly speaking there are two situations in which multiple regression is used to analyze data. The first is illustrated by the following example. A social science researcher conducts an extensive literature review, identifies all independent variables relevant to the research questions, collects the data, estimates a model in which all independent variables are included and reports results for this model. The second is illustrated by an example in which the researcher has data on a very large set of variables and does not know prior to analyzing the data which variables will be included in the final model that will be reported. This might happen because the researcher is working in a relatively new research area and collects data on a wide variety of variables or is conducting a secondary data analysis of a data set with a wide variety of predictors. In either case the researcher may want to begin by conducting variable selection that is using statistical results to select the best subset of many independent variables. There are several approaches to select the best subset of predictors. For example, stepwise regression, backward selection or forward selection is covered in many sources. However, in our experience, when applied to the same data set these three approaches are likely to give different answers. A convenient approach with R is to study all possible regressions.For introductory purposes, examine the code below given for a simulated data set; #simulate data set.seed(02082017) library(mvtnorm) sigma=matrix(c(5.899559,4.277045,3.906341, 4.277045,5.817412,3.654419, 3.906341,3.654419,5.642258),ncol=3) xx &lt;- rmvnorm(n=200, mean=c(0,0,0), sigma=sigma) yy=5+xx[,1]+xx[,2]*1.5+xx[,3]*2+rnorm(200,0,3) simdata=data.frame(yy,xx,id=1:200) library(leaps) formula &lt;- formula(paste(&quot;yy ~ &quot;, paste(names(simdata[2:4]), collapse=&quot; + &quot;))) allpossreg &lt;- regsubsets(formula,nbest=3,data=simdata) aprout &lt;- summary(allpossreg) #this functions reports more than R-squared and adjusted R-squared #examine str(aprout) APRtable=with(aprout,round(cbind(which,rsq,adjr2),3)) APRtable=data.frame(APRtable,check.rows = F,row.names = NULL) APRtable$ppri=rowSums(APRtable[,1:4]) kable(APRtable) X.Intercept. X1 X2 X3 rsq adjr2 ppri 1 0 1 0 0.753 0.751 2 1 0 0 1 0.696 0.695 2 1 1 0 0 0.630 0.629 2 1 0 1 1 0.871 0.870 3 1 1 0 1 0.811 0.809 3 1 1 1 0 0.808 0.806 3 1 1 1 1 0.890 0.888 4 This table reports that intercept and \\(X_2\\) only model results in an \\(R^2\\) value of .753. When all predictors included, the \\(R^2\\) reaches to .890; however, excluding the X1 from the full model reduced the \\(R^2\\) only by .019. Below is a graphical decpiction. require(ggplot2) ggplot(APRtable, aes(x=ppri-1, y=rsq)) + geom_point(shape=1,size=3)+ scale_y_continuous(breaks = seq(0.5, 1, by = 0.05)) + scale_x_continuous(breaks = seq(0, 3, by = 1))+ theme_bw()+labs(x = &quot;R-squared&quot;)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) ggplot(APRtable, aes(x=ppri-1, y=adjr2)) + geom_point(shape=1,size=3)+ scale_y_continuous(breaks = seq(0.5, 1, by = 0.05)) + scale_x_continuous(breaks = seq(0, 3, by = 1))+ theme_bw()+labs(x = &quot;Adjusted R-squared&quot;)+ theme(axis.text=element_text(size=15), axis.title=element_text(size=14,face=&quot;bold&quot;)) Figure 11.1: All Possible Regressions 11.1.7 g) Colliniearity Collinearity is the degree to which the predictors are correlated among themselves. The correlation between predictors is a concern in regression because the standard errors of the coefficients increase as collinearity increase and therefore collinearity hides the individual contribution of each predictor in the regression equation. As an illustration suppose there are two independent variables with r = .9. You MIGHT have two types of problems: The regression coefficients become unstable (i.e. they would vary a great deal across different samples obtained from the same population). You may obtain a statistically significant \\(R^2\\) but not statistically significant regression coefficients. Variance inflation factor (VIF) is helpful to detect collinearity in regard to a particular independent variables and can be applied in models two or more independent variables. The formula is \\(VIF_x=\\frac{1}{1-R^2_X}\\) where \\(R^2_X\\) is the \\(R^2\\) when the predictor is regressed on the remaining independent variables. Large VIF values are indicator of possible multicollinearity. Commonly pronounced cut off values are 4 and 10, however VIF values are indirectly affected by sample size and variance (Obrien (2007)). When large VIF values are detected, the researcher should examine the problem. It might be justifiable to (a) leave out one of the highly correlated predictor, (b) combine the two highly correlated variable. The decision should be made cautiously given that the possible solution might be more problematic than a large VIF value, see Obrien (2007). Examine the code below given for a simulated data set; #check correlations among predictors cor(simdata[,2:4]) ## X1 X2 X3 ## X1 1.00 0.730 0.640 ## X2 0.73 1.000 0.666 ## X3 0.64 0.666 1.000 #the largest correlation is.73 #no multicollinearity expected library(car) vif(lm(yy~X1+X2+X3,data=simdata)) ## X1 X2 X3 ## 2.36 2.50 1.98 # no problematic VIF values 11.1.8 h) Non-linearity In the presence of a non-linear relation between the dependent variable and any given independent variable, ignoring non-linearity is simply a validity concern due to the omitted variable issue. Examining the residuals is helpful to detect non-linearity. Residuals should be plotted against predicted and independent variables. A common practice is to include higher order variables in the model, for example, if the plot indicates a non linear pattern for \\(X_k\\) against residuals, \\(X_k^2\\) might be needed in the model. The type of the non-linearity , such as quadratic, cubic or quartic should be treated accordingly. Gelman and Hill (2007) , commenting on age variable when the age and dependent variable are not linearly associated, prefers treating the variable as a categorical predictor. Alternatively transformations of the dependent or independent variable may be employed. 11.1.9 i) Correlated errors and nonindependent errors Errors should not be correlated or more broadly should be independent. When such dependency is not addressed, regression results are invalid. This topic ,however, is well beyond the scope of this introductory material. Correlated errors are likely to distort the standard errors for the beta coefficients. This is not desired. In social sciences, correlated errors might be present when measurements are repeated. Multilevel models and latent growth models has been developed to address appropriate modeling of repeated measure designs. Nesting of participants in subgoups is another common source of non-independent errors in social sciences. Multilevel models are one popular solution to model clustered data. 11.1.10 j) Centering and Scaling Consider an example in which mother’s age at the date of her child’s birth (maternal age) is used to predict IQ at age 10. The intercept estimates average IQ for children whose mother’s maternal age was zero and cannot be meaningfully interpreted. Centering maternal age around its mean results in an intercept which estimates average IQ for children whose mother’s maternal age was at the mean of the sample and can be meaningfully interpreted. Or consider predicting absences from work from an anxiety measure. A score of zero is possible score on the anxiety measure, but does not occur in the sample. The intercept estimates average absences for employees whose anxiety level is outside the range of the data and therefore represents an extrapolation for the data. Centering around the mean for the sample solves this problem. Another approach would be to center around an anxiety score that is in the range of the data and considered high. Or consider a study of income and an index of health. Income is on a scale in which a change of 1 represents a change of 1 dollar in income. The regression coefficient is .001, which represents a trivial change in the index. Dividing X by 1000 so that a change of 1 represents a change of 1000 dollars in income results in a regression coefficient of 1, which is a small but not trivial change in the index may make the results easier to think about. 11.1.11 k) Standardized coefficients A related topic to linear transformations is to use a z-score for the continious predictors by substracting the mean and dividing by the standard deviation. Depending on the nature of the variable, using the z scores might ease the communication between researchers. Here are interpretation examples; Raw scores: An increase in anxiety of 1 unit is predicted to correspond to an increase of 3 units in achievement, holding the remaining predictors constant. z-scores: An increase in motivation of 1 standard deviation is predicted to correspond to an increase of 0.25 standard deviations in achievement, holding the the remaining predictors constant. 11.1.12 l) Interactions We covered the basic idea of interaction in our ANOVA section. Ignoring an interaction is an omitted variable problem because an interaction affects the interpretation of main effects. For example, suppose a researcher investigates the relationship between mathematics achievement at the end of the school year (\\(Y\\)), effort measured by voluntary homework completed and submitted during the year (\\(X_1\\)), and mathematics achievement at the end of the preceding year (\\(X_2\\)). Using the model \\(Y_i=\\beta_0+\\beta_1X_{i1}+\\beta_2X_{i2}+\\epsilon_i\\) assumes that the relationship between \\(Y\\) and \\(X_1\\) does not depend on \\(X_2\\) and will be misleading if the assumption is false. A common model used to investigate interactions is ; \\[\\begin{equation} Y_i=\\beta_0+\\beta_1 X_{i1}+\\beta_2 X_{i2}+\\beta_3 X_{i1} X_{i2}+ \\epsilon_i \\tag{11.2} \\end{equation}\\] The slope of the relationship between \\(Y\\) and \\(X_1\\), for example, is \\(\\beta_1+\\beta_2 X_{i2}\\) indicating that the relationship depends on \\(X_2\\). Similarly the slope relationship between \\(Y\\) and \\(X_2\\) is \\(\\beta_2+\\beta_1 X_{i1}\\). Consideration of \\(\\beta_1+\\beta_2 X_{i2}\\) shows that \\(\\beta_1\\) is the slope of the relationship between \\(Y\\) and \\(X_1\\) when \\(X_2 = 0\\) and therefore \\(\\beta_1\\) cannot be meaningfully interpreted if \\(X_2 = 0\\) is not a meaningful score or is outside the range of the data. This problem can be addresses by centering \\(X_1\\) and \\(X_2\\) around their respective means. It should be noted that the model in Equation (11.2) assumes that the interaction can be accurately modeled by including \\(\\beta_2 X_{i1}X_{i2}\\) in the model. This assumes the relationship between \\(Y\\) and \\(X_1\\) is linear when is \\(X_2\\) controlled. Violations of assumption of the model in Equation (11.2) should be investigated.R can be helpful in interpreting interactions by 3-dimension graphs. Examine the code below given for a simulated data set to highlight the use of R package visreg (Breheny and Burchett (2016)) ## manipulate simdata ## Yvar: dependent variable on no interaction simdata$Yvar=3+simdata$X1*2+simdata$X2*3+rnorm(nrow(simdata),0,5) library(visreg) model=lm(Yvar~X1+X2+X1*X2,data=simdata) visreg2d(model, &quot;X1&quot;, &quot;X2&quot;, plot.type=&quot;persp&quot;) The surface is flat indicating no interaction. ## manipulate simdata ## Yvarint: dependent variable on a interaction simdata$Yvarint=3+simdata$X1*1+simdata$X2*2+simdata$X1*simdata$X2*1.5+rnorm(nrow(simdata),0,5) library(visreg) model2=lm(Yvarint~X1+X2+X1*X2,data=simdata) visreg2d(model2, &quot;X1&quot;, &quot;X2&quot;, plot.type=&quot;persp&quot;) The surface is no longer flat in the presence of an interaction. 11.1.13 m) Estimators To be added 11.1.14 n) Robust Regression To be added 11.1.15 o) Sample size and statistical power To be added 11.1.16 p) Reliability of variables To be added 11.1.17 q) The nature of the variables To be added 11.1.18 r) Multiple dependent variables To be added 11.1.19 s) Missing variables To be added References "],
["useful-r-codes.html", " 12 Useful R codes 12.1 More on the apaStyle package 12.2 A useful shiny application", " 12 Useful R codes # Convert numeric to factor temdata[,2:9] &lt;- lapply(temdata[,2:9], as.factor) # Convert factor to numeric as.numeric.factor &lt;- function(x) {as.numeric(levels(x))[x]} temdata[,2:5] &lt;- lapply(temdata[,2:5], as.numeric.factor) # Have frequencies table for multiple columns dems=apply(temdata[,5:11], 2, function(x){table(x,temdata$grp)}) library (plyr) mydems &lt;- ldply (mydems, data.frame) # Aggregate variables by grp uncagg=aggregate(. ~ grp, data = temdata, FUN=mean, na.rm=TRUE) uncaggfaster=temdata[, lapply(.SD, mean,na.rm=T), by = grp] # Find max in a table which.max(x) # Update R if(!require(installr)) { install.packages(&quot;installr&quot;); require(installr)} #load / install+load installr updateR() # Create dummy variable from a factor head(temdata) for(level in unique(temdata$zp)){ temdata[paste(&quot;dummy&quot;, level, sep = &quot;_&quot;)] &lt;- ifelse(temdata$zp == level, 1, 0) } # Using semi colon to send multiple input x=rnorm(10000,5,10) mean(x);var(x);sqrt(var(x)) # Remove an object y=rnorm(10) rm(y) # Empty the working space rm(list=ls()) # Remove all but some rm(list=setdiff(ls(),c(&quot;temdata&quot;, &quot;temdata2&quot;))) # Integer division 7%/%2 # Modulo = remainder 5%%2 # Define and print (count=c(25,12,7,4,6,2,1,0,2)) # Read csv by clicking data=read.csv(file.choose(),header=TRUE,) #Combine more than 1 csv files filenames &lt;- list.files() temdata=do.call(&quot;rbind&quot;, lapply(filenames, read.csv, header = F)) write.table(temdata, file =&quot;temdata.binded.csv&quot; , sep = &quot;,&quot;,col.names = F, row.names = F) #Multiple QQ plot #split screen layout(matrix(1:9, nc = 3)) sapply(names(temdata)[1:9], function(x) { qqnorm(temdata[[x]], main = x) qqline(temdata[[x]]) }) #Split for more plots par(mfrow=c(3,3)) #Double for loop x=matrix(1:15,3,5) for(i in seq_len(nrow(x))) { for(j in seq_len(ncol(x))) { print(x[i,j]) } } #While loop count=0 while(count&lt;10){ print(count) count=count+1 } #Missing data convert -999s to NAs read.csv(&quot;x.csv&quot;, na.strings=&quot;-999&quot;) temdata[is.na(temdata)] &lt;- 0 #convert NAs to -99s vector[which(vector== NA)]= (-99) temdata[is.na(temdata)]= (-99) #if you are having trouble converting &lt;NA&gt; (but not NA) temdata=read.csv(&quot;temdata.csv&quot;,stringsAsFactors=FALSE) # add group mean temdata2=merge(temdata, aggregate(X ~ grp, data = temdata, FUN=mean, na.rm=TRUE), by = &quot;grp&quot;, suffixes = c(&quot;&quot;, &quot;.mean&quot;),all=T) temdata2=merge(temdata, aggregate(cbind(X1 ,X2 ,X3 , X4) ~ grp, data = temdata, FUN=mean, na.rm=TRUE), by = &quot;grp&quot;, suffixes = c(&quot;&quot;, &quot;.mean&quot;),all=T) temdata2=merge(temdata, ddply(temdata, c(&quot;grp&quot;), function(x) colMeans(x[c(&quot;X1&quot; ,&quot;X2&quot;,&quot;X3&quot; , &quot;X4&quot;)])), by = &quot;grp&quot;, suffixes = c(&quot;&quot;, &quot;.mean&quot;),all=T) #ifelse y=c(1,2,3,4,5,5,5) y2=ifelse(y==5,NA,y) y2 temdata &lt;- data.frame (ID=c(2,3,4,5), Hunger =c(415,452,550,318 )) temdata$newcol&lt;-ifelse(temdata[,2]&gt;=300 &amp; temdata[,2]&lt;400,350, ifelse(temdata[,2]&gt;=400 &amp;temdata[,2]&lt;500,450, ifelse(temdata[,2]&gt;=500 &amp; temdata[,2]&lt;600,550,NA))) #if x=5 y=if(x&gt;6){1}else{0} y=if(x&gt;6){1} else if(x==5) {99} else {0} #sort a dataframe by the order of the elements in B temdata[order(temdata$B),] #sort the dataframe in reverse order temdata[rev(order(temdata$B)),] #create combinations m=c(54,38,51,62,18,31,58,74,35,34) f=c(41,18,19,39,44,18,58,21,38) mean(m) mean(f) combn(m,8,FUN=mean) combn(f,8) min(combn(m,8,FUN=mean)) max(combn(f,8,mean)) #setting contrasts options(&#39;contrasts&#39;) options(contrasts=c(&#39;contr.sum&#39;,&#39;contr.poly&#39;)) options(contrasts=c(&#39;contr.treatment&#39;,&#39;contr.poly&#39;)) # delete if all NA temdata=temdata[apply(temdata,1,function(x)any(!is.na(x))),] # add group frequency temdata=ddply(temdata, &quot;grp&quot;, transform, cellsize = count(grp)[2]) #create new folder dir.create(&quot;testdir&quot;) #split data frame library(datasets) head(airquality) splitdata=split(airquality,airquality$Month) splitdata str(splitdata) splitdata[[2]] x=list(a=1:5, b=rnorm(10)) x lapply(x,mean) # output is always a list x=1:4 lapply(x,runif) lapply(x,runif,min=10, max=20) x=list(a=matrix(1:4,2,2),b=matrix(1:6,3,2)) lapply(x,function(elt) elt[,1]) # sapply x=list(a=1:5, b=rnorm(10),c=runif(10)) x lapply(x,mean) sapply(x,mean) #apply generally used for rows or columns x=matrix(rnorm(200),20,10) x apply(x,2,mean) apply(x,1,sum) #tapply x=c(1:10,rnorm(10),runif(10,3,5)) f=gl(3,10) ?gl h=factor(rep(1:3,each=10)) tapply(x,f,mean) tapply(x,h,mean) tapply(x,h,mean,simplify=F) tapply(x,h,range) #missing data proportion percentage propmiss &lt;- function(temdata) lapply(temdata,function(x) data.frame(nmiss=sum(is.na(x)), n=length(x), propmiss=sum(is.na(x))/length(x))) propmiss(temdata) #upper case temdata$childid=toupper(temdata$childid) # plot graph individual all variables plotpdf=&quot;C:/Users/Desktop/work/multiplePLOTS.pdf&quot; pdf(file=plotpdf) for (i in 7:55){ muis=round(mean(temdata[,i],na.rm=T),3) sdis=round(sd(temdata[,i],na.rm=T),3) meansc=c(&quot;mean&quot;,muis) hist(temdata[,i],freq=F,main=names(temdata)[i],xlab=meansc) #lines(density(temdata[,i],na.rm=T)) curve(dnorm(x, mean=muis, sd=sdis), add=TRUE) lines(density(temdata[,i],na.rm=T, adjust=2), lty=&quot;dotted&quot;, col=&quot;darkgreen&quot;, lwd=2) abline(v=muis,col=&quot;blue&quot;) abline(v=muis+3*sdis,col=&quot;red&quot;) abline(v=muis-3*sdis,col=&quot;red&quot;) } dev.off() # read in upper directory dd=read.csv(&quot;../temdata.csv&quot;) 12.1 More on the apaStyle package Here is more details on the apaStyle package; require(pastecs) require(apaStyle) library(rJava) #if this throws an error Sys.setenv(JAVA_HOME=&#39;C:\\\\Program Files\\\\Java\\\\jre1.8.0_111&#39;) # for 64-bit version #define a data set apa.descriptives(data = temdataet[,1:5], variables = names(temdataet[,1:5]), report = &quot;&quot;, title = &quot;test&quot;, filename = &quot;test.docx&quot;, note = NULL, position = &quot;lower&quot;, merge = FALSE, landscape = FALSE, save = TRUE) example &lt;- data.frame(c(&quot;Column 1&quot;, &quot;Column 2&quot;, &quot;Column 3&quot;), c(3.45, 5.21, 2.64), c(1.23, 1.06, 1.12) ) apa.table(data = example, level1.header = c(&quot;Variable&quot;, &quot;M&quot;, &quot;SD&quot;)) example &lt;- data.frame( c(&quot;Column 1&quot;, &quot;Column 2&quot;, &quot;Column 3&quot;), c(3.45, 5.21, 2.64), c(1.23, 1.06, 1.12), c(8.22, 25.12, 30.27), c(&quot;+&quot;, &quot;**&quot;, &quot;***&quot;) ) apa.table( data = example, level1.header = c(&quot;&quot;, &quot;Descriptives&quot;, &quot;Inferential&quot;), level1.colspan = c(1, 2, 1), level2.header = c(&quot;Variable&quot;, &quot;M&quot;, &quot;SD&quot;, &quot;t-value&quot;, &quot;*&quot;) )$table 12.2 A useful shiny application Below is a Shiny app example (Figure 12.1) to calculate sample size for an analyses of covariance design; knitr::include_app(&#39;https://burakaydin.shinyapps.io/ancovaN/&#39;, height = &#39;800px&#39;) Figure 12.1: ANCOVA sample size calculator "]
]
